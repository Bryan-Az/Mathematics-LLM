# Mathematics-LLM
This is a brief group project where we train and benchmark a LLM on it's ability to respond accurately to math problems.

## Abstract

## HuggingFace Links

### Finetuning Education/Math HuggingFaceTB SmolLM2 1.7B Parameter Model

base model: https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct 

non-quantized model: https://huggingface.co/Alexis-Az/Math-Problem-LlaMA-3.2-1.7B

quantized model: https://huggingface.co/Alexis-Az/Math-Problem-LlaMA-3.2-1.7B-GGUF


### Finetuning Base LlaMA 3.2 1B Parameter Model

base model: https://huggingface.co/unsloth/Llama-3.2-1B-Instruct

quantized model: https://huggingface.co/Alexis-Az/Math-Problem-LlaMA-3.2-1B-GGUF

### Training / Evaluation Datasets

Subsets for additions, derivaties, and roots: https://huggingface.co/datasets/Alexis-Az/math_datasets

### Evaluation Metrics Dataset

Evaluations for Both Models: https://huggingface.co/datasets/Alexis-Az/Math-LLM-Evaluations


