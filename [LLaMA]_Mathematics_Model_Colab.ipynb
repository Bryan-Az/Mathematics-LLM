{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.15",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "sourceId": 9910295,
          "sourceType": "datasetVersion",
          "datasetId": 6089178
        }
      ],
      "dockerImageVersionId": 30788,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4c19180935040f0b157fe8ddb65249e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ffa55b03566404bb4799e794211f2a8",
              "IPY_MODEL_3b2f48012ff0473f9a81eb884f4d0cde",
              "IPY_MODEL_c121cc1708014ee7850dcfb6aca90bfd"
            ],
            "layout": "IPY_MODEL_5551fa1083f5415fa3c1668abf34366e"
          }
        },
        "6ffa55b03566404bb4799e794211f2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dfa771c5b764f05aef5c4cc2aa53b2f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8b99868e6eea4833bcb061b3aa6c624c",
            "value": "README.md:â€‡100%"
          }
        },
        "3b2f48012ff0473f9a81eb884f4d0cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_192dfd0b251c49a48519174314ac4de7",
            "max": 5181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc1d72428a4e4b68bc72c427910e7d10",
            "value": 5181
          }
        },
        "c121cc1708014ee7850dcfb6aca90bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e0ce1d687de444cbd979e0950a98ae0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a2e65019eb274c89aac2511bd4c6f7fe",
            "value": "â€‡5.18k/5.18kâ€‡[00:00&lt;00:00,â€‡428kB/s]"
          }
        },
        "5551fa1083f5415fa3c1668abf34366e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dfa771c5b764f05aef5c4cc2aa53b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b99868e6eea4833bcb061b3aa6c624c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "192dfd0b251c49a48519174314ac4de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1d72428a4e4b68bc72c427910e7d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e0ce1d687de444cbd979e0950a98ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e65019eb274c89aac2511bd4c6f7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6082d1f2e3774591b330717b2db6a6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a68f873b036478f8e642913b8b9ac3e",
              "IPY_MODEL_aff5dcc10e8d45569ddc43cd7577cdec",
              "IPY_MODEL_3e55ad74f0c74c4d9b0f0f6167395a6f"
            ],
            "layout": "IPY_MODEL_7dda54ba16c94e56ac4bd74ad98dc6b3"
          }
        },
        "3a68f873b036478f8e642913b8b9ac3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecbe0ad48406484bb1672e52b29b43c3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_275029495a6940d185a52b108fe2ccfa",
            "value": "config.json:â€‡100%"
          }
        },
        "aff5dcc10e8d45569ddc43cd7577cdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0a5e0e39d443a682b5edc8a89700bb",
            "max": 1408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dc840f3e3394f61be780699a2b5c24f",
            "value": 1408
          }
        },
        "3e55ad74f0c74c4d9b0f0f6167395a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5068ba6f377a4f3f847159d9eb0370d0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a205587552f6473eafb49c1564c1f4a8",
            "value": "â€‡1.41k/1.41kâ€‡[00:00&lt;00:00,â€‡116kB/s]"
          }
        },
        "7dda54ba16c94e56ac4bd74ad98dc6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecbe0ad48406484bb1672e52b29b43c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "275029495a6940d185a52b108fe2ccfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe0a5e0e39d443a682b5edc8a89700bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dc840f3e3394f61be780699a2b5c24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5068ba6f377a4f3f847159d9eb0370d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a205587552f6473eafb49c1564c1f4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ba546ccd82b4a5980876a09ce61a108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1582068a1cce44b0b2ea470d563fe92c",
              "IPY_MODEL_ff19974f98624c68b91854d8b6ac3f67",
              "IPY_MODEL_5a5b69e6f5e947c6b7defeb99e0f7f73"
            ],
            "layout": "IPY_MODEL_7cde0297cbb64f9faf44c4428e89661b"
          }
        },
        "1582068a1cce44b0b2ea470d563fe92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7faba1fa9a84a179cee00dbeabefa48",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b4df420e48384f50b823152f50bc105a",
            "value": "adapter_model.safetensors:â€‡100%"
          }
        },
        "ff19974f98624c68b91854d8b6ac3f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_264176ce69204a36a3dcb788b67d27a0",
            "max": 1084519576,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c2732a3684c4058825c0bde018f8783",
            "value": 1084519576
          }
        },
        "5a5b69e6f5e947c6b7defeb99e0f7f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6da1c33facf2466a8d330796e48f7337",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2e5e71999d0a42cc92626762387545d3",
            "value": "â€‡1.08G/1.08Gâ€‡[00:25&lt;00:00,â€‡56.7MB/s]"
          }
        },
        "7cde0297cbb64f9faf44c4428e89661b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7faba1fa9a84a179cee00dbeabefa48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4df420e48384f50b823152f50bc105a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "264176ce69204a36a3dcb788b67d27a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2732a3684c4058825c0bde018f8783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6da1c33facf2466a8d330796e48f7337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5e71999d0a42cc92626762387545d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bryan-Az/Mathematics-LLM/blob/training/%5BLLaMA%5D_Mathematics_Model_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the 'Integration' Mathematics Problem Solving Model on a GPU Environment\n",
        "This notebook is running on an T4 GPU environment in google colab. The pre-trained foundation model we are using is the publically available unsloth/Llama-3.2-1B-Instruct, requiring authentication with HuggingFace."
      ],
      "metadata": {
        "id": "Egkwbn23u0-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Installs"
      ],
      "metadata": {
        "id": "4JYklhERu0-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "!pip install unsloth\n",
        "# Get latest Unsloth\n",
        "!pip install --upgrade --force-reinstall --no-deps \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L3b_zbWDllAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import AutoTokenizer\n",
        "#from transformers import AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model"
      ],
      "metadata": {
        "id": "I0-KN7U0-cmI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "EtWrZC1-oJM8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Optional\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "from transformers import LlamaConfig\n",
        "from unsloth import FastLanguageModel"
      ],
      "metadata": {
        "id": "pI_eIhOw-oe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c67a0c-ea04-4bff-fa45-4d5fdb21074f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "from datasets import load_dataset\n",
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "GsPr8ZqQ_Gvt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# import library to keep time using .now\n",
        "import datetime"
      ],
      "metadata": {
        "id": "EdXeoRvA_sLH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Tokenizer of the Pre-trained LlaMA 8B Model\n",
        "It's necessary to import the tokenizer of the model for loading the dataset."
      ],
      "metadata": {
        "id": "2gM7be1su0-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_INPUT=4096\n",
        "MODEL = \"unsloth/Llama-3.2-1B-Instruct\" #You should be able to use 7B model with no changes! There should be enough HBM\n",
        "SAVED_MODEL = \"Alexis-Az/Math-Problem-LlaMA-3.2-1B\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T18:50:57.596394Z",
          "iopub.execute_input": "2024-11-15T18:50:57.596685Z",
          "iopub.status.idle": "2024-11-15T18:50:57.601046Z",
          "shell.execute_reply.started": "2024-11-15T18:50:57.596656Z",
          "shell.execute_reply": "2024-11-15T18:50:57.600355Z"
        },
        "id": "DaXKh2vVu0-e"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "#if 'pad_token' not in tokenizer.special_tokens_map:\n",
        "#  tokenizer.pad_token=tokenizer.eos_token\n",
        "#print(f\"Tokens :\\n {tokenizer.special_tokens_map} \\n\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T18:50:57.601910Z",
          "iopub.execute_input": "2024-11-15T18:50:57.602155Z",
          "iopub.status.idle": "2024-11-15T18:50:59.756142Z",
          "shell.execute_reply.started": "2024-11-15T18:50:57.602129Z",
          "shell.execute_reply": "2024-11-15T18:50:59.755246Z"
        },
        "id": "6zSG68mou0-e"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Pre-trained Model with LoRa Adapters using Unsloth\n",
        "Adding LoRa will allow us to fine-tune the model on our story dataset."
      ],
      "metadata": {
        "id": "3Rtls26_u0-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set device\n",
        "device= f'cuda:{torch.cuda.current_device()}'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0PGCMdk2aK8Y",
        "outputId": "6d0c7ac1-733f-46d0-cd95-2cc288fd7bb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import is_bfloat16_supported\n",
        "max_seq_length = 2048\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(MODEL, max_seq_length=max_seq_length, dtype=None,load_in_4bit=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T18:55:44.526495Z",
          "iopub.execute_input": "2024-11-15T18:55:44.526785Z",
          "iopub.status.idle": "2024-11-15T19:02:08.999474Z",
          "shell.execute_reply.started": "2024-11-15T18:55:44.526757Z",
          "shell.execute_reply": "2024-11-15T19:02:08.998813Z"
        },
        "id": "sv-ZUQLju0-f",
        "outputId": "52ddc78d-5f6f-4e6b-bed7-17b5e802c4a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.11.10: Fast Llama patching. Transformers:4.46.2.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "nysqjvrmu0-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InstructionDataset(TorchDataset):\n",
        "    def __init__(self, tokenizer, max_length=1024, dataset=None):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prompts = self.dataset[idx]\n",
        "        text = \"\"\n",
        "        for prompt in prompts:\n",
        "            data = prompts[prompt]\n",
        "            if prompt == 'Function':\n",
        "                text += f\"<|im_start|>user\\n Can you help me solve this math problem? {data}<|im_end|>\\n\"\n",
        "            if prompt == 'Operation':\n",
        "                text += f\"<|im_start|>user\\n Can you help me solve this math problem with addition? {data}<|im_end|>\\n\"\n",
        "            if prompt == 'Roots':\n",
        "                text += f\"<|im_start|>assistant\\n Here's the answer to solve this root-based problem: {data}<|im_end|>\"\n",
        "            if prompt == 'Derivatives':\n",
        "                text += f\"<|im_start|>assistant\\n Here's the answer to solve this derivative-based problem: {data}<|im_end|>\"\n",
        "            if prompt == 'Result':\n",
        "                text += f\"<|im_start|>assistant\\n Here's the answer to solve this addition problem: {data}<|im_end|>\"\n",
        "\n",
        "\n",
        "        try:\n",
        "            input_ids = self.tokenizer(text, add_special_tokens=True, max_length=self.max_length, truncation=True, padding=\"max_length\", return_attention_mask=True, return_tensors=\"pt\")\n",
        "        except Exception as e:  # You can catch specific tokenizer exceptions if known\n",
        "            print(f\"Error tokenizing text at index {idx}: {e}\")\n",
        "            print(f\"Problematic text: {text}\")  # Print the text causing the issue\n",
        "            # Handle the exception (e.g., skip the sample, replace with empty tokens)\n",
        "            # Here, I'll skip the problematic sample:\n",
        "            return None  # or raise the exception if desired\n",
        "\n",
        "\n",
        "        if input_ids is None:\n",
        "            return None\n",
        "        return {\n",
        "            \"input_ids\": input_ids[\"input_ids\"].squeeze(0),\n",
        "            \"labels\": input_ids[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\":input_ids[\"attention_mask\"].squeeze(0),\n",
        "        }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T18:50:59.771228Z",
          "iopub.execute_input": "2024-11-15T18:50:59.771501Z",
          "iopub.status.idle": "2024-11-15T18:50:59.789867Z",
          "shell.execute_reply.started": "2024-11-15T18:50:59.771473Z",
          "shell.execute_reply": "2024-11-15T18:50:59.789103Z"
        },
        "id": "Y0K5kXltu0-e"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=\"Alexis-Az/math_datasets\"\n",
        "# ~1/5 of the dataset is used for validation\n",
        "train_data_derivs = load_dataset(train_dataset, name='derivatives', split='train[:8000]').shuffle()\n",
        "val_derivs = (load_dataset(train_dataset, 'derivatives', split=\"train[-2000:]\")).shuffle()"
      ],
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T18:50:59.790916Z",
          "iopub.execute_input": "2024-11-15T18:50:59.791175Z",
          "iopub.status.idle": "2024-11-15T18:55:44.474789Z",
          "shell.execute_reply.started": "2024-11-15T18:50:59.791148Z",
          "shell.execute_reply": "2024-11-15T18:55:44.473791Z"
        },
        "id": "S4Uulk-Uu0-e"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_roots = load_dataset(train_dataset, 'roots', split='train[:8000]').shuffle()\n",
        "val_roots = (load_dataset(train_dataset, 'roots', split=\"train[-2000:]\")).shuffle()"
      ],
      "metadata": {
        "id": "AWEPQAlxIYzg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_adds = load_dataset(train_dataset, 'additions', split='train[:800000]').shuffle()\n",
        "val_adds = (load_dataset(train_dataset, 'additions', split=\"train[-200000:]\")).shuffle()"
      ],
      "metadata": {
        "id": "nBA78DljcwDw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the additions dataset (our main objective) is 100x larger than the data for derivatives and roots, the max steps for additions is set to 2000 and is set to 500 each for the other datasets. This will train for 3,000 steps and will take roughly 1 hour and a half on the A100 gpu environment in google colab."
      ],
      "metadata": {
        "id": "SRl-dL68fxbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_deriv_configs = {'MAX_INPUT': MAX_INPUT,\n",
        "         'LOGGING_STEPS': 1,\n",
        "         'NUM_EPOCHS': 1,\n",
        "         'PAUSE_STEPS':0, # asks to exit training after x steps #todo checkpoints\n",
        "         'MAX_STEPS': 500,#Ooverides num epochs\n",
        "         'BATCH_SIZE': 2, #Making batch_size lower then 8 will result in slower training, but will allow for larger models\\context. Fortunately, we have 128GBs. Setting higher batch_size doesn't seem to improve time.\n",
        "          'LEN_TRAIN_DATA': len(train_data_derivs),\n",
        "         'VAL_STEPS': 20,\n",
        "         'VAL_BATCH': 5,\n",
        "         'GRAD_ACCUMULATION_STEP':1,\n",
        "         'MAX_GRAD_CLIP':1,\n",
        "        'LEARNING_RATE':6e-5,\n",
        "         'WARMUP_RATIO':0.01,\n",
        "         'OPTIMIZER':'adam', # default = 'adamw'  options->  ['adamw','SM3','came','adafactor','lion']\n",
        "         'SCHEDULAR':'cosine', # default= 'cosine'     options:-> ['linear','cosine']\n",
        "         'WEIGHT_DECAY':0.1,\n",
        "         'TRAIN_DATASET':train_data_derivs,\n",
        "         \"TEST_DATASET\":val_derivs,\n",
        "         'WANDB':True,\n",
        "        'PROJECT':'Math-Model',\n",
        "        }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T18:55:44.476329Z",
          "iopub.execute_input": "2024-11-15T18:55:44.476607Z",
          "iopub.status.idle": "2024-11-15T18:55:44.482235Z",
          "shell.execute_reply.started": "2024-11-15T18:55:44.476580Z",
          "shell.execute_reply": "2024-11-15T18:55:44.481520Z"
        },
        "id": "8mQHcHYPu0-e"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "train_roots_configs = {'MAX_INPUT': MAX_INPUT,\n",
        "         'LOGGING_STEPS': 1,\n",
        "         'NUM_EPOCHS': 1,\n",
        "         'PAUSE_STEPS':0, # asks to exit training after x steps #todo checkpoints\n",
        "         'MAX_STEPS': 500,#-1 trains on entire data. Settins max steps overides num epochs\n",
        "         'BATCH_SIZE': 2, #Making batch_size lower then 8 will result in slower training, but will allow for larger models\\context. Fortunately, we have 128GBs. Setting higher batch_size doesn't seem to improve time.\n",
        "          'LEN_TRAIN_DATA': len(train_data_roots),\n",
        "         'VAL_STEPS': 20,\n",
        "         'VAL_BATCH': 5,\n",
        "         'GRAD_ACCUMULATION_STEP':1,\n",
        "         'MAX_GRAD_CLIP':1,\n",
        "        'LEARNING_RATE':6e-5,\n",
        "         'WARMUP_RATIO':0.01,\n",
        "         'OPTIMIZER':'adam', # default = 'adamw'  options->  ['adamw','SM3','came','adafactor','lion']\n",
        "         'SCHEDULAR':'cosine', # default= 'cosine'     options:-> ['linear','cosine']\n",
        "         'WEIGHT_DECAY':0.1,\n",
        "         'TRAIN_DATASET':train_data_roots,\n",
        "         \"TEST_DATASET\":val_roots,\n",
        "         'WANDB':True,\n",
        "        'PROJECT':'Math-Model',\n",
        "        }"
      ],
      "metadata": {
        "id": "70gafqlMK7jQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# additions data is 100x bigger than for the other sides so max steps will be decreased\n",
        "train_adds_configs = {'MAX_INPUT': MAX_INPUT,\n",
        "         'LOGGING_STEPS': 1,\n",
        "         'NUM_EPOCHS': 1,\n",
        "         'PAUSE_STEPS':0, # asks to exit training after x steps #todo checkpoints\n",
        "         'MAX_STEPS': 2000,#-1 trains on entire data. Settins max steps overides num epochs\n",
        "         'BATCH_SIZE': 2, #Making batch_size lower then 8 will result in slower training, but will allow for larger models\\context. Fortunately, we have 128GBs. Setting higher batch_size doesn't seem to improve time.\n",
        "          'LEN_TRAIN_DATA': len(train_data_adds),\n",
        "         'VAL_STEPS': 20,\n",
        "         'VAL_BATCH': 5,\n",
        "         'GRAD_ACCUMULATION_STEP':1,\n",
        "         'MAX_GRAD_CLIP':1,\n",
        "        'LEARNING_RATE':6e-5,\n",
        "         'WARMUP_RATIO':0.01,\n",
        "         'OPTIMIZER':'adam', # default = 'adamw'  options->  ['adamw','SM3','came','adafactor','lion']\n",
        "         'SCHEDULAR':'cosine', # default= 'cosine'     options:-> ['linear','cosine']\n",
        "         'WEIGHT_DECAY':0.1,\n",
        "         'TRAIN_DATASET':train_data_adds,\n",
        "         \"TEST_DATASET\":val_adds,\n",
        "         'WANDB':True,\n",
        "        'PROJECT':'Math-Model',\n",
        "        }"
      ],
      "metadata": {
        "id": "JUMinWbfdQbn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_derivs_instruct = InstructionDataset(tokenizer, dataset=train_data_derivs, max_length=train_deriv_configs['MAX_INPUT'])\n",
        "val_derivs_instruct = InstructionDataset(tokenizer, dataset=val_derivs)\n",
        "\n",
        "#collate fn to skip nones in the batch\n",
        "def collate_fn(batch):\n",
        "    batch = list(filter(lambda x: x is not None, batch))\n",
        "    return torch.utils.data.dataloader.default_collate(batch)\n",
        "\n",
        "\n",
        "train_deriv_loader = torch.utils.data.DataLoader(train_data_derivs_instruct, batch_size=train_deriv_configs[\"BATCH_SIZE\"], collate_fn=collate_fn,shuffle=True)\n",
        "testing_deriv_loader = torch.utils.data.DataLoader(val_derivs, batch_size=train_deriv_configs[\"BATCH_SIZE\"], collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "print(f\"Max Steps: {len(train_deriv_loader)}, Batch size: {8*train_deriv_configs['BATCH_SIZE']}\")\n",
        "print(f\"Val Size: {len(testing_deriv_loader)}, Batch Size: {8*train_deriv_configs['BATCH_SIZE']}\")\n",
        "train_deriv_configs['STEPS']=len(train_deriv_loader)\n",
        "train_deriv_configs['BATCH_DATA']=train_deriv_configs['BATCH_SIZE']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T18:55:44.484666Z",
          "iopub.execute_input": "2024-11-15T18:55:44.484925Z",
          "iopub.status.idle": "2024-11-15T18:55:44.525558Z",
          "shell.execute_reply.started": "2024-11-15T18:55:44.484900Z",
          "shell.execute_reply": "2024-11-15T18:55:44.524815Z"
        },
        "id": "Ge_8qEe1u0-f",
        "outputId": "08bb93bb-308e-4e83-b350-73f146abb35f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Steps: 4000, Batch size: 16\n",
            "Val Size: 1000, Batch Size: 16\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_roots_instruct = InstructionDataset(tokenizer, dataset=train_data_roots, max_length=train_roots_configs['MAX_INPUT'])\n",
        "val_roots_instruct = InstructionDataset(tokenizer, dataset=val_roots)\n",
        "\n",
        "train_roots_loader = torch.utils.data.DataLoader(train_data_roots_instruct, batch_size=train_roots_configs[\"BATCH_SIZE\"],collate_fn=collate_fn, shuffle=True)\n",
        "testing_roots_loader = torch.utils.data.DataLoader(val_roots, batch_size=train_roots_configs[\"BATCH_SIZE\"], collate_fn=collate_fn,shuffle=True)\n",
        "\n",
        "print(f\"Max Steps: {len(train_roots_loader)}, Batch size: {8*train_roots_configs['BATCH_SIZE']}\")\n",
        "print(f\"Val Size: {len(testing_roots_loader)}, Batch Size: {8*train_roots_configs['BATCH_SIZE']}\")\n",
        "train_roots_configs['STEPS']=len(train_roots_loader)\n",
        "train_roots_configs['BATCH_DATA']=train_roots_configs['BATCH_SIZE']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2oOXJ9cMvL4",
        "outputId": "7547abf8-9f56-4e61-f847-b7a14d2c4004"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Steps: 4000, Batch size: 16\n",
            "Val Size: 1000, Batch Size: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_adds_instruct = InstructionDataset(tokenizer, dataset=train_data_adds, max_length=train_adds_configs['MAX_INPUT'])\n",
        "val_adds_instruct = InstructionDataset(tokenizer, dataset=val_adds)\n",
        "\n",
        "train_adds_loader = torch.utils.data.DataLoader(train_data_adds_instruct, batch_size=train_adds_configs[\"BATCH_SIZE\"],collate_fn=collate_fn, shuffle=True)\n",
        "testing_adds_loader = torch.utils.data.DataLoader(val_adds, batch_size=train_adds_configs[\"BATCH_SIZE\"], collate_fn=collate_fn,shuffle=True)\n",
        "\n",
        "print(f\"Max Steps: {len(train_adds_loader)}, Batch size: {8*train_adds_configs['BATCH_SIZE']}\")\n",
        "print(f\"Val Size: {len(testing_adds_loader)}, Batch Size: {8*train_adds_configs['BATCH_SIZE']}\")\n",
        "train_adds_configs['STEPS']=len(train_adds_loader)\n",
        "train_adds_configs['BATCH_DATA']=train_adds_configs['BATCH_SIZE']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJDqytXldjwm",
        "outputId": "ea514c52-1afe-4c3d-cbdb-48b7b8235143"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Steps: 400000, Batch size: 16\n",
            "Val Size: 100000, Batch Size: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls=LoraConfig(\n",
        "    r = 12, # Lora Rank should generally be smaller for smaller models\n",
        "    target_modules = ['q_proj', 'down_proj', 'up_proj', 'o_proj', 'v_proj', 'gate_proj', 'k_proj'],\n",
        "    lora_alpha = 16, #weight_scaling\n",
        "    lora_dropout = 0.05, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    modules_to_save = [\"lm_head\", \"embed_tokens\"] ## if you use new chat formats or embedding tokens\n",
        ")\n",
        "model = get_peft_model(model, ls)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T19:02:09.000369Z",
          "iopub.execute_input": "2024-11-15T19:02:09.000622Z",
          "iopub.status.idle": "2024-11-15T19:02:10.966133Z",
          "shell.execute_reply.started": "2024-11-15T19:02:09.000596Z",
          "shell.execute_reply": "2024-11-15T19:02:10.965033Z"
        },
        "id": "MPqmhKFBu0-f",
        "outputId": "898435c2-9ea2-4eea-aab4-647a225a19f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 533,790,720 || all params: 1,769,605,120 || trainable%: 30.1644\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "m65WvteNu0-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import wandb\n",
        "__wandb__=train_deriv_configs['WANDB']\n",
        "from transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\n",
        "# from random import randrange\n",
        "# from bitsandbytes.optim import AdamW8bit\n",
        "# from torchdistx.optimizers import AnyPrecisionAdamW\n",
        "\n",
        "val_step=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_loss(outputs,labels,pad_id=tokenizer.pad_token_id):\n",
        "  epsilon=1e-8\n",
        "  logits=outputs.logits\n",
        "  logits = logits[..., :-1, :].contiguous()\n",
        "  labels = labels[..., 1:].contiguous()\n",
        "  log_probs = -nn.functional.log_softmax(logits, dim=-1)\n",
        "  if labels.dim() == log_probs.dim() - 1:\n",
        "    labels = labels.unsqueeze(-1)\n",
        "  padding_mask = labels.eq(pad_id)\n",
        "  labels = torch.clamp(labels, min=0)\n",
        "  nll_loss = log_probs.gather(dim=-1, index=labels)\n",
        "  smoothed_loss = log_probs.sum(dim=-1, keepdim=True, dtype=torch.bfloat16)\n",
        "  nll_loss.masked_fill_(padding_mask, 0.0)\n",
        "  smoothed_loss.masked_fill_(padding_mask, 0.0)\n",
        "  num_active_elements = padding_mask.numel() - padding_mask.long().sum()\n",
        "  nll_loss = nll_loss.sum() / num_active_elements\n",
        "  smoothed_loss = smoothed_loss.sum() / (num_active_elements * log_probs.shape[-1])\n",
        "  del labels,logits,padding_mask\n",
        "  return (1-epsilon)*nll_loss + epsilon*smoothed_loss\n",
        "\n",
        "\n",
        "\n",
        "def train(FLAGS, training_loader, testing_loader, device):\n",
        "\n",
        "\n",
        "    ### Configuring Training\n",
        "    global val_step\n",
        "    update_params= filter(lambda p: p.requires_grad, model.parameters())\n",
        "    num_iterations = int((FLAGS[\"NUM_EPOCHS\"] * FLAGS['STEPS'] ) // FLAGS['GRAD_ACCUMULATION_STEP'])\n",
        "    warmup_steps = int(num_iterations * FLAGS['WARMUP_RATIO'])\n",
        "\n",
        "    if __wandb__:\n",
        "        wandb.init(project=FLAGS['PROJECT'],config=FLAGS)\n",
        "        wandb.define_metric(\"Validation_loss\", step_metric=\"val_step\")\n",
        "        wandb.define_metric(\"Learning_rate\",step_metric=\"train_step\")\n",
        "        wandb.define_metric(\"train_loss\",step_metric=\"train_step\")\n",
        "\n",
        "    ### Optimizers\n",
        "\n",
        "    if (FLAGS['OPTIMIZER']).lower()=='adam':\n",
        "        optimizer = Adam(update_params, eps=1e-8, lr=FLAGS['LEARNING_RATE'], betas=(0.9, 0.999),weight_decay=FLAGS['WEIGHT_DECAY'])\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        if len(param_group[\"params\"]) > 0:\n",
        "            print(param_group[\"params\"][0].device)\n",
        "            break\n",
        "\n",
        "\n",
        "    ### Schedulars\n",
        "\n",
        "    if (FLAGS['SCHEDULAR']).lower()=='linear':\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,num_iterations)\n",
        "    else:\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer,warmup_steps,num_iterations)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ### Training Loop\n",
        "    val_step=0\n",
        "    check=False #for brakes\n",
        "    for epoch in range(1, FLAGS['NUM_EPOCHS'] + 1):\n",
        "        if check:\n",
        "            break\n",
        "        model.train()\n",
        "        print('Epoch {} train begin {}'.format(epoch, datetime.datetime.now()))\n",
        "        for step, batch in enumerate(training_loader):\n",
        "            input_ids, labels,attention_mask = batch[\"input_ids\"].to(device),  batch[\"labels\"].to(device),batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "            loss = evaluate_loss(outputs,labels)\n",
        "\n",
        "\n",
        "            if (step + 1) % FLAGS['LOGGING_STEPS'] == 0:\n",
        "                print(f'loss: {loss.detach().cpu().item()}, time: {datetime.datetime.now()}, step: {step+1}')\n",
        "            if __wandb__:\n",
        "                wandb.log({\n",
        "                'Learning_rate': optimizer.param_groups[0]['lr'],\n",
        "                'train_loss':  loss.detach().cpu().item(),\n",
        "                'train_step': step + 1 + ((epoch-1) * FLAGS[\"STEPS\"]),\n",
        "                        })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            del input_ids , attention_mask\n",
        "            loss.backward()\n",
        "            del outputs,loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if (step+1) % FLAGS['GRAD_ACCUMULATION_STEP'] == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=FLAGS['MAX_GRAD_CLIP']*8)\n",
        "                scheduler.step()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if (step+1)% FLAGS['VAL_STEPS'] == 0:\n",
        "                end_index=FLAGS[\"VAL_BATCH\"]\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    total_loss = 0\n",
        "                    total_step = 0\n",
        "                    for stepx, batchx in enumerate(testing_loader):\n",
        "                        #check that the key 'input_ids' is in the batchx dict\n",
        "                        if 'input_ids' not in batchx:\n",
        "                            continue\n",
        "                        input_ids = batchx[\"input_ids\"].to(device)\n",
        "                        labels = batchx[\"labels\"].to(device)\n",
        "                        attention_mask = batchx[\"attention_mask\"].to(device)\n",
        "                        outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "                        loss = evaluate_loss(outputs,labels)\n",
        "                        total_loss += loss.item()\n",
        "                        total_step +=1\n",
        "                        print('----- Time -> {} ----- Validation Batch -> {} ----  Validation Loss -> {:.4f}'.format(datetime.datetime.now(), total_step , loss.item()))\n",
        "                        if __wandb__:\n",
        "                            val_step+=1\n",
        "                            wandb.log({\n",
        "                                'Validation_loss': loss.item(),\n",
        "                                'val_step':val_step,\n",
        "                                    })\n",
        "                        if (stepx+1)%end_index==0:\n",
        "                            break\n",
        "                    model.train()\n",
        "                    # avoid division by zero\n",
        "                    if total_loss==0:\n",
        "                      average_loss=0\n",
        "                    else:\n",
        "                      average_loss=total_loss/total_step\n",
        "                    print('----- Time -> {} ----- Validation Batch Size -> {} ----  Validation Loss -> {:.7f}'.format(datetime.datetime.now(), total_step , average_loss))\n",
        "\n",
        "            #uncomment if want to add checkpointing\n",
        "            #if (step+1)% FLAGS['PAUSE_STEPS']==0:\n",
        "            #    inp=input('want to continue training after {} steps'.format(step+1))\n",
        "            #    check = bool(\"no\" in inp.lower())\n",
        "            #    if check:\n",
        "            #        break\n",
        "            #    else:\n",
        "            #        pass\n",
        "\n",
        "            # stop at number of MAX_STEPS\n",
        "            if (step+1) == FLAGS['MAX_STEPS']:\n",
        "                break\n",
        "\n",
        "    if __wandb__:\n",
        "        wandb.finish()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T19:02:23.869971Z",
          "iopub.execute_input": "2024-11-15T19:02:23.870224Z",
          "iopub.status.idle": "2024-11-15T19:02:24.615412Z",
          "shell.execute_reply.started": "2024-11-15T19:02:23.870199Z",
          "shell.execute_reply": "2024-11-15T19:02:24.614445Z"
        },
        "id": "1P0FUwdMu0-f"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_adds_configs, train_adds_loader, testing_adds_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yTgc8gSYeJiK",
        "outputId": "d23c06f0-0727-47b9-bc5c-b040d67bb858"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:yzlzedlf) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Learning_rate</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ˆâ–‡â–‡â–†â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Learning_rate</td><td>4e-05</td></tr><tr><td>train_loss</td><td>0.39258</td></tr><tr><td>train_step</td><td>2360</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">prime-terrain-30</strong> at: <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/yzlzedlf' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/yzlzedlf</a><br/> View project at: <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241203_222152-yzlzedlf/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:yzlzedlf). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241203_233116-z7phfljd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/z7phfljd' target=\"_blank\">serene-mountain-31</a></strong> to <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/z7phfljd' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/z7phfljd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch 1 train begin 2024-12-03 23:31:18.697146\n",
            "loss: 0.390625, time: 2024-12-03 23:31:19.022726, step: 1\n",
            "loss: 0.388671875, time: 2024-12-03 23:31:19.615637, step: 2\n",
            "loss: 0.404296875, time: 2024-12-03 23:31:20.206165, step: 3\n",
            "loss: 0.423828125, time: 2024-12-03 23:31:20.796784, step: 4\n",
            "loss: 0.416015625, time: 2024-12-03 23:31:21.387397, step: 5\n",
            "loss: 0.396484375, time: 2024-12-03 23:31:21.977794, step: 6\n",
            "loss: 0.408203125, time: 2024-12-03 23:31:22.567942, step: 7\n",
            "loss: 0.46484375, time: 2024-12-03 23:31:23.158730, step: 8\n",
            "loss: 0.380859375, time: 2024-12-03 23:31:23.749491, step: 9\n",
            "loss: 0.375, time: 2024-12-03 23:31:24.340133, step: 10\n",
            "loss: 0.400390625, time: 2024-12-03 23:31:24.930283, step: 11\n",
            "loss: 0.40625, time: 2024-12-03 23:31:25.521231, step: 12\n",
            "loss: 0.404296875, time: 2024-12-03 23:31:26.111397, step: 13\n",
            "loss: 0.40625, time: 2024-12-03 23:31:26.701678, step: 14\n",
            "loss: 0.40625, time: 2024-12-03 23:31:27.292442, step: 15\n",
            "loss: 0.388671875, time: 2024-12-03 23:31:27.882801, step: 16\n",
            "loss: 0.404296875, time: 2024-12-03 23:31:28.473484, step: 17\n",
            "loss: 0.388671875, time: 2024-12-03 23:31:29.064386, step: 18\n",
            "loss: 0.39453125, time: 2024-12-03 23:31:29.654921, step: 19\n",
            "loss: 0.439453125, time: 2024-12-03 23:31:30.245476, step: 20\n",
            "----- Time -> 2024-12-03 23:31:53.867066 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.412109375, time: 2024-12-03 23:31:54.149211, step: 21\n",
            "loss: 0.380859375, time: 2024-12-03 23:31:54.739564, step: 22\n",
            "loss: 0.412109375, time: 2024-12-03 23:31:55.330173, step: 23\n",
            "loss: 0.41796875, time: 2024-12-03 23:31:55.920273, step: 24\n",
            "loss: 0.40625, time: 2024-12-03 23:31:56.510421, step: 25\n",
            "loss: 0.41796875, time: 2024-12-03 23:31:57.101125, step: 26\n",
            "loss: 0.44921875, time: 2024-12-03 23:31:57.691367, step: 27\n",
            "loss: 0.416015625, time: 2024-12-03 23:31:58.281626, step: 28\n",
            "loss: 0.3828125, time: 2024-12-03 23:31:58.872339, step: 29\n",
            "loss: 0.421875, time: 2024-12-03 23:31:59.462542, step: 30\n",
            "loss: 0.41015625, time: 2024-12-03 23:32:00.052669, step: 31\n",
            "loss: 0.396484375, time: 2024-12-03 23:32:00.643278, step: 32\n",
            "loss: 0.412109375, time: 2024-12-03 23:32:01.233690, step: 33\n",
            "loss: 0.416015625, time: 2024-12-03 23:32:01.824228, step: 34\n",
            "loss: 0.384765625, time: 2024-12-03 23:32:02.414658, step: 35\n",
            "loss: 0.388671875, time: 2024-12-03 23:32:03.004894, step: 36\n",
            "loss: 0.40234375, time: 2024-12-03 23:32:03.595530, step: 37\n",
            "loss: 0.435546875, time: 2024-12-03 23:32:04.185703, step: 38\n",
            "loss: 0.39453125, time: 2024-12-03 23:32:04.775621, step: 39\n",
            "loss: 0.45703125, time: 2024-12-03 23:32:05.365793, step: 40\n",
            "----- Time -> 2024-12-03 23:32:29.026007 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.412109375, time: 2024-12-03 23:32:29.309626, step: 41\n",
            "loss: 0.37890625, time: 2024-12-03 23:32:29.899480, step: 42\n",
            "loss: 0.37890625, time: 2024-12-03 23:32:30.490219, step: 43\n",
            "loss: 0.390625, time: 2024-12-03 23:32:31.080082, step: 44\n",
            "loss: 0.37890625, time: 2024-12-03 23:32:31.670596, step: 45\n",
            "loss: 0.3984375, time: 2024-12-03 23:32:32.261167, step: 46\n",
            "loss: 0.392578125, time: 2024-12-03 23:32:32.851364, step: 47\n",
            "loss: 0.373046875, time: 2024-12-03 23:32:33.441311, step: 48\n",
            "loss: 0.392578125, time: 2024-12-03 23:32:34.031449, step: 49\n",
            "loss: 0.400390625, time: 2024-12-03 23:32:34.621793, step: 50\n",
            "loss: 0.384765625, time: 2024-12-03 23:32:35.212049, step: 51\n",
            "loss: 0.373046875, time: 2024-12-03 23:32:35.802171, step: 52\n",
            "loss: 0.388671875, time: 2024-12-03 23:32:36.392203, step: 53\n",
            "loss: 0.41796875, time: 2024-12-03 23:32:36.982489, step: 54\n",
            "loss: 0.46484375, time: 2024-12-03 23:32:37.572498, step: 55\n",
            "loss: 0.3984375, time: 2024-12-03 23:32:38.162199, step: 56\n",
            "loss: 0.38671875, time: 2024-12-03 23:32:38.752395, step: 57\n",
            "loss: 0.421875, time: 2024-12-03 23:32:39.342531, step: 58\n",
            "loss: 0.4609375, time: 2024-12-03 23:32:39.932698, step: 59\n",
            "loss: 0.40625, time: 2024-12-03 23:32:40.522947, step: 60\n",
            "----- Time -> 2024-12-03 23:33:03.891576 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-03 23:33:04.164940, step: 61\n",
            "loss: 0.37890625, time: 2024-12-03 23:33:04.755038, step: 62\n",
            "loss: 0.40234375, time: 2024-12-03 23:33:05.345221, step: 63\n",
            "loss: 0.404296875, time: 2024-12-03 23:33:05.935108, step: 64\n",
            "loss: 0.3828125, time: 2024-12-03 23:33:06.525022, step: 65\n",
            "loss: 0.4296875, time: 2024-12-03 23:33:07.115129, step: 66\n",
            "loss: 0.416015625, time: 2024-12-03 23:33:07.705164, step: 67\n",
            "loss: 0.42578125, time: 2024-12-03 23:33:08.295475, step: 68\n",
            "loss: 0.400390625, time: 2024-12-03 23:33:08.885455, step: 69\n",
            "loss: 0.3828125, time: 2024-12-03 23:33:09.475911, step: 70\n",
            "loss: 0.380859375, time: 2024-12-03 23:33:10.066372, step: 71\n",
            "loss: 0.408203125, time: 2024-12-03 23:33:10.656233, step: 72\n",
            "loss: 0.396484375, time: 2024-12-03 23:33:11.246836, step: 73\n",
            "loss: 0.43359375, time: 2024-12-03 23:33:11.836860, step: 74\n",
            "loss: 0.3984375, time: 2024-12-03 23:33:12.427099, step: 75\n",
            "loss: 0.416015625, time: 2024-12-03 23:33:13.017174, step: 76\n",
            "loss: 0.41015625, time: 2024-12-03 23:33:13.607556, step: 77\n",
            "loss: 0.41015625, time: 2024-12-03 23:33:14.197880, step: 78\n",
            "loss: 0.380859375, time: 2024-12-03 23:33:14.788223, step: 79\n",
            "loss: 0.390625, time: 2024-12-03 23:33:15.378162, step: 80\n",
            "----- Time -> 2024-12-03 23:33:39.058473 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.380859375, time: 2024-12-03 23:33:39.332685, step: 81\n",
            "loss: 0.384765625, time: 2024-12-03 23:33:39.922869, step: 82\n",
            "loss: 0.4609375, time: 2024-12-03 23:33:40.513024, step: 83\n",
            "loss: 0.39453125, time: 2024-12-03 23:33:41.103265, step: 84\n",
            "loss: 0.40234375, time: 2024-12-03 23:33:41.693356, step: 85\n",
            "loss: 0.3984375, time: 2024-12-03 23:33:42.284193, step: 86\n",
            "loss: 0.3984375, time: 2024-12-03 23:33:42.874532, step: 87\n",
            "loss: 0.380859375, time: 2024-12-03 23:33:43.464651, step: 88\n",
            "loss: 0.384765625, time: 2024-12-03 23:33:44.055081, step: 89\n",
            "loss: 0.3984375, time: 2024-12-03 23:33:44.644915, step: 90\n",
            "loss: 0.384765625, time: 2024-12-03 23:33:45.235268, step: 91\n",
            "loss: 0.39453125, time: 2024-12-03 23:33:45.825778, step: 92\n",
            "loss: 0.3828125, time: 2024-12-03 23:33:46.415945, step: 93\n",
            "loss: 0.39453125, time: 2024-12-03 23:33:47.005905, step: 94\n",
            "loss: 0.380859375, time: 2024-12-03 23:33:47.596527, step: 95\n",
            "loss: 0.38671875, time: 2024-12-03 23:33:48.186186, step: 96\n",
            "loss: 0.38671875, time: 2024-12-03 23:33:48.776572, step: 97\n",
            "loss: 0.412109375, time: 2024-12-03 23:33:49.366578, step: 98\n",
            "loss: 0.3984375, time: 2024-12-03 23:33:49.956627, step: 99\n",
            "loss: 0.392578125, time: 2024-12-03 23:33:50.547212, step: 100\n",
            "----- Time -> 2024-12-03 23:34:14.029440 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.416015625, time: 2024-12-03 23:34:14.304768, step: 101\n",
            "loss: 0.392578125, time: 2024-12-03 23:34:14.895931, step: 102\n",
            "loss: 0.396484375, time: 2024-12-03 23:34:15.486195, step: 103\n",
            "loss: 0.37890625, time: 2024-12-03 23:34:16.076618, step: 104\n",
            "loss: 0.41015625, time: 2024-12-03 23:34:16.666956, step: 105\n",
            "loss: 0.38671875, time: 2024-12-03 23:34:17.257201, step: 106\n",
            "loss: 0.408203125, time: 2024-12-03 23:34:17.847890, step: 107\n",
            "loss: 0.4140625, time: 2024-12-03 23:34:18.438109, step: 108\n",
            "loss: 0.41796875, time: 2024-12-03 23:34:19.028476, step: 109\n",
            "loss: 0.443359375, time: 2024-12-03 23:34:19.619152, step: 110\n",
            "loss: 0.38671875, time: 2024-12-03 23:34:20.209480, step: 111\n",
            "loss: 0.396484375, time: 2024-12-03 23:34:20.800695, step: 112\n",
            "loss: 0.3828125, time: 2024-12-03 23:34:21.391339, step: 113\n",
            "loss: 0.392578125, time: 2024-12-03 23:34:21.981681, step: 114\n",
            "loss: 0.421875, time: 2024-12-03 23:34:22.571908, step: 115\n",
            "loss: 0.421875, time: 2024-12-03 23:34:23.162383, step: 116\n",
            "loss: 0.412109375, time: 2024-12-03 23:34:23.752914, step: 117\n",
            "loss: 0.3828125, time: 2024-12-03 23:34:24.343600, step: 118\n",
            "loss: 0.404296875, time: 2024-12-03 23:34:24.933725, step: 119\n",
            "loss: 0.423828125, time: 2024-12-03 23:34:25.523724, step: 120\n",
            "----- Time -> 2024-12-03 23:34:49.416645 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.412109375, time: 2024-12-03 23:34:49.691911, step: 121\n",
            "loss: 0.396484375, time: 2024-12-03 23:34:50.282213, step: 122\n",
            "loss: 0.396484375, time: 2024-12-03 23:34:50.872807, step: 123\n",
            "loss: 0.451171875, time: 2024-12-03 23:34:51.462868, step: 124\n",
            "loss: 0.3984375, time: 2024-12-03 23:34:52.052983, step: 125\n",
            "loss: 0.396484375, time: 2024-12-03 23:34:52.643378, step: 126\n",
            "loss: 0.3984375, time: 2024-12-03 23:34:53.233647, step: 127\n",
            "loss: 0.373046875, time: 2024-12-03 23:34:53.824396, step: 128\n",
            "loss: 0.41015625, time: 2024-12-03 23:34:54.414630, step: 129\n",
            "loss: 0.361328125, time: 2024-12-03 23:34:55.005305, step: 130\n",
            "loss: 0.39453125, time: 2024-12-03 23:34:55.595489, step: 131\n",
            "loss: 0.416015625, time: 2024-12-03 23:34:56.185581, step: 132\n",
            "loss: 0.388671875, time: 2024-12-03 23:34:56.776487, step: 133\n",
            "loss: 0.421875, time: 2024-12-03 23:34:57.366620, step: 134\n",
            "loss: 0.384765625, time: 2024-12-03 23:34:57.956969, step: 135\n",
            "loss: 0.412109375, time: 2024-12-03 23:34:58.547323, step: 136\n",
            "loss: 0.400390625, time: 2024-12-03 23:34:59.137565, step: 137\n",
            "loss: 0.412109375, time: 2024-12-03 23:34:59.728801, step: 138\n",
            "loss: 0.400390625, time: 2024-12-03 23:35:00.319374, step: 139\n",
            "loss: 0.3828125, time: 2024-12-03 23:35:00.909759, step: 140\n",
            "----- Time -> 2024-12-03 23:35:24.592242 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.416015625, time: 2024-12-03 23:35:24.868222, step: 141\n",
            "loss: 0.392578125, time: 2024-12-03 23:35:25.458557, step: 142\n",
            "loss: 0.380859375, time: 2024-12-03 23:35:26.049071, step: 143\n",
            "loss: 0.400390625, time: 2024-12-03 23:35:26.638984, step: 144\n",
            "loss: 0.388671875, time: 2024-12-03 23:35:27.228642, step: 145\n",
            "loss: 0.390625, time: 2024-12-03 23:35:27.819653, step: 146\n",
            "loss: 0.419921875, time: 2024-12-03 23:35:28.410176, step: 147\n",
            "loss: 0.369140625, time: 2024-12-03 23:35:29.000249, step: 148\n",
            "loss: 0.369140625, time: 2024-12-03 23:35:29.590208, step: 149\n",
            "loss: 0.39453125, time: 2024-12-03 23:35:30.180725, step: 150\n",
            "loss: 0.3828125, time: 2024-12-03 23:35:30.771329, step: 151\n",
            "loss: 0.41015625, time: 2024-12-03 23:35:31.361880, step: 152\n",
            "loss: 0.435546875, time: 2024-12-03 23:35:31.952904, step: 153\n",
            "loss: 0.41796875, time: 2024-12-03 23:35:32.542618, step: 154\n",
            "loss: 0.404296875, time: 2024-12-03 23:35:33.132708, step: 155\n",
            "loss: 0.396484375, time: 2024-12-03 23:35:33.724053, step: 156\n",
            "loss: 0.416015625, time: 2024-12-03 23:35:34.314195, step: 157\n",
            "loss: 0.39453125, time: 2024-12-03 23:35:34.904229, step: 158\n",
            "loss: 0.408203125, time: 2024-12-03 23:35:35.494752, step: 159\n",
            "loss: 0.390625, time: 2024-12-03 23:35:36.084600, step: 160\n",
            "----- Time -> 2024-12-03 23:35:59.713340 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.38671875, time: 2024-12-03 23:35:59.999976, step: 161\n",
            "loss: 0.396484375, time: 2024-12-03 23:36:00.590635, step: 162\n",
            "loss: 0.41796875, time: 2024-12-03 23:36:01.180695, step: 163\n",
            "loss: 0.40234375, time: 2024-12-03 23:36:01.770800, step: 164\n",
            "loss: 0.375, time: 2024-12-03 23:36:02.360890, step: 165\n",
            "loss: 0.3984375, time: 2024-12-03 23:36:02.950542, step: 166\n",
            "loss: 0.3984375, time: 2024-12-03 23:36:03.540272, step: 167\n",
            "loss: 0.388671875, time: 2024-12-03 23:36:04.129995, step: 168\n",
            "loss: 0.390625, time: 2024-12-03 23:36:04.720619, step: 169\n",
            "loss: 0.455078125, time: 2024-12-03 23:36:05.310961, step: 170\n",
            "loss: 0.412109375, time: 2024-12-03 23:36:05.900683, step: 171\n",
            "loss: 0.384765625, time: 2024-12-03 23:36:06.490891, step: 172\n",
            "loss: 0.3828125, time: 2024-12-03 23:36:07.080857, step: 173\n",
            "loss: 0.408203125, time: 2024-12-03 23:36:07.670854, step: 174\n",
            "loss: 0.3984375, time: 2024-12-03 23:36:08.262046, step: 175\n",
            "loss: 0.400390625, time: 2024-12-03 23:36:08.852340, step: 176\n",
            "loss: 0.3984375, time: 2024-12-03 23:36:09.442466, step: 177\n",
            "loss: 0.396484375, time: 2024-12-03 23:36:10.033098, step: 178\n",
            "loss: 0.3984375, time: 2024-12-03 23:36:10.623738, step: 179\n",
            "loss: 0.376953125, time: 2024-12-03 23:36:11.213912, step: 180\n",
            "----- Time -> 2024-12-03 23:36:35.074828 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-03 23:36:35.366281, step: 181\n",
            "loss: 0.3671875, time: 2024-12-03 23:36:35.956936, step: 182\n",
            "loss: 0.3828125, time: 2024-12-03 23:36:36.547069, step: 183\n",
            "loss: 0.416015625, time: 2024-12-03 23:36:37.137150, step: 184\n",
            "loss: 0.396484375, time: 2024-12-03 23:36:37.727108, step: 185\n",
            "loss: 0.3984375, time: 2024-12-03 23:36:38.317130, step: 186\n",
            "loss: 0.416015625, time: 2024-12-03 23:36:38.907169, step: 187\n",
            "loss: 0.419921875, time: 2024-12-03 23:36:39.497246, step: 188\n",
            "loss: 0.3828125, time: 2024-12-03 23:36:40.087583, step: 189\n",
            "loss: 0.404296875, time: 2024-12-03 23:36:40.677397, step: 190\n",
            "loss: 0.3984375, time: 2024-12-03 23:36:41.267774, step: 191\n",
            "loss: 0.421875, time: 2024-12-03 23:36:41.857959, step: 192\n",
            "loss: 0.4296875, time: 2024-12-03 23:36:42.448053, step: 193\n",
            "loss: 0.3828125, time: 2024-12-03 23:36:43.037735, step: 194\n",
            "loss: 0.390625, time: 2024-12-03 23:36:43.628030, step: 195\n",
            "loss: 0.44921875, time: 2024-12-03 23:36:44.218037, step: 196\n",
            "loss: 0.3984375, time: 2024-12-03 23:36:44.809047, step: 197\n",
            "loss: 0.37890625, time: 2024-12-03 23:36:45.399361, step: 198\n",
            "loss: 0.40234375, time: 2024-12-03 23:36:45.989590, step: 199\n",
            "loss: 0.388671875, time: 2024-12-03 23:36:46.580847, step: 200\n",
            "----- Time -> 2024-12-03 23:37:09.823454 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-03 23:37:10.092066, step: 201\n",
            "loss: 0.37890625, time: 2024-12-03 23:37:10.682557, step: 202\n",
            "loss: 0.392578125, time: 2024-12-03 23:37:11.272461, step: 203\n",
            "loss: 0.423828125, time: 2024-12-03 23:37:11.862626, step: 204\n",
            "loss: 0.3984375, time: 2024-12-03 23:37:12.452734, step: 205\n",
            "loss: 0.384765625, time: 2024-12-03 23:37:13.042726, step: 206\n",
            "loss: 0.375, time: 2024-12-03 23:37:13.632796, step: 207\n",
            "loss: 0.42578125, time: 2024-12-03 23:37:14.223234, step: 208\n",
            "loss: 0.373046875, time: 2024-12-03 23:37:14.814509, step: 209\n",
            "loss: 0.3984375, time: 2024-12-03 23:37:15.405182, step: 210\n",
            "loss: 0.390625, time: 2024-12-03 23:37:15.995213, step: 211\n",
            "loss: 0.390625, time: 2024-12-03 23:37:16.585083, step: 212\n",
            "loss: 0.380859375, time: 2024-12-03 23:37:17.174633, step: 213\n",
            "loss: 0.40234375, time: 2024-12-03 23:37:17.764951, step: 214\n",
            "loss: 0.3828125, time: 2024-12-03 23:37:18.355125, step: 215\n",
            "loss: 0.388671875, time: 2024-12-03 23:37:18.945358, step: 216\n",
            "loss: 0.390625, time: 2024-12-03 23:37:19.535672, step: 217\n",
            "loss: 0.38671875, time: 2024-12-03 23:37:20.125524, step: 218\n",
            "loss: 0.380859375, time: 2024-12-03 23:37:20.715437, step: 219\n",
            "loss: 0.404296875, time: 2024-12-03 23:37:21.305835, step: 220\n",
            "----- Time -> 2024-12-03 23:37:44.711220 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.388671875, time: 2024-12-03 23:37:44.990996, step: 221\n",
            "loss: 0.404296875, time: 2024-12-03 23:37:45.581049, step: 222\n",
            "loss: 0.373046875, time: 2024-12-03 23:37:46.170981, step: 223\n",
            "loss: 0.41796875, time: 2024-12-03 23:37:46.761886, step: 224\n",
            "loss: 0.404296875, time: 2024-12-03 23:37:47.352367, step: 225\n",
            "loss: 0.40625, time: 2024-12-03 23:37:47.942662, step: 226\n",
            "loss: 0.40625, time: 2024-12-03 23:37:48.532691, step: 227\n",
            "loss: 0.39453125, time: 2024-12-03 23:37:49.122677, step: 228\n",
            "loss: 0.416015625, time: 2024-12-03 23:37:49.712695, step: 229\n",
            "loss: 0.39453125, time: 2024-12-03 23:37:50.303123, step: 230\n",
            "loss: 0.396484375, time: 2024-12-03 23:37:50.893607, step: 231\n",
            "loss: 0.470703125, time: 2024-12-03 23:37:51.484520, step: 232\n",
            "loss: 0.40234375, time: 2024-12-03 23:37:52.075825, step: 233\n",
            "loss: 0.40625, time: 2024-12-03 23:37:52.665659, step: 234\n",
            "loss: 0.380859375, time: 2024-12-03 23:37:53.255487, step: 235\n",
            "loss: 0.3828125, time: 2024-12-03 23:37:53.846181, step: 236\n",
            "loss: 0.375, time: 2024-12-03 23:37:54.436482, step: 237\n",
            "loss: 0.41796875, time: 2024-12-03 23:37:55.026298, step: 238\n",
            "loss: 0.396484375, time: 2024-12-03 23:37:55.616740, step: 239\n",
            "loss: 0.427734375, time: 2024-12-03 23:37:56.206922, step: 240\n",
            "----- Time -> 2024-12-03 23:38:19.525999 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-03 23:38:19.801282, step: 241\n",
            "loss: 0.41796875, time: 2024-12-03 23:38:20.391624, step: 242\n",
            "loss: 0.392578125, time: 2024-12-03 23:38:20.981740, step: 243\n",
            "loss: 0.408203125, time: 2024-12-03 23:38:21.571710, step: 244\n",
            "loss: 0.40234375, time: 2024-12-03 23:38:22.162126, step: 245\n",
            "loss: 0.412109375, time: 2024-12-03 23:38:22.752034, step: 246\n",
            "loss: 0.40625, time: 2024-12-03 23:38:23.342101, step: 247\n",
            "loss: 0.3984375, time: 2024-12-03 23:38:23.932550, step: 248\n",
            "loss: 0.40625, time: 2024-12-03 23:38:24.522662, step: 249\n",
            "loss: 0.39453125, time: 2024-12-03 23:38:25.112866, step: 250\n",
            "loss: 0.376953125, time: 2024-12-03 23:38:25.703737, step: 251\n",
            "loss: 0.357421875, time: 2024-12-03 23:38:26.294289, step: 252\n",
            "loss: 0.38671875, time: 2024-12-03 23:38:26.884573, step: 253\n",
            "loss: 0.388671875, time: 2024-12-03 23:38:27.474610, step: 254\n",
            "loss: 0.400390625, time: 2024-12-03 23:38:28.064156, step: 255\n",
            "loss: 0.400390625, time: 2024-12-03 23:38:28.653950, step: 256\n",
            "loss: 0.419921875, time: 2024-12-03 23:38:29.244512, step: 257\n",
            "loss: 0.38671875, time: 2024-12-03 23:38:29.834266, step: 258\n",
            "loss: 0.388671875, time: 2024-12-03 23:38:30.424194, step: 259\n",
            "loss: 0.412109375, time: 2024-12-03 23:38:31.014694, step: 260\n",
            "----- Time -> 2024-12-03 23:38:54.511225 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.373046875, time: 2024-12-03 23:38:54.785175, step: 261\n",
            "loss: 0.408203125, time: 2024-12-03 23:38:55.375137, step: 262\n",
            "loss: 0.37890625, time: 2024-12-03 23:38:55.964639, step: 263\n",
            "loss: 0.384765625, time: 2024-12-03 23:38:56.554482, step: 264\n",
            "loss: 0.39453125, time: 2024-12-03 23:38:57.144551, step: 265\n",
            "loss: 0.38671875, time: 2024-12-03 23:38:57.734881, step: 266\n",
            "loss: 0.421875, time: 2024-12-03 23:38:58.325706, step: 267\n",
            "loss: 0.404296875, time: 2024-12-03 23:38:58.915496, step: 268\n",
            "loss: 0.38671875, time: 2024-12-03 23:38:59.505335, step: 269\n",
            "loss: 0.4140625, time: 2024-12-03 23:39:00.095517, step: 270\n",
            "loss: 0.4140625, time: 2024-12-03 23:39:00.685503, step: 271\n",
            "loss: 0.388671875, time: 2024-12-03 23:39:01.275674, step: 272\n",
            "loss: 0.38671875, time: 2024-12-03 23:39:01.866430, step: 273\n",
            "loss: 0.375, time: 2024-12-03 23:39:02.456835, step: 274\n",
            "loss: 0.40234375, time: 2024-12-03 23:39:03.047545, step: 275\n",
            "loss: 0.3828125, time: 2024-12-03 23:39:03.637995, step: 276\n",
            "loss: 0.439453125, time: 2024-12-03 23:39:04.227757, step: 277\n",
            "loss: 0.3828125, time: 2024-12-03 23:39:04.817509, step: 278\n",
            "loss: 0.373046875, time: 2024-12-03 23:39:05.408037, step: 279\n",
            "loss: 0.38671875, time: 2024-12-03 23:39:05.997536, step: 280\n",
            "----- Time -> 2024-12-03 23:39:29.683424 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.38671875, time: 2024-12-03 23:39:29.959339, step: 281\n",
            "loss: 0.36328125, time: 2024-12-03 23:39:30.550350, step: 282\n",
            "loss: 0.388671875, time: 2024-12-03 23:39:31.140629, step: 283\n",
            "loss: 0.3984375, time: 2024-12-03 23:39:31.730821, step: 284\n",
            "loss: 0.396484375, time: 2024-12-03 23:39:32.321426, step: 285\n",
            "loss: 0.404296875, time: 2024-12-03 23:39:32.911385, step: 286\n",
            "loss: 0.41796875, time: 2024-12-03 23:39:33.501136, step: 287\n",
            "loss: 0.40625, time: 2024-12-03 23:39:34.091344, step: 288\n",
            "loss: 0.404296875, time: 2024-12-03 23:39:34.681740, step: 289\n",
            "loss: 0.373046875, time: 2024-12-03 23:39:35.271602, step: 290\n",
            "loss: 0.419921875, time: 2024-12-03 23:39:35.861902, step: 291\n",
            "loss: 0.373046875, time: 2024-12-03 23:39:36.451736, step: 292\n",
            "loss: 0.400390625, time: 2024-12-03 23:39:37.041689, step: 293\n",
            "loss: 0.400390625, time: 2024-12-03 23:39:37.632138, step: 294\n",
            "loss: 0.400390625, time: 2024-12-03 23:39:38.222231, step: 295\n",
            "loss: 0.404296875, time: 2024-12-03 23:39:38.812791, step: 296\n",
            "loss: 0.40625, time: 2024-12-03 23:39:39.403212, step: 297\n",
            "loss: 0.4296875, time: 2024-12-03 23:39:39.992841, step: 298\n",
            "loss: 0.38671875, time: 2024-12-03 23:39:40.584271, step: 299\n",
            "loss: 0.427734375, time: 2024-12-03 23:39:41.175051, step: 300\n",
            "----- Time -> 2024-12-03 23:40:04.829775 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.404296875, time: 2024-12-03 23:40:05.112792, step: 301\n",
            "loss: 0.375, time: 2024-12-03 23:40:05.703037, step: 302\n",
            "loss: 0.37109375, time: 2024-12-03 23:40:06.293145, step: 303\n",
            "loss: 0.400390625, time: 2024-12-03 23:40:06.883144, step: 304\n",
            "loss: 0.388671875, time: 2024-12-03 23:40:07.472910, step: 305\n",
            "loss: 0.41796875, time: 2024-12-03 23:40:08.062575, step: 306\n",
            "loss: 0.396484375, time: 2024-12-03 23:40:08.652593, step: 307\n",
            "loss: 0.404296875, time: 2024-12-03 23:40:09.242564, step: 308\n",
            "loss: 0.3828125, time: 2024-12-03 23:40:09.832806, step: 309\n",
            "loss: 0.37890625, time: 2024-12-03 23:40:10.423102, step: 310\n",
            "loss: 0.408203125, time: 2024-12-03 23:40:11.012669, step: 311\n",
            "loss: 0.423828125, time: 2024-12-03 23:40:11.602997, step: 312\n",
            "loss: 0.38671875, time: 2024-12-03 23:40:12.193062, step: 313\n",
            "loss: 0.40625, time: 2024-12-03 23:40:12.783249, step: 314\n",
            "loss: 0.390625, time: 2024-12-03 23:40:13.373828, step: 315\n",
            "loss: 0.41796875, time: 2024-12-03 23:40:13.963977, step: 316\n",
            "loss: 0.369140625, time: 2024-12-03 23:40:14.554014, step: 317\n",
            "loss: 0.3828125, time: 2024-12-03 23:40:15.144371, step: 318\n",
            "loss: 0.388671875, time: 2024-12-03 23:40:15.734557, step: 319\n",
            "loss: 0.4296875, time: 2024-12-03 23:40:16.324857, step: 320\n",
            "----- Time -> 2024-12-03 23:40:40.057624 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.404296875, time: 2024-12-03 23:40:40.332657, step: 321\n",
            "loss: 0.41015625, time: 2024-12-03 23:40:40.922626, step: 322\n",
            "loss: 0.396484375, time: 2024-12-03 23:40:41.513295, step: 323\n",
            "loss: 0.427734375, time: 2024-12-03 23:40:42.103287, step: 324\n",
            "loss: 0.388671875, time: 2024-12-03 23:40:42.693430, step: 325\n",
            "loss: 0.412109375, time: 2024-12-03 23:40:43.283850, step: 326\n",
            "loss: 0.39453125, time: 2024-12-03 23:40:43.873903, step: 327\n",
            "loss: 0.416015625, time: 2024-12-03 23:40:44.463955, step: 328\n",
            "loss: 0.41015625, time: 2024-12-03 23:40:45.053605, step: 329\n",
            "loss: 0.408203125, time: 2024-12-03 23:40:45.643891, step: 330\n",
            "loss: 0.3984375, time: 2024-12-03 23:40:46.233492, step: 331\n",
            "loss: 0.392578125, time: 2024-12-03 23:40:46.823219, step: 332\n",
            "loss: 0.369140625, time: 2024-12-03 23:40:47.413533, step: 333\n",
            "loss: 0.416015625, time: 2024-12-03 23:40:48.002920, step: 334\n",
            "loss: 0.384765625, time: 2024-12-03 23:40:48.592745, step: 335\n",
            "loss: 0.408203125, time: 2024-12-03 23:40:49.183004, step: 336\n",
            "loss: 0.37109375, time: 2024-12-03 23:40:49.772564, step: 337\n",
            "loss: 0.41015625, time: 2024-12-03 23:40:50.362588, step: 338\n",
            "loss: 0.357421875, time: 2024-12-03 23:40:50.952636, step: 339\n",
            "loss: 0.404296875, time: 2024-12-03 23:40:51.542882, step: 340\n",
            "----- Time -> 2024-12-03 23:41:15.088890 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.38671875, time: 2024-12-03 23:41:15.359072, step: 341\n",
            "loss: 0.384765625, time: 2024-12-03 23:41:15.949056, step: 342\n",
            "loss: 0.390625, time: 2024-12-03 23:41:16.538625, step: 343\n",
            "loss: 0.3984375, time: 2024-12-03 23:41:17.128349, step: 344\n",
            "loss: 0.396484375, time: 2024-12-03 23:41:17.718213, step: 345\n",
            "loss: 0.37890625, time: 2024-12-03 23:41:18.308488, step: 346\n",
            "loss: 0.384765625, time: 2024-12-03 23:41:18.898732, step: 347\n",
            "loss: 0.3828125, time: 2024-12-03 23:41:19.488455, step: 348\n",
            "loss: 0.39453125, time: 2024-12-03 23:41:20.078348, step: 349\n",
            "loss: 0.37109375, time: 2024-12-03 23:41:20.668475, step: 350\n",
            "loss: 0.400390625, time: 2024-12-03 23:41:21.258545, step: 351\n",
            "loss: 0.39453125, time: 2024-12-03 23:41:21.848872, step: 352\n",
            "loss: 0.37890625, time: 2024-12-03 23:41:22.438549, step: 353\n",
            "loss: 0.427734375, time: 2024-12-03 23:41:23.028046, step: 354\n",
            "loss: 0.392578125, time: 2024-12-03 23:41:23.618124, step: 355\n",
            "loss: 0.376953125, time: 2024-12-03 23:41:24.207724, step: 356\n",
            "loss: 0.41796875, time: 2024-12-03 23:41:24.798249, step: 357\n",
            "loss: 0.421875, time: 2024-12-03 23:41:25.388047, step: 358\n",
            "loss: 0.42578125, time: 2024-12-03 23:41:25.977889, step: 359\n",
            "loss: 0.3828125, time: 2024-12-03 23:41:26.567587, step: 360\n",
            "----- Time -> 2024-12-03 23:41:50.192661 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.427734375, time: 2024-12-03 23:41:50.474129, step: 361\n",
            "loss: 0.396484375, time: 2024-12-03 23:41:51.064124, step: 362\n",
            "loss: 0.380859375, time: 2024-12-03 23:41:51.653884, step: 363\n",
            "loss: 0.404296875, time: 2024-12-03 23:41:52.243457, step: 364\n",
            "loss: 0.392578125, time: 2024-12-03 23:41:52.833337, step: 365\n",
            "loss: 0.400390625, time: 2024-12-03 23:41:53.423317, step: 366\n",
            "loss: 0.373046875, time: 2024-12-03 23:41:54.012915, step: 367\n",
            "loss: 0.42578125, time: 2024-12-03 23:41:54.603217, step: 368\n",
            "loss: 0.416015625, time: 2024-12-03 23:41:55.192816, step: 369\n",
            "loss: 0.396484375, time: 2024-12-03 23:41:55.782779, step: 370\n",
            "loss: 0.400390625, time: 2024-12-03 23:41:56.373582, step: 371\n",
            "loss: 0.37109375, time: 2024-12-03 23:41:56.963238, step: 372\n",
            "loss: 0.380859375, time: 2024-12-03 23:41:57.553954, step: 373\n",
            "loss: 0.37890625, time: 2024-12-03 23:41:58.144361, step: 374\n",
            "loss: 0.38671875, time: 2024-12-03 23:41:58.734068, step: 375\n",
            "loss: 0.40625, time: 2024-12-03 23:41:59.324105, step: 376\n",
            "loss: 0.369140625, time: 2024-12-03 23:41:59.914633, step: 377\n",
            "loss: 0.404296875, time: 2024-12-03 23:42:00.504531, step: 378\n",
            "loss: 0.38671875, time: 2024-12-03 23:42:01.094948, step: 379\n",
            "loss: 0.390625, time: 2024-12-03 23:42:01.685077, step: 380\n",
            "----- Time -> 2024-12-03 23:42:25.405091 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40234375, time: 2024-12-03 23:42:25.683765, step: 381\n",
            "loss: 0.4140625, time: 2024-12-03 23:42:26.274251, step: 382\n",
            "loss: 0.3984375, time: 2024-12-03 23:42:26.863839, step: 383\n",
            "loss: 0.380859375, time: 2024-12-03 23:42:27.453733, step: 384\n",
            "loss: 0.39453125, time: 2024-12-03 23:42:28.043244, step: 385\n",
            "loss: 0.388671875, time: 2024-12-03 23:42:28.633223, step: 386\n",
            "loss: 0.400390625, time: 2024-12-03 23:42:29.222897, step: 387\n",
            "loss: 0.37890625, time: 2024-12-03 23:42:29.812647, step: 388\n",
            "loss: 0.423828125, time: 2024-12-03 23:42:30.402468, step: 389\n",
            "loss: 0.384765625, time: 2024-12-03 23:42:30.992470, step: 390\n",
            "loss: 0.384765625, time: 2024-12-03 23:42:31.582284, step: 391\n",
            "loss: 0.3984375, time: 2024-12-03 23:42:32.171891, step: 392\n",
            "loss: 0.3984375, time: 2024-12-03 23:42:32.762193, step: 393\n",
            "loss: 0.423828125, time: 2024-12-03 23:42:33.352841, step: 394\n",
            "loss: 0.376953125, time: 2024-12-03 23:42:33.942530, step: 395\n",
            "loss: 0.431640625, time: 2024-12-03 23:42:34.890547, step: 396\n",
            "loss: 0.41015625, time: 2024-12-03 23:42:35.480905, step: 397\n",
            "loss: 0.3828125, time: 2024-12-03 23:42:36.071135, step: 398\n",
            "loss: 0.390625, time: 2024-12-03 23:42:36.660995, step: 399\n",
            "loss: 0.3984375, time: 2024-12-03 23:42:37.250466, step: 400\n",
            "----- Time -> 2024-12-03 23:43:00.850796 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.39453125, time: 2024-12-03 23:43:01.120963, step: 401\n",
            "loss: 0.39453125, time: 2024-12-03 23:43:01.711198, step: 402\n",
            "loss: 0.4140625, time: 2024-12-03 23:43:02.301364, step: 403\n",
            "loss: 0.3984375, time: 2024-12-03 23:43:02.891457, step: 404\n",
            "loss: 0.390625, time: 2024-12-03 23:43:03.481505, step: 405\n",
            "loss: 0.369140625, time: 2024-12-03 23:43:04.071581, step: 406\n",
            "loss: 0.416015625, time: 2024-12-03 23:43:04.661432, step: 407\n",
            "loss: 0.400390625, time: 2024-12-03 23:43:05.251582, step: 408\n",
            "loss: 0.373046875, time: 2024-12-03 23:43:05.841709, step: 409\n",
            "loss: 0.41015625, time: 2024-12-03 23:43:06.431390, step: 410\n",
            "loss: 0.408203125, time: 2024-12-03 23:43:07.021363, step: 411\n",
            "loss: 0.376953125, time: 2024-12-03 23:43:07.611039, step: 412\n",
            "loss: 0.41015625, time: 2024-12-03 23:43:08.200858, step: 413\n",
            "loss: 0.4609375, time: 2024-12-03 23:43:08.790435, step: 414\n",
            "loss: 0.3828125, time: 2024-12-03 23:43:09.380624, step: 415\n",
            "loss: 0.365234375, time: 2024-12-03 23:43:09.970697, step: 416\n",
            "loss: 0.37109375, time: 2024-12-03 23:43:10.560598, step: 417\n",
            "loss: 0.38671875, time: 2024-12-03 23:43:11.151344, step: 418\n",
            "loss: 0.396484375, time: 2024-12-03 23:43:11.741384, step: 419\n",
            "loss: 0.40234375, time: 2024-12-03 23:43:12.331705, step: 420\n",
            "----- Time -> 2024-12-03 23:43:36.723254 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40625, time: 2024-12-03 23:43:37.009197, step: 421\n",
            "loss: 0.39453125, time: 2024-12-03 23:43:37.599691, step: 422\n",
            "loss: 0.41015625, time: 2024-12-03 23:43:38.190215, step: 423\n",
            "loss: 0.37890625, time: 2024-12-03 23:43:38.781115, step: 424\n",
            "loss: 0.37109375, time: 2024-12-03 23:43:39.371813, step: 425\n",
            "loss: 0.396484375, time: 2024-12-03 23:43:39.962131, step: 426\n",
            "loss: 0.3984375, time: 2024-12-03 23:43:40.553497, step: 427\n",
            "loss: 0.390625, time: 2024-12-03 23:43:41.143920, step: 428\n",
            "loss: 0.37890625, time: 2024-12-03 23:43:41.734770, step: 429\n",
            "loss: 0.392578125, time: 2024-12-03 23:43:42.325292, step: 430\n",
            "loss: 0.3828125, time: 2024-12-03 23:43:42.915415, step: 431\n",
            "loss: 0.388671875, time: 2024-12-03 23:43:43.505931, step: 432\n",
            "loss: 0.412109375, time: 2024-12-03 23:43:44.096368, step: 433\n",
            "loss: 0.3984375, time: 2024-12-03 23:43:44.686489, step: 434\n",
            "loss: 0.39453125, time: 2024-12-03 23:43:45.277487, step: 435\n",
            "loss: 0.3828125, time: 2024-12-03 23:43:45.867783, step: 436\n",
            "loss: 0.375, time: 2024-12-03 23:43:46.457540, step: 437\n",
            "loss: 0.3828125, time: 2024-12-03 23:43:47.047535, step: 438\n",
            "loss: 0.369140625, time: 2024-12-03 23:43:47.637195, step: 439\n",
            "loss: 0.38671875, time: 2024-12-03 23:43:48.228016, step: 440\n",
            "----- Time -> 2024-12-03 23:44:12.066318 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.388671875, time: 2024-12-03 23:44:12.358862, step: 441\n",
            "loss: 0.388671875, time: 2024-12-03 23:44:12.948973, step: 442\n",
            "loss: 0.40234375, time: 2024-12-03 23:44:13.539238, step: 443\n",
            "loss: 0.38671875, time: 2024-12-03 23:44:14.129001, step: 444\n",
            "loss: 0.421875, time: 2024-12-03 23:44:14.719284, step: 445\n",
            "loss: 0.388671875, time: 2024-12-03 23:44:15.309659, step: 446\n",
            "loss: 0.408203125, time: 2024-12-03 23:44:15.899973, step: 447\n",
            "loss: 0.38671875, time: 2024-12-03 23:44:16.489919, step: 448\n",
            "loss: 0.404296875, time: 2024-12-03 23:44:17.079642, step: 449\n",
            "loss: 0.396484375, time: 2024-12-03 23:44:17.669742, step: 450\n",
            "loss: 0.38671875, time: 2024-12-03 23:44:18.260151, step: 451\n",
            "loss: 0.4453125, time: 2024-12-03 23:44:18.849841, step: 452\n",
            "loss: 0.3984375, time: 2024-12-03 23:44:19.439611, step: 453\n",
            "loss: 0.375, time: 2024-12-03 23:44:20.029516, step: 454\n",
            "loss: 0.39453125, time: 2024-12-03 23:44:20.619730, step: 455\n",
            "loss: 0.41796875, time: 2024-12-03 23:44:21.210494, step: 456\n",
            "loss: 0.392578125, time: 2024-12-03 23:44:21.801026, step: 457\n",
            "loss: 0.390625, time: 2024-12-03 23:44:22.390819, step: 458\n",
            "loss: 0.37890625, time: 2024-12-03 23:44:22.980480, step: 459\n",
            "loss: 0.400390625, time: 2024-12-03 23:44:23.570514, step: 460\n",
            "----- Time -> 2024-12-03 23:44:47.188281 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.400390625, time: 2024-12-03 23:44:47.460431, step: 461\n",
            "loss: 0.392578125, time: 2024-12-03 23:44:48.050242, step: 462\n",
            "loss: 0.412109375, time: 2024-12-03 23:44:48.639961, step: 463\n",
            "loss: 0.421875, time: 2024-12-03 23:44:49.229527, step: 464\n",
            "loss: 0.392578125, time: 2024-12-03 23:44:49.819211, step: 465\n",
            "loss: 0.384765625, time: 2024-12-03 23:44:50.409008, step: 466\n",
            "loss: 0.4296875, time: 2024-12-03 23:44:50.999123, step: 467\n",
            "loss: 0.39453125, time: 2024-12-03 23:44:51.589516, step: 468\n",
            "loss: 0.427734375, time: 2024-12-03 23:44:52.179721, step: 469\n",
            "loss: 0.396484375, time: 2024-12-03 23:44:52.769853, step: 470\n",
            "loss: 0.408203125, time: 2024-12-03 23:44:53.360401, step: 471\n",
            "loss: 0.388671875, time: 2024-12-03 23:44:53.950524, step: 472\n",
            "loss: 0.384765625, time: 2024-12-03 23:44:54.540386, step: 473\n",
            "loss: 0.416015625, time: 2024-12-03 23:44:55.130554, step: 474\n",
            "loss: 0.384765625, time: 2024-12-03 23:44:55.720562, step: 475\n",
            "loss: 0.408203125, time: 2024-12-03 23:44:56.310513, step: 476\n",
            "loss: 0.4140625, time: 2024-12-03 23:44:56.900787, step: 477\n",
            "loss: 0.380859375, time: 2024-12-03 23:44:57.490652, step: 478\n",
            "loss: 0.396484375, time: 2024-12-03 23:44:58.080985, step: 479\n",
            "loss: 0.376953125, time: 2024-12-03 23:44:58.671598, step: 480\n",
            "----- Time -> 2024-12-03 23:45:22.165774 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40234375, time: 2024-12-03 23:45:22.439447, step: 481\n",
            "loss: 0.40234375, time: 2024-12-03 23:45:23.029424, step: 482\n",
            "loss: 0.396484375, time: 2024-12-03 23:45:23.620104, step: 483\n",
            "loss: 0.390625, time: 2024-12-03 23:45:24.209759, step: 484\n",
            "loss: 0.376953125, time: 2024-12-03 23:45:24.799668, step: 485\n",
            "loss: 0.37890625, time: 2024-12-03 23:45:25.389475, step: 486\n",
            "loss: 0.4140625, time: 2024-12-03 23:45:25.979237, step: 487\n",
            "loss: 0.38671875, time: 2024-12-03 23:45:26.569305, step: 488\n",
            "loss: 0.408203125, time: 2024-12-03 23:45:27.158896, step: 489\n",
            "loss: 0.439453125, time: 2024-12-03 23:45:27.748660, step: 490\n",
            "loss: 0.375, time: 2024-12-03 23:45:28.339260, step: 491\n",
            "loss: 0.380859375, time: 2024-12-03 23:45:28.929172, step: 492\n",
            "loss: 0.361328125, time: 2024-12-03 23:45:29.519314, step: 493\n",
            "loss: 0.392578125, time: 2024-12-03 23:45:30.110254, step: 494\n",
            "loss: 0.388671875, time: 2024-12-03 23:45:30.700822, step: 495\n",
            "loss: 0.404296875, time: 2024-12-03 23:45:31.290496, step: 496\n",
            "loss: 0.37890625, time: 2024-12-03 23:45:31.880483, step: 497\n",
            "loss: 0.388671875, time: 2024-12-03 23:45:32.470458, step: 498\n",
            "loss: 0.408203125, time: 2024-12-03 23:45:33.059953, step: 499\n",
            "loss: 0.37890625, time: 2024-12-03 23:45:33.650732, step: 500\n",
            "----- Time -> 2024-12-03 23:45:57.675272 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-03 23:45:57.959431, step: 501\n",
            "loss: 0.423828125, time: 2024-12-03 23:45:58.550385, step: 502\n",
            "loss: 0.392578125, time: 2024-12-03 23:45:59.140846, step: 503\n",
            "loss: 0.40234375, time: 2024-12-03 23:45:59.730464, step: 504\n",
            "loss: 0.412109375, time: 2024-12-03 23:46:00.321064, step: 505\n",
            "loss: 0.41015625, time: 2024-12-03 23:46:00.911079, step: 506\n",
            "loss: 0.40234375, time: 2024-12-03 23:46:01.500966, step: 507\n",
            "loss: 0.404296875, time: 2024-12-03 23:46:02.090667, step: 508\n",
            "loss: 0.3984375, time: 2024-12-03 23:46:02.681340, step: 509\n",
            "loss: 0.38671875, time: 2024-12-03 23:46:03.271494, step: 510\n",
            "loss: 0.392578125, time: 2024-12-03 23:46:03.861469, step: 511\n",
            "loss: 0.396484375, time: 2024-12-03 23:46:04.451685, step: 512\n",
            "loss: 0.4375, time: 2024-12-03 23:46:05.041199, step: 513\n",
            "loss: 0.423828125, time: 2024-12-03 23:46:05.631312, step: 514\n",
            "loss: 0.380859375, time: 2024-12-03 23:46:06.221095, step: 515\n",
            "loss: 0.40234375, time: 2024-12-03 23:46:06.811206, step: 516\n",
            "loss: 0.3828125, time: 2024-12-03 23:46:07.401490, step: 517\n",
            "loss: 0.408203125, time: 2024-12-03 23:46:08.000962, step: 518\n",
            "loss: 0.390625, time: 2024-12-03 23:46:08.592541, step: 519\n",
            "loss: 0.3984375, time: 2024-12-03 23:46:09.182603, step: 520\n",
            "----- Time -> 2024-12-03 23:46:32.993792 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.380859375, time: 2024-12-03 23:46:33.265039, step: 521\n",
            "loss: 0.39453125, time: 2024-12-03 23:46:33.859062, step: 522\n",
            "loss: 0.408203125, time: 2024-12-03 23:46:34.448836, step: 523\n",
            "loss: 0.44921875, time: 2024-12-03 23:46:35.038242, step: 524\n",
            "loss: 0.3828125, time: 2024-12-03 23:46:35.628112, step: 525\n",
            "loss: 0.3828125, time: 2024-12-03 23:46:36.218516, step: 526\n",
            "loss: 0.384765625, time: 2024-12-03 23:46:36.808556, step: 527\n",
            "loss: 0.373046875, time: 2024-12-03 23:46:37.398778, step: 528\n",
            "loss: 0.388671875, time: 2024-12-03 23:46:37.989061, step: 529\n",
            "loss: 0.404296875, time: 2024-12-03 23:46:38.578968, step: 530\n",
            "loss: 0.380859375, time: 2024-12-03 23:46:39.168782, step: 531\n",
            "loss: 0.384765625, time: 2024-12-03 23:46:39.759464, step: 532\n",
            "loss: 0.369140625, time: 2024-12-03 23:46:40.349640, step: 533\n",
            "loss: 0.3671875, time: 2024-12-03 23:46:40.939132, step: 534\n",
            "loss: 0.3984375, time: 2024-12-03 23:46:41.529166, step: 535\n",
            "loss: 0.392578125, time: 2024-12-03 23:46:42.119001, step: 536\n",
            "loss: 0.3984375, time: 2024-12-03 23:46:42.708500, step: 537\n",
            "loss: 0.470703125, time: 2024-12-03 23:46:43.299117, step: 538\n",
            "loss: 0.3828125, time: 2024-12-03 23:46:43.889211, step: 539\n",
            "loss: 0.400390625, time: 2024-12-03 23:46:44.479385, step: 540\n",
            "----- Time -> 2024-12-03 23:47:08.331369 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.380859375, time: 2024-12-03 23:47:08.605140, step: 541\n",
            "loss: 0.380859375, time: 2024-12-03 23:47:09.194967, step: 542\n",
            "loss: 0.357421875, time: 2024-12-03 23:47:09.785881, step: 543\n",
            "loss: 0.408203125, time: 2024-12-03 23:47:10.376596, step: 544\n",
            "loss: 0.384765625, time: 2024-12-03 23:47:10.966198, step: 545\n",
            "loss: 0.392578125, time: 2024-12-03 23:47:11.556188, step: 546\n",
            "loss: 0.41015625, time: 2024-12-03 23:47:12.147163, step: 547\n",
            "loss: 0.388671875, time: 2024-12-03 23:47:12.736826, step: 548\n",
            "loss: 0.400390625, time: 2024-12-03 23:47:13.326520, step: 549\n",
            "loss: 0.390625, time: 2024-12-03 23:47:13.917536, step: 550\n",
            "loss: 0.376953125, time: 2024-12-03 23:47:14.507325, step: 551\n",
            "loss: 0.3984375, time: 2024-12-03 23:47:15.096962, step: 552\n",
            "loss: 0.37109375, time: 2024-12-03 23:47:15.687698, step: 553\n",
            "loss: 0.388671875, time: 2024-12-03 23:47:16.277729, step: 554\n",
            "loss: 0.376953125, time: 2024-12-03 23:47:16.867650, step: 555\n",
            "loss: 0.369140625, time: 2024-12-03 23:47:17.457815, step: 556\n",
            "loss: 0.388671875, time: 2024-12-03 23:47:18.047551, step: 557\n",
            "loss: 0.423828125, time: 2024-12-03 23:47:18.637126, step: 558\n",
            "loss: 0.380859375, time: 2024-12-03 23:47:19.226677, step: 559\n",
            "loss: 0.376953125, time: 2024-12-03 23:47:19.817570, step: 560\n",
            "----- Time -> 2024-12-03 23:47:43.411222 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.380859375, time: 2024-12-03 23:47:43.702394, step: 561\n",
            "loss: 0.380859375, time: 2024-12-03 23:47:44.292853, step: 562\n",
            "loss: 0.392578125, time: 2024-12-03 23:47:44.883047, step: 563\n",
            "loss: 0.404296875, time: 2024-12-03 23:47:45.473469, step: 564\n",
            "loss: 0.388671875, time: 2024-12-03 23:47:46.063536, step: 565\n",
            "loss: 0.392578125, time: 2024-12-03 23:47:46.653526, step: 566\n",
            "loss: 0.3828125, time: 2024-12-03 23:47:47.243568, step: 567\n",
            "loss: 0.412109375, time: 2024-12-03 23:47:47.834115, step: 568\n",
            "loss: 0.421875, time: 2024-12-03 23:47:48.423923, step: 569\n",
            "loss: 0.380859375, time: 2024-12-03 23:47:49.013779, step: 570\n",
            "loss: 0.416015625, time: 2024-12-03 23:47:49.604103, step: 571\n",
            "loss: 0.396484375, time: 2024-12-03 23:47:50.193823, step: 572\n",
            "loss: 0.384765625, time: 2024-12-03 23:47:50.783521, step: 573\n",
            "loss: 0.423828125, time: 2024-12-03 23:47:51.373597, step: 574\n",
            "loss: 0.39453125, time: 2024-12-03 23:47:51.963159, step: 575\n",
            "loss: 0.390625, time: 2024-12-03 23:47:52.553101, step: 576\n",
            "loss: 0.400390625, time: 2024-12-03 23:47:53.142593, step: 577\n",
            "loss: 0.388671875, time: 2024-12-03 23:47:53.732957, step: 578\n",
            "loss: 0.384765625, time: 2024-12-03 23:47:54.322929, step: 579\n",
            "loss: 0.380859375, time: 2024-12-03 23:47:54.912478, step: 580\n",
            "----- Time -> 2024-12-03 23:48:18.308007 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.404296875, time: 2024-12-03 23:48:18.583391, step: 581\n",
            "loss: 0.369140625, time: 2024-12-03 23:48:19.173501, step: 582\n",
            "loss: 0.369140625, time: 2024-12-03 23:48:19.764193, step: 583\n",
            "loss: 0.400390625, time: 2024-12-03 23:48:20.354553, step: 584\n",
            "loss: 0.390625, time: 2024-12-03 23:48:20.944438, step: 585\n",
            "loss: 0.388671875, time: 2024-12-03 23:48:21.533952, step: 586\n",
            "loss: 0.400390625, time: 2024-12-03 23:48:22.123558, step: 587\n",
            "loss: 0.416015625, time: 2024-12-03 23:48:22.714524, step: 588\n",
            "loss: 0.416015625, time: 2024-12-03 23:48:23.304646, step: 589\n",
            "loss: 0.375, time: 2024-12-03 23:48:23.894434, step: 590\n",
            "loss: 0.412109375, time: 2024-12-03 23:48:24.484850, step: 591\n",
            "loss: 0.3828125, time: 2024-12-03 23:48:25.074865, step: 592\n",
            "loss: 0.396484375, time: 2024-12-03 23:48:25.664473, step: 593\n",
            "loss: 0.3984375, time: 2024-12-03 23:48:26.254510, step: 594\n",
            "loss: 0.380859375, time: 2024-12-03 23:48:26.844043, step: 595\n",
            "loss: 0.447265625, time: 2024-12-03 23:48:27.433564, step: 596\n",
            "loss: 0.4296875, time: 2024-12-03 23:48:28.023305, step: 597\n",
            "loss: 0.373046875, time: 2024-12-03 23:48:28.613269, step: 598\n",
            "loss: 0.388671875, time: 2024-12-03 23:48:29.202832, step: 599\n",
            "loss: 0.39453125, time: 2024-12-03 23:48:29.792531, step: 600\n",
            "----- Time -> 2024-12-03 23:48:53.463800 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40625, time: 2024-12-03 23:48:53.741071, step: 601\n",
            "loss: 0.3984375, time: 2024-12-03 23:48:54.331566, step: 602\n",
            "loss: 0.39453125, time: 2024-12-03 23:48:54.921925, step: 603\n",
            "loss: 0.3984375, time: 2024-12-03 23:48:55.511662, step: 604\n",
            "loss: 0.38671875, time: 2024-12-03 23:48:56.102074, step: 605\n",
            "loss: 0.3828125, time: 2024-12-03 23:48:56.691771, step: 606\n",
            "loss: 0.392578125, time: 2024-12-03 23:48:57.281750, step: 607\n",
            "loss: 0.37890625, time: 2024-12-03 23:48:57.871481, step: 608\n",
            "loss: 0.392578125, time: 2024-12-03 23:48:58.461683, step: 609\n",
            "loss: 0.388671875, time: 2024-12-03 23:48:59.052074, step: 610\n",
            "loss: 0.361328125, time: 2024-12-03 23:48:59.641633, step: 611\n",
            "loss: 0.392578125, time: 2024-12-03 23:49:00.232001, step: 612\n",
            "loss: 0.4375, time: 2024-12-03 23:49:00.822132, step: 613\n",
            "loss: 0.390625, time: 2024-12-03 23:49:01.411802, step: 614\n",
            "loss: 0.38671875, time: 2024-12-03 23:49:02.001442, step: 615\n",
            "loss: 0.3984375, time: 2024-12-03 23:49:02.591507, step: 616\n",
            "loss: 0.40625, time: 2024-12-03 23:49:03.182159, step: 617\n",
            "loss: 0.421875, time: 2024-12-03 23:49:03.771846, step: 618\n",
            "loss: 0.375, time: 2024-12-03 23:49:04.361539, step: 619\n",
            "loss: 0.392578125, time: 2024-12-03 23:49:04.951451, step: 620\n",
            "----- Time -> 2024-12-03 23:49:28.222302 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40234375, time: 2024-12-03 23:49:28.504196, step: 621\n",
            "loss: 0.380859375, time: 2024-12-03 23:49:29.094477, step: 622\n",
            "loss: 0.404296875, time: 2024-12-03 23:49:29.684432, step: 623\n",
            "loss: 0.408203125, time: 2024-12-03 23:49:30.274519, step: 624\n",
            "loss: 0.3828125, time: 2024-12-03 23:49:30.864172, step: 625\n",
            "loss: 0.41015625, time: 2024-12-03 23:49:31.454396, step: 626\n",
            "loss: 0.37109375, time: 2024-12-03 23:49:32.044259, step: 627\n",
            "loss: 0.369140625, time: 2024-12-03 23:49:32.633992, step: 628\n",
            "loss: 0.416015625, time: 2024-12-03 23:49:33.223898, step: 629\n",
            "loss: 0.380859375, time: 2024-12-03 23:49:33.813819, step: 630\n",
            "loss: 0.400390625, time: 2024-12-03 23:49:34.403438, step: 631\n",
            "loss: 0.404296875, time: 2024-12-03 23:49:34.992776, step: 632\n",
            "loss: 0.388671875, time: 2024-12-03 23:49:35.582509, step: 633\n",
            "loss: 0.384765625, time: 2024-12-03 23:49:36.172922, step: 634\n",
            "loss: 0.373046875, time: 2024-12-03 23:49:36.762885, step: 635\n",
            "loss: 0.384765625, time: 2024-12-03 23:49:37.352791, step: 636\n",
            "loss: 0.39453125, time: 2024-12-03 23:49:37.943080, step: 637\n",
            "loss: 0.390625, time: 2024-12-03 23:49:38.532957, step: 638\n",
            "loss: 0.396484375, time: 2024-12-03 23:49:39.122768, step: 639\n",
            "loss: 0.380859375, time: 2024-12-03 23:49:39.713061, step: 640\n",
            "----- Time -> 2024-12-03 23:50:03.373241 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-03 23:50:03.658843, step: 641\n",
            "loss: 0.380859375, time: 2024-12-03 23:50:04.248861, step: 642\n",
            "loss: 0.40625, time: 2024-12-03 23:50:04.839000, step: 643\n",
            "loss: 0.376953125, time: 2024-12-03 23:50:05.428952, step: 644\n",
            "loss: 0.408203125, time: 2024-12-03 23:50:06.018778, step: 645\n",
            "loss: 0.38671875, time: 2024-12-03 23:50:06.608837, step: 646\n",
            "loss: 0.42578125, time: 2024-12-03 23:50:07.198330, step: 647\n",
            "loss: 0.416015625, time: 2024-12-03 23:50:07.788255, step: 648\n",
            "loss: 0.38671875, time: 2024-12-03 23:50:08.378398, step: 649\n",
            "loss: 0.380859375, time: 2024-12-03 23:50:08.967865, step: 650\n",
            "loss: 0.38671875, time: 2024-12-03 23:50:09.557756, step: 651\n",
            "loss: 0.38671875, time: 2024-12-03 23:50:10.147918, step: 652\n",
            "loss: 0.376953125, time: 2024-12-03 23:50:10.737549, step: 653\n",
            "loss: 0.412109375, time: 2024-12-03 23:50:11.327440, step: 654\n",
            "loss: 0.392578125, time: 2024-12-03 23:50:11.917684, step: 655\n",
            "loss: 0.40234375, time: 2024-12-03 23:50:12.508223, step: 656\n",
            "loss: 0.38671875, time: 2024-12-03 23:50:13.098019, step: 657\n",
            "loss: 0.390625, time: 2024-12-03 23:50:13.688536, step: 658\n",
            "loss: 0.40234375, time: 2024-12-03 23:50:14.279218, step: 659\n",
            "loss: 0.37890625, time: 2024-12-03 23:50:14.869132, step: 660\n",
            "----- Time -> 2024-12-03 23:50:38.323701 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3984375, time: 2024-12-03 23:50:38.615089, step: 661\n",
            "loss: 0.396484375, time: 2024-12-03 23:50:39.204885, step: 662\n",
            "loss: 0.390625, time: 2024-12-03 23:50:39.795061, step: 663\n",
            "loss: 0.396484375, time: 2024-12-03 23:50:40.385348, step: 664\n",
            "loss: 0.388671875, time: 2024-12-03 23:50:40.975519, step: 665\n",
            "loss: 0.380859375, time: 2024-12-03 23:50:41.565835, step: 666\n",
            "loss: 0.38671875, time: 2024-12-03 23:50:42.156102, step: 667\n",
            "loss: 0.392578125, time: 2024-12-03 23:50:42.745791, step: 668\n",
            "loss: 0.396484375, time: 2024-12-03 23:50:43.335697, step: 669\n",
            "loss: 0.380859375, time: 2024-12-03 23:50:43.925450, step: 670\n",
            "loss: 0.419921875, time: 2024-12-03 23:50:44.515312, step: 671\n",
            "loss: 0.392578125, time: 2024-12-03 23:50:45.105214, step: 672\n",
            "loss: 0.365234375, time: 2024-12-03 23:50:45.695723, step: 673\n",
            "loss: 0.416015625, time: 2024-12-03 23:50:46.286126, step: 674\n",
            "loss: 0.384765625, time: 2024-12-03 23:50:46.875945, step: 675\n",
            "loss: 0.400390625, time: 2024-12-03 23:50:47.466472, step: 676\n",
            "loss: 0.37109375, time: 2024-12-03 23:50:48.056205, step: 677\n",
            "loss: 0.40234375, time: 2024-12-03 23:50:48.646190, step: 678\n",
            "loss: 0.384765625, time: 2024-12-03 23:50:49.236395, step: 679\n",
            "loss: 0.439453125, time: 2024-12-03 23:50:49.826326, step: 680\n",
            "----- Time -> 2024-12-03 23:51:13.313697 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.390625, time: 2024-12-03 23:51:13.604530, step: 681\n",
            "loss: 0.36328125, time: 2024-12-03 23:51:14.194361, step: 682\n",
            "loss: 0.369140625, time: 2024-12-03 23:51:14.784148, step: 683\n",
            "loss: 0.44140625, time: 2024-12-03 23:51:15.417577, step: 684\n",
            "loss: 0.37890625, time: 2024-12-03 23:51:16.007706, step: 685\n",
            "loss: 0.408203125, time: 2024-12-03 23:51:16.597523, step: 686\n",
            "loss: 0.3671875, time: 2024-12-03 23:51:17.187419, step: 687\n",
            "loss: 0.390625, time: 2024-12-03 23:51:17.777171, step: 688\n",
            "loss: 0.388671875, time: 2024-12-03 23:51:18.367223, step: 689\n",
            "loss: 0.37890625, time: 2024-12-03 23:51:18.957593, step: 690\n",
            "loss: 0.388671875, time: 2024-12-03 23:51:19.549164, step: 691\n",
            "loss: 0.396484375, time: 2024-12-03 23:51:20.138829, step: 692\n",
            "loss: 0.4453125, time: 2024-12-03 23:51:20.729091, step: 693\n",
            "loss: 0.384765625, time: 2024-12-03 23:51:21.318821, step: 694\n",
            "loss: 0.388671875, time: 2024-12-03 23:51:21.908416, step: 695\n",
            "loss: 0.41015625, time: 2024-12-03 23:51:22.498435, step: 696\n",
            "loss: 0.390625, time: 2024-12-03 23:51:23.088142, step: 697\n",
            "loss: 0.3828125, time: 2024-12-03 23:51:23.677861, step: 698\n",
            "loss: 0.3828125, time: 2024-12-03 23:51:24.267609, step: 699\n",
            "loss: 0.37890625, time: 2024-12-03 23:51:24.857490, step: 700\n",
            "----- Time -> 2024-12-03 23:51:48.443487 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.41015625, time: 2024-12-03 23:51:48.713219, step: 701\n",
            "loss: 0.396484375, time: 2024-12-03 23:51:49.303347, step: 702\n",
            "loss: 0.40234375, time: 2024-12-03 23:51:49.893261, step: 703\n",
            "loss: 0.408203125, time: 2024-12-03 23:51:50.483073, step: 704\n",
            "loss: 0.390625, time: 2024-12-03 23:51:51.072969, step: 705\n",
            "loss: 0.3984375, time: 2024-12-03 23:51:51.663319, step: 706\n",
            "loss: 0.4609375, time: 2024-12-03 23:51:52.253575, step: 707\n",
            "loss: 0.396484375, time: 2024-12-03 23:51:52.843384, step: 708\n",
            "loss: 0.400390625, time: 2024-12-03 23:51:53.433858, step: 709\n",
            "loss: 0.400390625, time: 2024-12-03 23:51:54.023453, step: 710\n",
            "loss: 0.44140625, time: 2024-12-03 23:51:54.613406, step: 711\n",
            "loss: 0.396484375, time: 2024-12-03 23:51:55.202910, step: 712\n",
            "loss: 0.3984375, time: 2024-12-03 23:51:55.793191, step: 713\n",
            "loss: 0.3984375, time: 2024-12-03 23:51:56.383161, step: 714\n",
            "loss: 0.3828125, time: 2024-12-03 23:51:56.973103, step: 715\n",
            "loss: 0.369140625, time: 2024-12-03 23:51:57.563489, step: 716\n",
            "loss: 0.419921875, time: 2024-12-03 23:51:58.153338, step: 717\n",
            "loss: 0.4375, time: 2024-12-03 23:51:58.743319, step: 718\n",
            "loss: 0.40625, time: 2024-12-03 23:51:59.333378, step: 719\n",
            "loss: 0.3828125, time: 2024-12-03 23:51:59.923639, step: 720\n",
            "----- Time -> 2024-12-03 23:52:23.481879 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40625, time: 2024-12-03 23:52:23.774760, step: 721\n",
            "loss: 0.40234375, time: 2024-12-03 23:52:24.365244, step: 722\n",
            "loss: 0.390625, time: 2024-12-03 23:52:24.955061, step: 723\n",
            "loss: 0.412109375, time: 2024-12-03 23:52:25.545373, step: 724\n",
            "loss: 0.40234375, time: 2024-12-03 23:52:26.135133, step: 725\n",
            "loss: 0.396484375, time: 2024-12-03 23:52:26.724981, step: 726\n",
            "loss: 0.392578125, time: 2024-12-03 23:52:27.315613, step: 727\n",
            "loss: 0.3984375, time: 2024-12-03 23:52:27.905386, step: 728\n",
            "loss: 0.390625, time: 2024-12-03 23:52:28.495161, step: 729\n",
            "loss: 0.396484375, time: 2024-12-03 23:52:29.085555, step: 730\n",
            "loss: 0.37109375, time: 2024-12-03 23:52:29.675345, step: 731\n",
            "loss: 0.41015625, time: 2024-12-03 23:52:30.265174, step: 732\n",
            "loss: 0.390625, time: 2024-12-03 23:52:30.855159, step: 733\n",
            "loss: 0.369140625, time: 2024-12-03 23:52:31.444671, step: 734\n",
            "loss: 0.392578125, time: 2024-12-03 23:52:32.034522, step: 735\n",
            "loss: 0.40625, time: 2024-12-03 23:52:32.624769, step: 736\n",
            "loss: 0.392578125, time: 2024-12-03 23:52:33.214665, step: 737\n",
            "loss: 0.400390625, time: 2024-12-03 23:52:33.804861, step: 738\n",
            "loss: 0.38671875, time: 2024-12-03 23:52:34.395372, step: 739\n",
            "loss: 0.388671875, time: 2024-12-03 23:52:34.985285, step: 740\n",
            "----- Time -> 2024-12-03 23:52:58.586079 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.376953125, time: 2024-12-03 23:52:58.861829, step: 741\n",
            "loss: 0.388671875, time: 2024-12-03 23:52:59.452347, step: 742\n",
            "loss: 0.359375, time: 2024-12-03 23:53:00.042739, step: 743\n",
            "loss: 0.37890625, time: 2024-12-03 23:53:00.632705, step: 744\n",
            "loss: 0.38671875, time: 2024-12-03 23:53:01.222614, step: 745\n",
            "loss: 0.3828125, time: 2024-12-03 23:53:01.813087, step: 746\n",
            "loss: 0.37890625, time: 2024-12-03 23:53:02.403135, step: 747\n",
            "loss: 0.416015625, time: 2024-12-03 23:53:02.993301, step: 748\n",
            "loss: 0.376953125, time: 2024-12-03 23:53:03.583309, step: 749\n",
            "loss: 0.38671875, time: 2024-12-03 23:53:04.173390, step: 750\n",
            "loss: 0.41796875, time: 2024-12-03 23:53:04.763472, step: 751\n",
            "loss: 0.37890625, time: 2024-12-03 23:53:05.353412, step: 752\n",
            "loss: 0.392578125, time: 2024-12-03 23:53:05.943472, step: 753\n",
            "loss: 0.388671875, time: 2024-12-03 23:53:06.533067, step: 754\n",
            "loss: 0.431640625, time: 2024-12-03 23:53:07.122873, step: 755\n",
            "loss: 0.3828125, time: 2024-12-03 23:53:07.713625, step: 756\n",
            "loss: 0.390625, time: 2024-12-03 23:53:08.303599, step: 757\n",
            "loss: 0.408203125, time: 2024-12-03 23:53:08.893486, step: 758\n",
            "loss: 0.412109375, time: 2024-12-03 23:53:09.483649, step: 759\n",
            "loss: 0.390625, time: 2024-12-03 23:53:10.074051, step: 760\n",
            "----- Time -> 2024-12-03 23:53:33.693990 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.4140625, time: 2024-12-03 23:53:33.979454, step: 761\n",
            "loss: 0.40234375, time: 2024-12-03 23:53:34.569784, step: 762\n",
            "loss: 0.396484375, time: 2024-12-03 23:53:35.159983, step: 763\n",
            "loss: 0.380859375, time: 2024-12-03 23:53:35.750211, step: 764\n",
            "loss: 0.41796875, time: 2024-12-03 23:53:36.340615, step: 765\n",
            "loss: 0.396484375, time: 2024-12-03 23:53:36.930400, step: 766\n",
            "loss: 0.38671875, time: 2024-12-03 23:53:37.520584, step: 767\n",
            "loss: 0.423828125, time: 2024-12-03 23:53:38.110295, step: 768\n",
            "loss: 0.36328125, time: 2024-12-03 23:53:38.700972, step: 769\n",
            "loss: 0.384765625, time: 2024-12-03 23:53:39.291639, step: 770\n",
            "loss: 0.380859375, time: 2024-12-03 23:53:39.881834, step: 771\n",
            "loss: 0.392578125, time: 2024-12-03 23:53:40.471859, step: 772\n",
            "loss: 0.376953125, time: 2024-12-03 23:53:41.062290, step: 773\n",
            "loss: 0.37890625, time: 2024-12-03 23:53:41.652064, step: 774\n",
            "loss: 0.41015625, time: 2024-12-03 23:53:42.242185, step: 775\n",
            "loss: 0.40625, time: 2024-12-03 23:53:42.832813, step: 776\n",
            "loss: 0.3984375, time: 2024-12-03 23:53:43.422699, step: 777\n",
            "loss: 0.396484375, time: 2024-12-03 23:53:44.012748, step: 778\n",
            "loss: 0.380859375, time: 2024-12-03 23:53:44.602896, step: 779\n",
            "loss: 0.41015625, time: 2024-12-03 23:53:45.192893, step: 780\n",
            "----- Time -> 2024-12-03 23:54:08.774630 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.41015625, time: 2024-12-03 23:54:09.045882, step: 781\n",
            "loss: 0.388671875, time: 2024-12-03 23:54:09.635835, step: 782\n",
            "loss: 0.41015625, time: 2024-12-03 23:54:10.225728, step: 783\n",
            "loss: 0.392578125, time: 2024-12-03 23:54:10.815862, step: 784\n",
            "loss: 0.396484375, time: 2024-12-03 23:54:11.405809, step: 785\n",
            "loss: 0.384765625, time: 2024-12-03 23:54:11.996109, step: 786\n",
            "loss: 0.419921875, time: 2024-12-03 23:54:12.585840, step: 787\n",
            "loss: 0.380859375, time: 2024-12-03 23:54:13.175958, step: 788\n",
            "loss: 0.37890625, time: 2024-12-03 23:54:13.766032, step: 789\n",
            "loss: 0.404296875, time: 2024-12-03 23:54:14.356358, step: 790\n",
            "loss: 0.3984375, time: 2024-12-03 23:54:14.946524, step: 791\n",
            "loss: 0.41796875, time: 2024-12-03 23:54:15.536575, step: 792\n",
            "loss: 0.3671875, time: 2024-12-03 23:54:16.126262, step: 793\n",
            "loss: 0.37890625, time: 2024-12-03 23:54:16.716192, step: 794\n",
            "loss: 0.390625, time: 2024-12-03 23:54:17.306904, step: 795\n",
            "loss: 0.416015625, time: 2024-12-03 23:54:17.897450, step: 796\n",
            "loss: 0.40625, time: 2024-12-03 23:54:18.487101, step: 797\n",
            "loss: 0.404296875, time: 2024-12-03 23:54:19.077195, step: 798\n",
            "loss: 0.3984375, time: 2024-12-03 23:54:19.685474, step: 799\n",
            "loss: 0.3984375, time: 2024-12-03 23:54:20.275944, step: 800\n",
            "----- Time -> 2024-12-03 23:54:43.627236 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.369140625, time: 2024-12-03 23:54:43.917473, step: 801\n",
            "loss: 0.3828125, time: 2024-12-03 23:54:44.507273, step: 802\n",
            "loss: 0.359375, time: 2024-12-03 23:54:45.097117, step: 803\n",
            "loss: 0.392578125, time: 2024-12-03 23:54:45.687444, step: 804\n",
            "loss: 0.390625, time: 2024-12-03 23:54:46.277451, step: 805\n",
            "loss: 0.3828125, time: 2024-12-03 23:54:46.867833, step: 806\n",
            "loss: 0.388671875, time: 2024-12-03 23:54:47.457687, step: 807\n",
            "loss: 0.400390625, time: 2024-12-03 23:54:48.047868, step: 808\n",
            "loss: 0.376953125, time: 2024-12-03 23:54:48.638115, step: 809\n",
            "loss: 0.384765625, time: 2024-12-03 23:54:49.228074, step: 810\n",
            "loss: 0.37890625, time: 2024-12-03 23:54:49.818328, step: 811\n",
            "loss: 0.38671875, time: 2024-12-03 23:54:50.408352, step: 812\n",
            "loss: 0.39453125, time: 2024-12-03 23:54:50.998344, step: 813\n",
            "loss: 0.38671875, time: 2024-12-03 23:54:51.588184, step: 814\n",
            "loss: 0.404296875, time: 2024-12-03 23:54:52.178250, step: 815\n",
            "loss: 0.388671875, time: 2024-12-03 23:54:52.767940, step: 816\n",
            "loss: 0.3828125, time: 2024-12-03 23:54:53.357696, step: 817\n",
            "loss: 0.4140625, time: 2024-12-03 23:54:53.947284, step: 818\n",
            "loss: 0.412109375, time: 2024-12-03 23:54:54.537696, step: 819\n",
            "loss: 0.41015625, time: 2024-12-03 23:54:55.127296, step: 820\n",
            "----- Time -> 2024-12-03 23:55:18.911607 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.390625, time: 2024-12-03 23:55:19.185935, step: 821\n",
            "loss: 0.4375, time: 2024-12-03 23:55:19.775877, step: 822\n",
            "loss: 0.421875, time: 2024-12-03 23:55:20.365840, step: 823\n",
            "loss: 0.396484375, time: 2024-12-03 23:55:20.965185, step: 824\n",
            "loss: 0.388671875, time: 2024-12-03 23:55:21.556220, step: 825\n",
            "loss: 0.388671875, time: 2024-12-03 23:55:22.146280, step: 826\n",
            "loss: 0.37890625, time: 2024-12-03 23:55:22.736235, step: 827\n",
            "loss: 0.400390625, time: 2024-12-03 23:55:23.326255, step: 828\n",
            "loss: 0.392578125, time: 2024-12-03 23:55:23.916412, step: 829\n",
            "loss: 0.376953125, time: 2024-12-03 23:55:24.506243, step: 830\n",
            "loss: 0.37890625, time: 2024-12-03 23:55:25.096063, step: 831\n",
            "loss: 0.3828125, time: 2024-12-03 23:55:25.686211, step: 832\n",
            "loss: 0.392578125, time: 2024-12-03 23:55:26.276199, step: 833\n",
            "loss: 0.37890625, time: 2024-12-03 23:55:26.866478, step: 834\n",
            "loss: 0.412109375, time: 2024-12-03 23:55:27.456794, step: 835\n",
            "loss: 0.376953125, time: 2024-12-03 23:55:28.046737, step: 836\n",
            "loss: 0.41796875, time: 2024-12-03 23:55:28.637014, step: 837\n",
            "loss: 0.380859375, time: 2024-12-03 23:55:29.227231, step: 838\n",
            "loss: 0.392578125, time: 2024-12-03 23:55:29.817058, step: 839\n",
            "loss: 0.373046875, time: 2024-12-03 23:55:30.407163, step: 840\n",
            "----- Time -> 2024-12-03 23:55:54.042492 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.408203125, time: 2024-12-03 23:55:54.323991, step: 841\n",
            "loss: 0.400390625, time: 2024-12-03 23:55:54.913389, step: 842\n",
            "loss: 0.408203125, time: 2024-12-03 23:55:55.503391, step: 843\n",
            "loss: 0.412109375, time: 2024-12-03 23:55:56.093734, step: 844\n",
            "loss: 0.388671875, time: 2024-12-03 23:55:56.683930, step: 845\n",
            "loss: 0.388671875, time: 2024-12-03 23:55:57.273988, step: 846\n",
            "loss: 0.408203125, time: 2024-12-03 23:55:57.863995, step: 847\n",
            "loss: 0.43359375, time: 2024-12-03 23:55:58.454196, step: 848\n",
            "loss: 0.38671875, time: 2024-12-03 23:55:59.044123, step: 849\n",
            "loss: 0.3828125, time: 2024-12-03 23:55:59.634034, step: 850\n",
            "loss: 0.390625, time: 2024-12-03 23:56:00.223886, step: 851\n",
            "loss: 0.388671875, time: 2024-12-03 23:56:00.813804, step: 852\n",
            "loss: 0.380859375, time: 2024-12-03 23:56:01.403674, step: 853\n",
            "loss: 0.375, time: 2024-12-03 23:56:01.993557, step: 854\n",
            "loss: 0.396484375, time: 2024-12-03 23:56:02.583388, step: 855\n",
            "loss: 0.3828125, time: 2024-12-03 23:56:03.172998, step: 856\n",
            "loss: 0.396484375, time: 2024-12-03 23:56:03.763580, step: 857\n",
            "loss: 0.400390625, time: 2024-12-03 23:56:04.353513, step: 858\n",
            "loss: 0.42578125, time: 2024-12-03 23:56:04.943695, step: 859\n",
            "loss: 0.388671875, time: 2024-12-03 23:56:05.534334, step: 860\n",
            "----- Time -> 2024-12-03 23:56:29.150423 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.38671875, time: 2024-12-03 23:56:29.438208, step: 861\n",
            "loss: 0.396484375, time: 2024-12-03 23:56:30.029503, step: 862\n",
            "loss: 0.419921875, time: 2024-12-03 23:56:30.619667, step: 863\n",
            "loss: 0.392578125, time: 2024-12-03 23:56:31.210722, step: 864\n",
            "loss: 0.39453125, time: 2024-12-03 23:56:31.800983, step: 865\n",
            "loss: 0.373046875, time: 2024-12-03 23:56:32.390602, step: 866\n",
            "loss: 0.380859375, time: 2024-12-03 23:56:32.980073, step: 867\n",
            "loss: 0.39453125, time: 2024-12-03 23:56:33.570482, step: 868\n",
            "loss: 0.392578125, time: 2024-12-03 23:56:34.159910, step: 869\n",
            "loss: 0.388671875, time: 2024-12-03 23:56:34.749485, step: 870\n",
            "loss: 0.388671875, time: 2024-12-03 23:56:35.339813, step: 871\n",
            "loss: 0.396484375, time: 2024-12-03 23:56:35.929839, step: 872\n",
            "loss: 0.373046875, time: 2024-12-03 23:56:36.519269, step: 873\n",
            "loss: 0.3984375, time: 2024-12-03 23:56:37.109402, step: 874\n",
            "loss: 0.400390625, time: 2024-12-03 23:56:37.699185, step: 875\n",
            "loss: 0.390625, time: 2024-12-03 23:56:38.289315, step: 876\n",
            "loss: 0.3671875, time: 2024-12-03 23:56:38.879023, step: 877\n",
            "loss: 0.400390625, time: 2024-12-03 23:56:39.469519, step: 878\n",
            "loss: 0.388671875, time: 2024-12-03 23:56:40.062038, step: 879\n",
            "loss: 0.380859375, time: 2024-12-03 23:56:40.651916, step: 880\n",
            "----- Time -> 2024-12-03 23:57:04.104760 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.376953125, time: 2024-12-03 23:57:04.373264, step: 881\n",
            "loss: 0.416015625, time: 2024-12-03 23:57:04.963059, step: 882\n",
            "loss: 0.390625, time: 2024-12-03 23:57:05.553099, step: 883\n",
            "loss: 0.388671875, time: 2024-12-03 23:57:06.143049, step: 884\n",
            "loss: 0.380859375, time: 2024-12-03 23:57:06.732925, step: 885\n",
            "loss: 0.390625, time: 2024-12-03 23:57:07.323261, step: 886\n",
            "loss: 0.41015625, time: 2024-12-03 23:57:07.913699, step: 887\n",
            "loss: 0.3984375, time: 2024-12-03 23:57:08.503847, step: 888\n",
            "loss: 0.38671875, time: 2024-12-03 23:57:09.094240, step: 889\n",
            "loss: 0.376953125, time: 2024-12-03 23:57:09.684157, step: 890\n",
            "loss: 0.37890625, time: 2024-12-03 23:57:10.274336, step: 891\n",
            "loss: 0.3828125, time: 2024-12-03 23:57:10.864563, step: 892\n",
            "loss: 0.42578125, time: 2024-12-03 23:57:11.454576, step: 893\n",
            "loss: 0.376953125, time: 2024-12-03 23:57:12.044213, step: 894\n",
            "loss: 0.421875, time: 2024-12-03 23:57:12.634160, step: 895\n",
            "loss: 0.3984375, time: 2024-12-03 23:57:13.223934, step: 896\n",
            "loss: 0.37890625, time: 2024-12-03 23:57:13.814748, step: 897\n",
            "loss: 0.396484375, time: 2024-12-03 23:57:14.404577, step: 898\n",
            "loss: 0.380859375, time: 2024-12-03 23:57:14.993964, step: 899\n",
            "loss: 0.41015625, time: 2024-12-03 23:57:15.583760, step: 900\n",
            "----- Time -> 2024-12-03 23:57:39.313687 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.400390625, time: 2024-12-03 23:57:39.592698, step: 901\n",
            "loss: 0.380859375, time: 2024-12-03 23:57:40.189442, step: 902\n",
            "loss: 0.427734375, time: 2024-12-03 23:57:40.780228, step: 903\n",
            "loss: 0.38671875, time: 2024-12-03 23:57:41.370348, step: 904\n",
            "loss: 0.412109375, time: 2024-12-03 23:57:41.960414, step: 905\n",
            "loss: 0.408203125, time: 2024-12-03 23:57:42.551075, step: 906\n",
            "loss: 0.384765625, time: 2024-12-03 23:57:43.140880, step: 907\n",
            "loss: 0.39453125, time: 2024-12-03 23:57:43.731547, step: 908\n",
            "loss: 0.419921875, time: 2024-12-03 23:57:44.322316, step: 909\n",
            "loss: 0.40625, time: 2024-12-03 23:57:44.912159, step: 910\n",
            "loss: 0.396484375, time: 2024-12-03 23:57:45.504206, step: 911\n",
            "loss: 0.396484375, time: 2024-12-03 23:57:46.094154, step: 912\n",
            "loss: 0.388671875, time: 2024-12-03 23:57:46.684365, step: 913\n",
            "loss: 0.41796875, time: 2024-12-03 23:57:47.274801, step: 914\n",
            "loss: 0.396484375, time: 2024-12-03 23:57:47.864639, step: 915\n",
            "loss: 0.380859375, time: 2024-12-03 23:57:48.454164, step: 916\n",
            "loss: 0.421875, time: 2024-12-03 23:57:49.043959, step: 917\n",
            "loss: 0.369140625, time: 2024-12-03 23:57:49.633996, step: 918\n",
            "loss: 0.40625, time: 2024-12-03 23:57:50.223816, step: 919\n",
            "loss: 0.3828125, time: 2024-12-03 23:57:50.813952, step: 920\n",
            "----- Time -> 2024-12-03 23:58:14.460961 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.39453125, time: 2024-12-03 23:58:14.733273, step: 921\n",
            "loss: 0.404296875, time: 2024-12-03 23:58:15.323273, step: 922\n",
            "loss: 0.388671875, time: 2024-12-03 23:58:15.913091, step: 923\n",
            "loss: 0.380859375, time: 2024-12-03 23:58:16.503072, step: 924\n",
            "loss: 0.37109375, time: 2024-12-03 23:58:17.092686, step: 925\n",
            "loss: 0.400390625, time: 2024-12-03 23:58:17.682456, step: 926\n",
            "loss: 0.396484375, time: 2024-12-03 23:58:18.272371, step: 927\n",
            "loss: 0.3984375, time: 2024-12-03 23:58:18.863024, step: 928\n",
            "loss: 0.388671875, time: 2024-12-03 23:58:19.452933, step: 929\n",
            "loss: 0.392578125, time: 2024-12-03 23:58:20.042826, step: 930\n",
            "loss: 0.408203125, time: 2024-12-03 23:58:20.633647, step: 931\n",
            "loss: 0.384765625, time: 2024-12-03 23:58:21.224170, step: 932\n",
            "loss: 0.392578125, time: 2024-12-03 23:58:21.814422, step: 933\n",
            "loss: 0.38671875, time: 2024-12-03 23:58:22.405229, step: 934\n",
            "loss: 0.404296875, time: 2024-12-03 23:58:22.995066, step: 935\n",
            "loss: 0.39453125, time: 2024-12-03 23:58:23.584799, step: 936\n",
            "loss: 0.396484375, time: 2024-12-03 23:58:24.175156, step: 937\n",
            "loss: 0.427734375, time: 2024-12-03 23:58:24.764909, step: 938\n",
            "loss: 0.376953125, time: 2024-12-03 23:58:25.354900, step: 939\n",
            "loss: 0.392578125, time: 2024-12-03 23:58:25.946026, step: 940\n",
            "----- Time -> 2024-12-03 23:58:49.533486 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3984375, time: 2024-12-03 23:58:49.821838, step: 941\n",
            "loss: 0.388671875, time: 2024-12-03 23:58:50.412108, step: 942\n",
            "loss: 0.373046875, time: 2024-12-03 23:58:51.001657, step: 943\n",
            "loss: 0.396484375, time: 2024-12-03 23:58:51.591556, step: 944\n",
            "loss: 0.3828125, time: 2024-12-03 23:58:52.181237, step: 945\n",
            "loss: 0.392578125, time: 2024-12-03 23:58:52.770995, step: 946\n",
            "loss: 0.388671875, time: 2024-12-03 23:58:53.361546, step: 947\n",
            "loss: 0.404296875, time: 2024-12-03 23:58:53.951308, step: 948\n",
            "loss: 0.373046875, time: 2024-12-03 23:58:54.540815, step: 949\n",
            "loss: 0.40625, time: 2024-12-03 23:58:55.130797, step: 950\n",
            "loss: 0.388671875, time: 2024-12-03 23:58:55.720650, step: 951\n",
            "loss: 0.419921875, time: 2024-12-03 23:58:56.310987, step: 952\n",
            "loss: 0.423828125, time: 2024-12-03 23:58:56.900912, step: 953\n",
            "loss: 0.37109375, time: 2024-12-03 23:58:57.490662, step: 954\n",
            "loss: 0.3828125, time: 2024-12-03 23:58:58.080551, step: 955\n",
            "loss: 0.41796875, time: 2024-12-03 23:58:58.671525, step: 956\n",
            "loss: 0.373046875, time: 2024-12-03 23:58:59.261356, step: 957\n",
            "loss: 0.384765625, time: 2024-12-03 23:58:59.851637, step: 958\n",
            "loss: 0.390625, time: 2024-12-03 23:59:00.443513, step: 959\n",
            "loss: 0.390625, time: 2024-12-03 23:59:01.033773, step: 960\n",
            "----- Time -> 2024-12-03 23:59:24.644151 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.359375, time: 2024-12-03 23:59:24.913977, step: 961\n",
            "loss: 0.37109375, time: 2024-12-03 23:59:25.503921, step: 962\n",
            "loss: 0.419921875, time: 2024-12-03 23:59:26.093489, step: 963\n",
            "loss: 0.3828125, time: 2024-12-03 23:59:26.724529, step: 964\n",
            "loss: 0.376953125, time: 2024-12-03 23:59:27.315922, step: 965\n",
            "loss: 0.40234375, time: 2024-12-03 23:59:27.905827, step: 966\n",
            "loss: 0.390625, time: 2024-12-03 23:59:28.495508, step: 967\n",
            "loss: 0.37890625, time: 2024-12-03 23:59:29.085482, step: 968\n",
            "loss: 0.390625, time: 2024-12-03 23:59:29.675359, step: 969\n",
            "loss: 0.39453125, time: 2024-12-03 23:59:30.265096, step: 970\n",
            "loss: 0.3828125, time: 2024-12-03 23:59:30.855468, step: 971\n",
            "loss: 0.390625, time: 2024-12-03 23:59:31.445215, step: 972\n",
            "loss: 0.40234375, time: 2024-12-03 23:59:32.034929, step: 973\n",
            "loss: 0.375, time: 2024-12-03 23:59:32.625129, step: 974\n",
            "loss: 0.4140625, time: 2024-12-03 23:59:33.214510, step: 975\n",
            "loss: 0.419921875, time: 2024-12-03 23:59:33.804528, step: 976\n",
            "loss: 0.408203125, time: 2024-12-03 23:59:34.394477, step: 977\n",
            "loss: 0.396484375, time: 2024-12-03 23:59:34.983855, step: 978\n",
            "loss: 0.4296875, time: 2024-12-03 23:59:35.573648, step: 979\n",
            "loss: 0.376953125, time: 2024-12-03 23:59:36.164870, step: 980\n",
            "----- Time -> 2024-12-03 23:59:59.849254 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-04 00:00:00.118294, step: 981\n",
            "loss: 0.396484375, time: 2024-12-04 00:00:00.708823, step: 982\n",
            "loss: 0.39453125, time: 2024-12-04 00:00:01.299267, step: 983\n",
            "loss: 0.44140625, time: 2024-12-04 00:00:01.890208, step: 984\n",
            "loss: 0.42578125, time: 2024-12-04 00:00:02.480561, step: 985\n",
            "loss: 0.396484375, time: 2024-12-04 00:00:03.070545, step: 986\n",
            "loss: 0.38671875, time: 2024-12-04 00:00:03.660827, step: 987\n",
            "loss: 0.421875, time: 2024-12-04 00:00:04.251348, step: 988\n",
            "loss: 0.38671875, time: 2024-12-04 00:00:04.841247, step: 989\n",
            "loss: 0.380859375, time: 2024-12-04 00:00:05.431763, step: 990\n",
            "loss: 0.38671875, time: 2024-12-04 00:00:06.021401, step: 991\n",
            "loss: 0.412109375, time: 2024-12-04 00:00:06.611097, step: 992\n",
            "loss: 0.390625, time: 2024-12-04 00:00:07.201728, step: 993\n",
            "loss: 0.3671875, time: 2024-12-04 00:00:07.791619, step: 994\n",
            "loss: 0.376953125, time: 2024-12-04 00:00:08.381368, step: 995\n",
            "loss: 0.388671875, time: 2024-12-04 00:00:08.971228, step: 996\n",
            "loss: 0.392578125, time: 2024-12-04 00:00:09.560781, step: 997\n",
            "loss: 0.3828125, time: 2024-12-04 00:00:10.150589, step: 998\n",
            "loss: 0.400390625, time: 2024-12-04 00:00:10.740299, step: 999\n",
            "loss: 0.400390625, time: 2024-12-04 00:00:11.330683, step: 1000\n",
            "----- Time -> 2024-12-04 00:00:34.940222 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.38671875, time: 2024-12-04 00:00:35.221517, step: 1001\n",
            "loss: 0.388671875, time: 2024-12-04 00:00:35.811729, step: 1002\n",
            "loss: 0.388671875, time: 2024-12-04 00:00:36.401536, step: 1003\n",
            "loss: 0.40234375, time: 2024-12-04 00:00:36.991116, step: 1004\n",
            "loss: 0.392578125, time: 2024-12-04 00:00:37.580600, step: 1005\n",
            "loss: 0.388671875, time: 2024-12-04 00:00:38.170541, step: 1006\n",
            "loss: 0.384765625, time: 2024-12-04 00:00:38.760739, step: 1007\n",
            "loss: 0.41015625, time: 2024-12-04 00:00:39.351175, step: 1008\n",
            "loss: 0.419921875, time: 2024-12-04 00:00:39.941361, step: 1009\n",
            "loss: 0.375, time: 2024-12-04 00:00:40.532076, step: 1010\n",
            "loss: 0.396484375, time: 2024-12-04 00:00:41.122303, step: 1011\n",
            "loss: 0.39453125, time: 2024-12-04 00:00:41.712530, step: 1012\n",
            "loss: 0.40234375, time: 2024-12-04 00:00:42.302504, step: 1013\n",
            "loss: 0.37890625, time: 2024-12-04 00:00:42.892526, step: 1014\n",
            "loss: 0.38671875, time: 2024-12-04 00:00:43.482306, step: 1015\n",
            "loss: 0.3828125, time: 2024-12-04 00:00:44.072526, step: 1016\n",
            "loss: 0.3984375, time: 2024-12-04 00:00:44.662513, step: 1017\n",
            "loss: 0.41796875, time: 2024-12-04 00:00:45.252488, step: 1018\n",
            "loss: 0.373046875, time: 2024-12-04 00:00:45.842946, step: 1019\n",
            "loss: 0.390625, time: 2024-12-04 00:00:46.432791, step: 1020\n",
            "----- Time -> 2024-12-04 00:01:09.868248 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40234375, time: 2024-12-04 00:01:10.159003, step: 1021\n",
            "loss: 0.384765625, time: 2024-12-04 00:01:10.749041, step: 1022\n",
            "loss: 0.392578125, time: 2024-12-04 00:01:11.338818, step: 1023\n",
            "loss: 0.419921875, time: 2024-12-04 00:01:11.928584, step: 1024\n",
            "loss: 0.37109375, time: 2024-12-04 00:01:12.518222, step: 1025\n",
            "loss: 0.40625, time: 2024-12-04 00:01:13.108232, step: 1026\n",
            "loss: 0.390625, time: 2024-12-04 00:01:13.697982, step: 1027\n",
            "loss: 0.41015625, time: 2024-12-04 00:01:14.288353, step: 1028\n",
            "loss: 0.376953125, time: 2024-12-04 00:01:14.878353, step: 1029\n",
            "loss: 0.392578125, time: 2024-12-04 00:01:15.468194, step: 1030\n",
            "loss: 0.388671875, time: 2024-12-04 00:01:16.058278, step: 1031\n",
            "loss: 0.38671875, time: 2024-12-04 00:01:16.648102, step: 1032\n",
            "loss: 0.419921875, time: 2024-12-04 00:01:17.238172, step: 1033\n",
            "loss: 0.384765625, time: 2024-12-04 00:01:17.828467, step: 1034\n",
            "loss: 0.375, time: 2024-12-04 00:01:18.418168, step: 1035\n",
            "loss: 0.390625, time: 2024-12-04 00:01:19.008732, step: 1036\n",
            "loss: 0.384765625, time: 2024-12-04 00:01:19.598369, step: 1037\n",
            "loss: 0.37890625, time: 2024-12-04 00:01:20.188312, step: 1038\n",
            "loss: 0.400390625, time: 2024-12-04 00:01:20.778145, step: 1039\n",
            "loss: 0.39453125, time: 2024-12-04 00:01:21.368591, step: 1040\n",
            "----- Time -> 2024-12-04 00:01:44.440398 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.37890625, time: 2024-12-04 00:01:44.732735, step: 1041\n",
            "loss: 0.380859375, time: 2024-12-04 00:01:45.323454, step: 1042\n",
            "loss: 0.375, time: 2024-12-04 00:01:45.913667, step: 1043\n",
            "loss: 0.369140625, time: 2024-12-04 00:01:46.504160, step: 1044\n",
            "loss: 0.37890625, time: 2024-12-04 00:01:47.094057, step: 1045\n",
            "loss: 0.41015625, time: 2024-12-04 00:01:47.683954, step: 1046\n",
            "loss: 0.380859375, time: 2024-12-04 00:01:48.274457, step: 1047\n",
            "loss: 0.380859375, time: 2024-12-04 00:01:48.864242, step: 1048\n",
            "loss: 0.3671875, time: 2024-12-04 00:01:49.453987, step: 1049\n",
            "loss: 0.3828125, time: 2024-12-04 00:01:50.043817, step: 1050\n",
            "loss: 0.3984375, time: 2024-12-04 00:01:50.634076, step: 1051\n",
            "loss: 0.400390625, time: 2024-12-04 00:01:51.223842, step: 1052\n",
            "loss: 0.37109375, time: 2024-12-04 00:01:51.814284, step: 1053\n",
            "loss: 0.427734375, time: 2024-12-04 00:01:52.404104, step: 1054\n",
            "loss: 0.408203125, time: 2024-12-04 00:01:52.994166, step: 1055\n",
            "loss: 0.4453125, time: 2024-12-04 00:01:53.584376, step: 1056\n",
            "loss: 0.384765625, time: 2024-12-04 00:01:54.175210, step: 1057\n",
            "loss: 0.4453125, time: 2024-12-04 00:01:54.765585, step: 1058\n",
            "loss: 0.37109375, time: 2024-12-04 00:01:55.356186, step: 1059\n",
            "loss: 0.3828125, time: 2024-12-04 00:01:55.946125, step: 1060\n",
            "----- Time -> 2024-12-04 00:02:19.452314 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.41015625, time: 2024-12-04 00:02:19.737505, step: 1061\n",
            "loss: 0.38671875, time: 2024-12-04 00:02:20.327973, step: 1062\n",
            "loss: 0.38671875, time: 2024-12-04 00:02:20.917585, step: 1063\n",
            "loss: 0.396484375, time: 2024-12-04 00:02:21.507294, step: 1064\n",
            "loss: 0.376953125, time: 2024-12-04 00:02:22.097087, step: 1065\n",
            "loss: 0.400390625, time: 2024-12-04 00:02:22.687079, step: 1066\n",
            "loss: 0.392578125, time: 2024-12-04 00:02:23.277156, step: 1067\n",
            "loss: 0.38671875, time: 2024-12-04 00:02:23.866992, step: 1068\n",
            "loss: 0.3984375, time: 2024-12-04 00:02:24.456564, step: 1069\n",
            "loss: 0.376953125, time: 2024-12-04 00:02:25.046636, step: 1070\n",
            "loss: 0.396484375, time: 2024-12-04 00:02:25.636440, step: 1071\n",
            "loss: 0.458984375, time: 2024-12-04 00:02:26.226229, step: 1072\n",
            "loss: 0.40234375, time: 2024-12-04 00:02:26.816272, step: 1073\n",
            "loss: 0.380859375, time: 2024-12-04 00:02:27.406004, step: 1074\n",
            "loss: 0.388671875, time: 2024-12-04 00:02:27.995811, step: 1075\n",
            "loss: 0.3828125, time: 2024-12-04 00:02:28.586297, step: 1076\n",
            "loss: 0.380859375, time: 2024-12-04 00:02:29.176438, step: 1077\n",
            "loss: 0.404296875, time: 2024-12-04 00:02:29.766900, step: 1078\n",
            "loss: 0.408203125, time: 2024-12-04 00:02:30.357269, step: 1079\n",
            "loss: 0.380859375, time: 2024-12-04 00:02:30.946942, step: 1080\n",
            "----- Time -> 2024-12-04 00:02:54.474500 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3984375, time: 2024-12-04 00:02:54.754655, step: 1081\n",
            "loss: 0.392578125, time: 2024-12-04 00:02:55.344842, step: 1082\n",
            "loss: 0.3984375, time: 2024-12-04 00:02:55.935333, step: 1083\n",
            "loss: 0.41015625, time: 2024-12-04 00:02:56.525189, step: 1084\n",
            "loss: 0.37890625, time: 2024-12-04 00:02:57.115427, step: 1085\n",
            "loss: 0.37109375, time: 2024-12-04 00:02:57.705188, step: 1086\n",
            "loss: 0.37890625, time: 2024-12-04 00:02:58.295068, step: 1087\n",
            "loss: 0.427734375, time: 2024-12-04 00:02:58.885037, step: 1088\n",
            "loss: 0.4453125, time: 2024-12-04 00:02:59.474836, step: 1089\n",
            "loss: 0.439453125, time: 2024-12-04 00:03:00.065008, step: 1090\n",
            "loss: 0.37890625, time: 2024-12-04 00:03:00.654956, step: 1091\n",
            "loss: 0.419921875, time: 2024-12-04 00:03:01.246078, step: 1092\n",
            "loss: 0.392578125, time: 2024-12-04 00:03:01.836590, step: 1093\n",
            "loss: 0.380859375, time: 2024-12-04 00:03:02.426722, step: 1094\n",
            "loss: 0.396484375, time: 2024-12-04 00:03:03.016413, step: 1095\n",
            "loss: 0.404296875, time: 2024-12-04 00:03:03.606393, step: 1096\n",
            "loss: 0.38671875, time: 2024-12-04 00:03:04.196279, step: 1097\n",
            "loss: 0.38671875, time: 2024-12-04 00:03:04.786043, step: 1098\n",
            "loss: 0.396484375, time: 2024-12-04 00:03:05.375908, step: 1099\n",
            "loss: 0.390625, time: 2024-12-04 00:03:05.966120, step: 1100\n",
            "----- Time -> 2024-12-04 00:03:29.606115 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.39453125, time: 2024-12-04 00:03:29.895144, step: 1101\n",
            "loss: 0.3984375, time: 2024-12-04 00:03:30.484994, step: 1102\n",
            "loss: 0.3984375, time: 2024-12-04 00:03:31.074484, step: 1103\n",
            "loss: 0.392578125, time: 2024-12-04 00:03:31.665014, step: 1104\n",
            "loss: 0.375, time: 2024-12-04 00:03:32.255111, step: 1105\n",
            "loss: 0.384765625, time: 2024-12-04 00:03:32.845381, step: 1106\n",
            "loss: 0.39453125, time: 2024-12-04 00:03:33.435656, step: 1107\n",
            "loss: 0.388671875, time: 2024-12-04 00:03:34.025371, step: 1108\n",
            "loss: 0.38671875, time: 2024-12-04 00:03:34.615777, step: 1109\n",
            "loss: 0.408203125, time: 2024-12-04 00:03:35.206740, step: 1110\n",
            "loss: 0.37890625, time: 2024-12-04 00:03:35.796417, step: 1111\n",
            "loss: 0.416015625, time: 2024-12-04 00:03:36.386239, step: 1112\n",
            "loss: 0.376953125, time: 2024-12-04 00:03:36.976228, step: 1113\n",
            "loss: 0.37109375, time: 2024-12-04 00:03:37.565749, step: 1114\n",
            "loss: 0.37890625, time: 2024-12-04 00:03:38.155231, step: 1115\n",
            "loss: 0.388671875, time: 2024-12-04 00:03:38.745033, step: 1116\n",
            "loss: 0.39453125, time: 2024-12-04 00:03:39.335066, step: 1117\n",
            "loss: 0.412109375, time: 2024-12-04 00:03:39.924796, step: 1118\n",
            "loss: 0.396484375, time: 2024-12-04 00:03:40.514527, step: 1119\n",
            "loss: 0.412109375, time: 2024-12-04 00:03:41.104457, step: 1120\n",
            "----- Time -> 2024-12-04 00:04:04.869221 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.400390625, time: 2024-12-04 00:04:05.146284, step: 1121\n",
            "loss: 0.412109375, time: 2024-12-04 00:04:05.736329, step: 1122\n",
            "loss: 0.390625, time: 2024-12-04 00:04:06.326492, step: 1123\n",
            "loss: 0.396484375, time: 2024-12-04 00:04:06.916301, step: 1124\n",
            "loss: 0.3828125, time: 2024-12-04 00:04:07.506189, step: 1125\n",
            "loss: 0.39453125, time: 2024-12-04 00:04:08.096382, step: 1126\n",
            "loss: 0.3828125, time: 2024-12-04 00:04:08.686388, step: 1127\n",
            "loss: 0.392578125, time: 2024-12-04 00:04:09.276543, step: 1128\n",
            "loss: 0.376953125, time: 2024-12-04 00:04:09.867030, step: 1129\n",
            "loss: 0.384765625, time: 2024-12-04 00:04:10.457296, step: 1130\n",
            "loss: 0.384765625, time: 2024-12-04 00:04:11.047454, step: 1131\n",
            "loss: 0.38671875, time: 2024-12-04 00:04:11.638334, step: 1132\n",
            "loss: 0.384765625, time: 2024-12-04 00:04:12.229103, step: 1133\n",
            "loss: 0.37890625, time: 2024-12-04 00:04:12.819300, step: 1134\n",
            "loss: 0.396484375, time: 2024-12-04 00:04:13.409270, step: 1135\n",
            "loss: 0.400390625, time: 2024-12-04 00:04:13.999250, step: 1136\n",
            "loss: 0.390625, time: 2024-12-04 00:04:14.589536, step: 1137\n",
            "loss: 0.41015625, time: 2024-12-04 00:04:15.179923, step: 1138\n",
            "loss: 0.37890625, time: 2024-12-04 00:04:15.770082, step: 1139\n",
            "loss: 0.376953125, time: 2024-12-04 00:04:16.360174, step: 1140\n",
            "----- Time -> 2024-12-04 00:04:40.146741 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.37890625, time: 2024-12-04 00:04:40.439930, step: 1141\n",
            "loss: 0.3828125, time: 2024-12-04 00:04:41.030704, step: 1142\n",
            "loss: 0.376953125, time: 2024-12-04 00:04:41.621338, step: 1143\n",
            "loss: 0.3984375, time: 2024-12-04 00:04:42.211436, step: 1144\n",
            "loss: 0.400390625, time: 2024-12-04 00:04:42.801679, step: 1145\n",
            "loss: 0.400390625, time: 2024-12-04 00:04:43.391950, step: 1146\n",
            "loss: 0.375, time: 2024-12-04 00:04:43.982315, step: 1147\n",
            "loss: 0.380859375, time: 2024-12-04 00:04:44.572602, step: 1148\n",
            "loss: 0.388671875, time: 2024-12-04 00:04:45.163056, step: 1149\n",
            "loss: 0.40625, time: 2024-12-04 00:04:45.753488, step: 1150\n",
            "loss: 0.41015625, time: 2024-12-04 00:04:46.343762, step: 1151\n",
            "loss: 0.384765625, time: 2024-12-04 00:04:46.934333, step: 1152\n",
            "loss: 0.40625, time: 2024-12-04 00:04:47.524419, step: 1153\n",
            "loss: 0.376953125, time: 2024-12-04 00:04:48.114945, step: 1154\n",
            "loss: 0.396484375, time: 2024-12-04 00:04:48.706155, step: 1155\n",
            "loss: 0.392578125, time: 2024-12-04 00:04:49.296957, step: 1156\n",
            "loss: 0.38671875, time: 2024-12-04 00:04:49.887422, step: 1157\n",
            "loss: 0.38671875, time: 2024-12-04 00:04:50.478444, step: 1158\n",
            "loss: 0.388671875, time: 2024-12-04 00:04:51.068903, step: 1159\n",
            "loss: 0.44140625, time: 2024-12-04 00:04:51.659316, step: 1160\n",
            "----- Time -> 2024-12-04 00:05:15.337269 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.4140625, time: 2024-12-04 00:05:15.628952, step: 1161\n",
            "loss: 0.392578125, time: 2024-12-04 00:05:16.219515, step: 1162\n",
            "loss: 0.388671875, time: 2024-12-04 00:05:16.809693, step: 1163\n",
            "loss: 0.375, time: 2024-12-04 00:05:17.400008, step: 1164\n",
            "loss: 0.3984375, time: 2024-12-04 00:05:17.990506, step: 1165\n",
            "loss: 0.3828125, time: 2024-12-04 00:05:18.581377, step: 1166\n",
            "loss: 0.392578125, time: 2024-12-04 00:05:19.171611, step: 1167\n",
            "loss: 0.39453125, time: 2024-12-04 00:05:19.761907, step: 1168\n",
            "loss: 0.423828125, time: 2024-12-04 00:05:20.352436, step: 1169\n",
            "loss: 0.37109375, time: 2024-12-04 00:05:20.942538, step: 1170\n",
            "loss: 0.3828125, time: 2024-12-04 00:05:21.533184, step: 1171\n",
            "loss: 0.412109375, time: 2024-12-04 00:05:22.124135, step: 1172\n",
            "loss: 0.380859375, time: 2024-12-04 00:05:22.714345, step: 1173\n",
            "loss: 0.412109375, time: 2024-12-04 00:05:23.304351, step: 1174\n",
            "loss: 0.396484375, time: 2024-12-04 00:05:23.895271, step: 1175\n",
            "loss: 0.388671875, time: 2024-12-04 00:05:24.485680, step: 1176\n",
            "loss: 0.388671875, time: 2024-12-04 00:05:25.076320, step: 1177\n",
            "loss: 0.392578125, time: 2024-12-04 00:05:25.666577, step: 1178\n",
            "loss: 0.404296875, time: 2024-12-04 00:05:26.256820, step: 1179\n",
            "loss: 0.4140625, time: 2024-12-04 00:05:26.847193, step: 1180\n",
            "----- Time -> 2024-12-04 00:05:50.752451 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.396484375, time: 2024-12-04 00:05:51.040164, step: 1181\n",
            "loss: 0.419921875, time: 2024-12-04 00:05:51.630815, step: 1182\n",
            "loss: 0.404296875, time: 2024-12-04 00:05:52.221567, step: 1183\n",
            "loss: 0.384765625, time: 2024-12-04 00:05:52.811912, step: 1184\n",
            "loss: 0.369140625, time: 2024-12-04 00:05:53.402101, step: 1185\n",
            "loss: 0.408203125, time: 2024-12-04 00:05:53.992463, step: 1186\n",
            "loss: 0.380859375, time: 2024-12-04 00:05:54.582572, step: 1187\n",
            "loss: 0.40234375, time: 2024-12-04 00:05:55.172704, step: 1188\n",
            "loss: 0.396484375, time: 2024-12-04 00:05:55.762905, step: 1189\n",
            "loss: 0.388671875, time: 2024-12-04 00:05:56.353268, step: 1190\n",
            "loss: 0.390625, time: 2024-12-04 00:05:56.943423, step: 1191\n",
            "loss: 0.388671875, time: 2024-12-04 00:05:57.533988, step: 1192\n",
            "loss: 0.39453125, time: 2024-12-04 00:05:58.124249, step: 1193\n",
            "loss: 0.3671875, time: 2024-12-04 00:05:58.715223, step: 1194\n",
            "loss: 0.37890625, time: 2024-12-04 00:05:59.305842, step: 1195\n",
            "loss: 0.3984375, time: 2024-12-04 00:05:59.896497, step: 1196\n",
            "loss: 0.390625, time: 2024-12-04 00:06:00.486651, step: 1197\n",
            "loss: 0.392578125, time: 2024-12-04 00:06:01.077475, step: 1198\n",
            "loss: 0.388671875, time: 2024-12-04 00:06:01.667978, step: 1199\n",
            "loss: 0.40234375, time: 2024-12-04 00:06:02.258319, step: 1200\n",
            "----- Time -> 2024-12-04 00:06:25.992372 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-04 00:06:26.272166, step: 1201\n",
            "loss: 0.3828125, time: 2024-12-04 00:06:26.862463, step: 1202\n",
            "loss: 0.384765625, time: 2024-12-04 00:06:27.452803, step: 1203\n",
            "loss: 0.3828125, time: 2024-12-04 00:06:28.043264, step: 1204\n",
            "loss: 0.38671875, time: 2024-12-04 00:06:28.633864, step: 1205\n",
            "loss: 0.41796875, time: 2024-12-04 00:06:29.224507, step: 1206\n",
            "loss: 0.37890625, time: 2024-12-04 00:06:29.815290, step: 1207\n",
            "loss: 0.39453125, time: 2024-12-04 00:06:30.405631, step: 1208\n",
            "loss: 0.37890625, time: 2024-12-04 00:06:30.996068, step: 1209\n",
            "loss: 0.376953125, time: 2024-12-04 00:06:31.586350, step: 1210\n",
            "loss: 0.408203125, time: 2024-12-04 00:06:32.176973, step: 1211\n",
            "loss: 0.3984375, time: 2024-12-04 00:06:32.767231, step: 1212\n",
            "loss: 0.392578125, time: 2024-12-04 00:06:33.357515, step: 1213\n",
            "loss: 0.4296875, time: 2024-12-04 00:06:33.947905, step: 1214\n",
            "loss: 0.38671875, time: 2024-12-04 00:06:34.537931, step: 1215\n",
            "loss: 0.38671875, time: 2024-12-04 00:06:35.128190, step: 1216\n",
            "loss: 0.421875, time: 2024-12-04 00:06:35.718311, step: 1217\n",
            "loss: 0.37109375, time: 2024-12-04 00:06:36.308225, step: 1218\n",
            "loss: 0.37890625, time: 2024-12-04 00:06:36.899040, step: 1219\n",
            "loss: 0.388671875, time: 2024-12-04 00:06:37.489319, step: 1220\n",
            "----- Time -> 2024-12-04 00:07:00.977799 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.388671875, time: 2024-12-04 00:07:01.255237, step: 1221\n",
            "loss: 0.37109375, time: 2024-12-04 00:07:01.845543, step: 1222\n",
            "loss: 0.40234375, time: 2024-12-04 00:07:02.435636, step: 1223\n",
            "loss: 0.380859375, time: 2024-12-04 00:07:03.025607, step: 1224\n",
            "loss: 0.384765625, time: 2024-12-04 00:07:03.615621, step: 1225\n",
            "loss: 0.37109375, time: 2024-12-04 00:07:04.205276, step: 1226\n",
            "loss: 0.404296875, time: 2024-12-04 00:07:04.795464, step: 1227\n",
            "loss: 0.37109375, time: 2024-12-04 00:07:05.385950, step: 1228\n",
            "loss: 0.40625, time: 2024-12-04 00:07:05.975818, step: 1229\n",
            "loss: 0.4296875, time: 2024-12-04 00:07:06.566904, step: 1230\n",
            "loss: 0.392578125, time: 2024-12-04 00:07:07.157506, step: 1231\n",
            "loss: 0.400390625, time: 2024-12-04 00:07:07.747581, step: 1232\n",
            "loss: 0.384765625, time: 2024-12-04 00:07:08.338451, step: 1233\n",
            "loss: 0.404296875, time: 2024-12-04 00:07:08.928276, step: 1234\n",
            "loss: 0.392578125, time: 2024-12-04 00:07:09.518211, step: 1235\n",
            "loss: 0.3984375, time: 2024-12-04 00:07:10.108576, step: 1236\n",
            "loss: 0.390625, time: 2024-12-04 00:07:10.699334, step: 1237\n",
            "loss: 0.3828125, time: 2024-12-04 00:07:11.289505, step: 1238\n",
            "loss: 0.384765625, time: 2024-12-04 00:07:11.880208, step: 1239\n",
            "loss: 0.396484375, time: 2024-12-04 00:07:12.470358, step: 1240\n",
            "----- Time -> 2024-12-04 00:07:36.334772 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-04 00:07:36.616984, step: 1241\n",
            "loss: 0.39453125, time: 2024-12-04 00:07:37.206786, step: 1242\n",
            "loss: 0.384765625, time: 2024-12-04 00:07:37.797014, step: 1243\n",
            "loss: 0.380859375, time: 2024-12-04 00:07:38.399738, step: 1244\n",
            "loss: 0.380859375, time: 2024-12-04 00:07:38.990130, step: 1245\n",
            "loss: 0.376953125, time: 2024-12-04 00:07:39.579914, step: 1246\n",
            "loss: 0.412109375, time: 2024-12-04 00:07:40.170429, step: 1247\n",
            "loss: 0.388671875, time: 2024-12-04 00:07:40.760626, step: 1248\n",
            "loss: 0.38671875, time: 2024-12-04 00:07:41.351402, step: 1249\n",
            "loss: 0.400390625, time: 2024-12-04 00:07:41.941530, step: 1250\n",
            "loss: 0.40625, time: 2024-12-04 00:07:42.532648, step: 1251\n",
            "loss: 0.400390625, time: 2024-12-04 00:07:43.122796, step: 1252\n",
            "loss: 0.37890625, time: 2024-12-04 00:07:43.712855, step: 1253\n",
            "loss: 0.39453125, time: 2024-12-04 00:07:44.302930, step: 1254\n",
            "loss: 0.41015625, time: 2024-12-04 00:07:44.893155, step: 1255\n",
            "loss: 0.390625, time: 2024-12-04 00:07:45.483350, step: 1256\n",
            "loss: 0.3828125, time: 2024-12-04 00:07:46.073536, step: 1257\n",
            "loss: 0.38671875, time: 2024-12-04 00:07:46.663462, step: 1258\n",
            "loss: 0.3984375, time: 2024-12-04 00:07:47.253939, step: 1259\n",
            "loss: 0.38671875, time: 2024-12-04 00:07:47.843770, step: 1260\n",
            "----- Time -> 2024-12-04 00:08:11.401870 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40234375, time: 2024-12-04 00:08:11.672553, step: 1261\n",
            "loss: 0.41796875, time: 2024-12-04 00:08:12.262844, step: 1262\n",
            "loss: 0.380859375, time: 2024-12-04 00:08:12.853507, step: 1263\n",
            "loss: 0.396484375, time: 2024-12-04 00:08:13.443843, step: 1264\n",
            "loss: 0.3828125, time: 2024-12-04 00:08:14.034613, step: 1265\n",
            "loss: 0.41015625, time: 2024-12-04 00:08:14.624700, step: 1266\n",
            "loss: 0.384765625, time: 2024-12-04 00:08:15.214953, step: 1267\n",
            "loss: 0.390625, time: 2024-12-04 00:08:15.805650, step: 1268\n",
            "loss: 0.392578125, time: 2024-12-04 00:08:16.395647, step: 1269\n",
            "loss: 0.392578125, time: 2024-12-04 00:08:16.985762, step: 1270\n",
            "loss: 0.392578125, time: 2024-12-04 00:08:17.575914, step: 1271\n",
            "loss: 0.3828125, time: 2024-12-04 00:08:18.165913, step: 1272\n",
            "loss: 0.359375, time: 2024-12-04 00:08:18.756041, step: 1273\n",
            "loss: 0.38671875, time: 2024-12-04 00:08:19.346674, step: 1274\n",
            "loss: 0.37890625, time: 2024-12-04 00:08:19.937210, step: 1275\n",
            "loss: 0.376953125, time: 2024-12-04 00:08:20.528837, step: 1276\n",
            "loss: 0.388671875, time: 2024-12-04 00:08:21.119564, step: 1277\n",
            "loss: 0.408203125, time: 2024-12-04 00:08:21.709661, step: 1278\n",
            "loss: 0.396484375, time: 2024-12-04 00:08:22.299895, step: 1279\n",
            "loss: 0.390625, time: 2024-12-04 00:08:22.890238, step: 1280\n",
            "----- Time -> 2024-12-04 00:08:46.359470 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.39453125, time: 2024-12-04 00:08:46.635951, step: 1281\n",
            "loss: 0.3828125, time: 2024-12-04 00:08:47.225893, step: 1282\n",
            "loss: 0.38671875, time: 2024-12-04 00:08:47.816094, step: 1283\n",
            "loss: 0.37890625, time: 2024-12-04 00:08:48.405795, step: 1284\n",
            "loss: 0.373046875, time: 2024-12-04 00:08:48.995809, step: 1285\n",
            "loss: 0.400390625, time: 2024-12-04 00:08:49.586282, step: 1286\n",
            "loss: 0.380859375, time: 2024-12-04 00:08:50.176083, step: 1287\n",
            "loss: 0.3984375, time: 2024-12-04 00:08:50.765869, step: 1288\n",
            "loss: 0.3984375, time: 2024-12-04 00:08:51.355878, step: 1289\n",
            "loss: 0.40234375, time: 2024-12-04 00:08:51.946072, step: 1290\n",
            "loss: 0.37890625, time: 2024-12-04 00:08:52.536042, step: 1291\n",
            "loss: 0.38671875, time: 2024-12-04 00:08:53.125824, step: 1292\n",
            "loss: 0.404296875, time: 2024-12-04 00:08:53.715706, step: 1293\n",
            "loss: 0.390625, time: 2024-12-04 00:08:54.306204, step: 1294\n",
            "loss: 0.408203125, time: 2024-12-04 00:08:54.896655, step: 1295\n",
            "loss: 0.38671875, time: 2024-12-04 00:08:55.486844, step: 1296\n",
            "loss: 0.375, time: 2024-12-04 00:08:56.077154, step: 1297\n",
            "loss: 0.380859375, time: 2024-12-04 00:08:56.667658, step: 1298\n",
            "loss: 0.408203125, time: 2024-12-04 00:08:57.258056, step: 1299\n",
            "loss: 0.3984375, time: 2024-12-04 00:08:57.848648, step: 1300\n",
            "----- Time -> 2024-12-04 00:09:21.567851 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-04 00:09:21.841360, step: 1301\n",
            "loss: 0.361328125, time: 2024-12-04 00:09:22.431770, step: 1302\n",
            "loss: 0.375, time: 2024-12-04 00:09:23.021471, step: 1303\n",
            "loss: 0.3828125, time: 2024-12-04 00:09:23.611684, step: 1304\n",
            "loss: 0.41015625, time: 2024-12-04 00:09:24.202007, step: 1305\n",
            "loss: 0.404296875, time: 2024-12-04 00:09:24.791643, step: 1306\n",
            "loss: 0.400390625, time: 2024-12-04 00:09:25.381685, step: 1307\n",
            "loss: 0.369140625, time: 2024-12-04 00:09:25.971785, step: 1308\n",
            "loss: 0.3671875, time: 2024-12-04 00:09:26.562032, step: 1309\n",
            "loss: 0.3828125, time: 2024-12-04 00:09:27.151669, step: 1310\n",
            "loss: 0.3828125, time: 2024-12-04 00:09:27.741221, step: 1311\n",
            "loss: 0.423828125, time: 2024-12-04 00:09:28.331830, step: 1312\n",
            "loss: 0.40625, time: 2024-12-04 00:09:28.921753, step: 1313\n",
            "loss: 0.3984375, time: 2024-12-04 00:09:29.511652, step: 1314\n",
            "loss: 0.388671875, time: 2024-12-04 00:09:30.101896, step: 1315\n",
            "loss: 0.373046875, time: 2024-12-04 00:09:30.692046, step: 1316\n",
            "loss: 0.390625, time: 2024-12-04 00:09:31.282236, step: 1317\n",
            "loss: 0.38671875, time: 2024-12-04 00:09:31.872624, step: 1318\n",
            "loss: 0.388671875, time: 2024-12-04 00:09:32.462312, step: 1319\n",
            "loss: 0.421875, time: 2024-12-04 00:09:33.051966, step: 1320\n",
            "----- Time -> 2024-12-04 00:09:56.674723 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-04 00:09:56.959311, step: 1321\n",
            "loss: 0.38671875, time: 2024-12-04 00:09:57.550400, step: 1322\n",
            "loss: 0.390625, time: 2024-12-04 00:09:58.140520, step: 1323\n",
            "loss: 0.396484375, time: 2024-12-04 00:09:58.730679, step: 1324\n",
            "loss: 0.392578125, time: 2024-12-04 00:09:59.321227, step: 1325\n",
            "loss: 0.38671875, time: 2024-12-04 00:09:59.911354, step: 1326\n",
            "loss: 0.41015625, time: 2024-12-04 00:10:00.501606, step: 1327\n",
            "loss: 0.392578125, time: 2024-12-04 00:10:01.092360, step: 1328\n",
            "loss: 0.373046875, time: 2024-12-04 00:10:01.682647, step: 1329\n",
            "loss: 0.376953125, time: 2024-12-04 00:10:02.273073, step: 1330\n",
            "loss: 0.373046875, time: 2024-12-04 00:10:02.863596, step: 1331\n",
            "loss: 0.40234375, time: 2024-12-04 00:10:03.453544, step: 1332\n",
            "loss: 0.390625, time: 2024-12-04 00:10:04.043696, step: 1333\n",
            "loss: 0.376953125, time: 2024-12-04 00:10:04.634175, step: 1334\n",
            "loss: 0.4296875, time: 2024-12-04 00:10:05.224006, step: 1335\n",
            "loss: 0.412109375, time: 2024-12-04 00:10:05.814124, step: 1336\n",
            "loss: 0.38671875, time: 2024-12-04 00:10:06.404591, step: 1337\n",
            "loss: 0.40234375, time: 2024-12-04 00:10:06.994282, step: 1338\n",
            "loss: 0.390625, time: 2024-12-04 00:10:07.584083, step: 1339\n",
            "loss: 0.376953125, time: 2024-12-04 00:10:08.173723, step: 1340\n",
            "----- Time -> 2024-12-04 00:10:31.578061 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.37109375, time: 2024-12-04 00:10:31.844650, step: 1341\n",
            "loss: 0.380859375, time: 2024-12-04 00:10:32.434638, step: 1342\n",
            "loss: 0.388671875, time: 2024-12-04 00:10:33.024456, step: 1343\n",
            "loss: 0.388671875, time: 2024-12-04 00:10:33.614089, step: 1344\n",
            "loss: 0.392578125, time: 2024-12-04 00:10:34.204077, step: 1345\n",
            "loss: 0.37890625, time: 2024-12-04 00:10:34.794243, step: 1346\n",
            "loss: 0.388671875, time: 2024-12-04 00:10:35.384258, step: 1347\n",
            "loss: 0.392578125, time: 2024-12-04 00:10:35.974649, step: 1348\n",
            "loss: 0.380859375, time: 2024-12-04 00:10:36.564547, step: 1349\n",
            "loss: 0.388671875, time: 2024-12-04 00:10:37.154797, step: 1350\n",
            "loss: 0.3828125, time: 2024-12-04 00:10:37.744823, step: 1351\n",
            "loss: 0.380859375, time: 2024-12-04 00:10:38.335196, step: 1352\n",
            "loss: 0.3828125, time: 2024-12-04 00:10:38.925324, step: 1353\n",
            "loss: 0.37890625, time: 2024-12-04 00:10:39.515845, step: 1354\n",
            "loss: 0.3828125, time: 2024-12-04 00:10:40.105846, step: 1355\n",
            "loss: 0.408203125, time: 2024-12-04 00:10:40.696556, step: 1356\n",
            "loss: 0.39453125, time: 2024-12-04 00:10:41.287142, step: 1357\n",
            "loss: 0.37890625, time: 2024-12-04 00:10:41.877833, step: 1358\n",
            "loss: 0.419921875, time: 2024-12-04 00:10:42.467678, step: 1359\n",
            "loss: 0.388671875, time: 2024-12-04 00:10:43.058042, step: 1360\n",
            "----- Time -> 2024-12-04 00:11:06.630813 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.37109375, time: 2024-12-04 00:11:06.916344, step: 1361\n",
            "loss: 0.3828125, time: 2024-12-04 00:11:07.506973, step: 1362\n",
            "loss: 0.376953125, time: 2024-12-04 00:11:08.097328, step: 1363\n",
            "loss: 0.474609375, time: 2024-12-04 00:11:08.687685, step: 1364\n",
            "loss: 0.400390625, time: 2024-12-04 00:11:09.277956, step: 1365\n",
            "loss: 0.408203125, time: 2024-12-04 00:11:09.868287, step: 1366\n",
            "loss: 0.373046875, time: 2024-12-04 00:11:10.458580, step: 1367\n",
            "loss: 0.3984375, time: 2024-12-04 00:11:11.048783, step: 1368\n",
            "loss: 0.3828125, time: 2024-12-04 00:11:11.639600, step: 1369\n",
            "loss: 0.41015625, time: 2024-12-04 00:11:12.229835, step: 1370\n",
            "loss: 0.40625, time: 2024-12-04 00:11:12.820130, step: 1371\n",
            "loss: 0.384765625, time: 2024-12-04 00:11:13.410433, step: 1372\n",
            "loss: 0.390625, time: 2024-12-04 00:11:14.000638, step: 1373\n",
            "loss: 0.40625, time: 2024-12-04 00:11:14.591518, step: 1374\n",
            "loss: 0.416015625, time: 2024-12-04 00:11:15.182231, step: 1375\n",
            "loss: 0.37890625, time: 2024-12-04 00:11:15.772503, step: 1376\n",
            "loss: 0.388671875, time: 2024-12-04 00:11:16.362916, step: 1377\n",
            "loss: 0.384765625, time: 2024-12-04 00:11:16.953199, step: 1378\n",
            "loss: 0.404296875, time: 2024-12-04 00:11:17.543320, step: 1379\n",
            "loss: 0.400390625, time: 2024-12-04 00:11:18.133653, step: 1380\n",
            "----- Time -> 2024-12-04 00:11:41.738039 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3984375, time: 2024-12-04 00:11:42.006559, step: 1381\n",
            "loss: 0.3984375, time: 2024-12-04 00:11:42.596933, step: 1382\n",
            "loss: 0.408203125, time: 2024-12-04 00:11:43.187374, step: 1383\n",
            "loss: 0.392578125, time: 2024-12-04 00:11:43.777383, step: 1384\n",
            "loss: 0.388671875, time: 2024-12-04 00:11:44.367558, step: 1385\n",
            "loss: 0.3984375, time: 2024-12-04 00:11:44.957622, step: 1386\n",
            "loss: 0.390625, time: 2024-12-04 00:11:45.548423, step: 1387\n",
            "loss: 0.376953125, time: 2024-12-04 00:11:46.138622, step: 1388\n",
            "loss: 0.412109375, time: 2024-12-04 00:11:46.728931, step: 1389\n",
            "loss: 0.3828125, time: 2024-12-04 00:11:47.319160, step: 1390\n",
            "loss: 0.400390625, time: 2024-12-04 00:11:47.909371, step: 1391\n",
            "loss: 0.3984375, time: 2024-12-04 00:11:48.500159, step: 1392\n",
            "loss: 0.388671875, time: 2024-12-04 00:11:49.090769, step: 1393\n",
            "loss: 0.40625, time: 2024-12-04 00:11:49.681639, step: 1394\n",
            "loss: 0.392578125, time: 2024-12-04 00:11:50.272480, step: 1395\n",
            "loss: 0.373046875, time: 2024-12-04 00:11:50.863463, step: 1396\n",
            "loss: 0.3984375, time: 2024-12-04 00:11:51.454165, step: 1397\n",
            "loss: 0.38671875, time: 2024-12-04 00:11:52.044695, step: 1398\n",
            "loss: 0.388671875, time: 2024-12-04 00:11:52.635763, step: 1399\n",
            "loss: 0.369140625, time: 2024-12-04 00:11:53.226156, step: 1400\n",
            "----- Time -> 2024-12-04 00:12:16.608823 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.37109375, time: 2024-12-04 00:12:16.897839, step: 1401\n",
            "loss: 0.3828125, time: 2024-12-04 00:12:17.488538, step: 1402\n",
            "loss: 0.388671875, time: 2024-12-04 00:12:18.079576, step: 1403\n",
            "loss: 0.37890625, time: 2024-12-04 00:12:18.670074, step: 1404\n",
            "loss: 0.4140625, time: 2024-12-04 00:12:19.261361, step: 1405\n",
            "loss: 0.38671875, time: 2024-12-04 00:12:19.851750, step: 1406\n",
            "loss: 0.384765625, time: 2024-12-04 00:12:20.442039, step: 1407\n",
            "loss: 0.373046875, time: 2024-12-04 00:12:21.032841, step: 1408\n",
            "loss: 0.408203125, time: 2024-12-04 00:12:21.623119, step: 1409\n",
            "loss: 0.390625, time: 2024-12-04 00:12:22.213174, step: 1410\n",
            "loss: 0.388671875, time: 2024-12-04 00:12:22.803793, step: 1411\n",
            "loss: 0.39453125, time: 2024-12-04 00:12:23.394047, step: 1412\n",
            "loss: 0.38671875, time: 2024-12-04 00:12:23.984216, step: 1413\n",
            "loss: 0.37890625, time: 2024-12-04 00:12:24.575119, step: 1414\n",
            "loss: 0.3984375, time: 2024-12-04 00:12:25.164887, step: 1415\n",
            "loss: 0.3828125, time: 2024-12-04 00:12:25.754809, step: 1416\n",
            "loss: 0.392578125, time: 2024-12-04 00:12:26.345151, step: 1417\n",
            "loss: 0.392578125, time: 2024-12-04 00:12:26.935086, step: 1418\n",
            "loss: 0.37109375, time: 2024-12-04 00:12:27.525317, step: 1419\n",
            "loss: 0.3671875, time: 2024-12-04 00:12:28.115806, step: 1420\n",
            "----- Time -> 2024-12-04 00:12:51.679927 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.388671875, time: 2024-12-04 00:12:51.952922, step: 1421\n",
            "loss: 0.373046875, time: 2024-12-04 00:12:52.542890, step: 1422\n",
            "loss: 0.400390625, time: 2024-12-04 00:12:53.132873, step: 1423\n",
            "loss: 0.3828125, time: 2024-12-04 00:12:53.723193, step: 1424\n",
            "loss: 0.41796875, time: 2024-12-04 00:12:54.313637, step: 1425\n",
            "loss: 0.373046875, time: 2024-12-04 00:12:54.903644, step: 1426\n",
            "loss: 0.37890625, time: 2024-12-04 00:12:55.494230, step: 1427\n",
            "loss: 0.419921875, time: 2024-12-04 00:12:56.085158, step: 1428\n",
            "loss: 0.4375, time: 2024-12-04 00:12:56.675166, step: 1429\n",
            "loss: 0.396484375, time: 2024-12-04 00:12:57.265504, step: 1430\n",
            "loss: 0.40625, time: 2024-12-04 00:12:57.856231, step: 1431\n",
            "loss: 0.4375, time: 2024-12-04 00:12:58.446527, step: 1432\n",
            "loss: 0.41015625, time: 2024-12-04 00:12:59.036751, step: 1433\n",
            "loss: 0.3828125, time: 2024-12-04 00:12:59.626465, step: 1434\n",
            "loss: 0.3828125, time: 2024-12-04 00:13:00.217445, step: 1435\n",
            "loss: 0.3828125, time: 2024-12-04 00:13:00.808634, step: 1436\n",
            "loss: 0.408203125, time: 2024-12-04 00:13:01.398620, step: 1437\n",
            "loss: 0.39453125, time: 2024-12-04 00:13:01.989036, step: 1438\n",
            "loss: 0.3828125, time: 2024-12-04 00:13:02.578930, step: 1439\n",
            "loss: 0.3828125, time: 2024-12-04 00:13:03.169030, step: 1440\n",
            "----- Time -> 2024-12-04 00:13:26.896253 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.384765625, time: 2024-12-04 00:13:27.163830, step: 1441\n",
            "loss: 0.435546875, time: 2024-12-04 00:13:27.753978, step: 1442\n",
            "loss: 0.390625, time: 2024-12-04 00:13:28.344547, step: 1443\n",
            "loss: 0.3828125, time: 2024-12-04 00:13:28.934533, step: 1444\n",
            "loss: 0.37890625, time: 2024-12-04 00:13:29.524799, step: 1445\n",
            "loss: 0.400390625, time: 2024-12-04 00:13:30.114641, step: 1446\n",
            "loss: 0.373046875, time: 2024-12-04 00:13:30.704515, step: 1447\n",
            "loss: 0.38671875, time: 2024-12-04 00:13:31.294744, step: 1448\n",
            "loss: 0.392578125, time: 2024-12-04 00:13:31.884662, step: 1449\n",
            "loss: 0.39453125, time: 2024-12-04 00:13:32.474559, step: 1450\n",
            "loss: 0.384765625, time: 2024-12-04 00:13:33.065158, step: 1451\n",
            "loss: 0.3671875, time: 2024-12-04 00:13:33.656030, step: 1452\n",
            "loss: 0.392578125, time: 2024-12-04 00:13:34.246411, step: 1453\n",
            "loss: 0.384765625, time: 2024-12-04 00:13:34.836832, step: 1454\n",
            "loss: 0.390625, time: 2024-12-04 00:13:35.427069, step: 1455\n",
            "loss: 0.380859375, time: 2024-12-04 00:13:36.017017, step: 1456\n",
            "loss: 0.41015625, time: 2024-12-04 00:13:36.607483, step: 1457\n",
            "loss: 0.375, time: 2024-12-04 00:13:37.197553, step: 1458\n",
            "loss: 0.376953125, time: 2024-12-04 00:13:37.787859, step: 1459\n",
            "loss: 0.392578125, time: 2024-12-04 00:13:38.377910, step: 1460\n",
            "----- Time -> 2024-12-04 00:14:01.829168 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.37109375, time: 2024-12-04 00:14:02.105663, step: 1461\n",
            "loss: 0.3984375, time: 2024-12-04 00:14:02.695839, step: 1462\n",
            "loss: 0.39453125, time: 2024-12-04 00:14:03.286120, step: 1463\n",
            "loss: 0.359375, time: 2024-12-04 00:14:03.876386, step: 1464\n",
            "loss: 0.3984375, time: 2024-12-04 00:14:04.466146, step: 1465\n",
            "loss: 0.41015625, time: 2024-12-04 00:14:05.055729, step: 1466\n",
            "loss: 0.36328125, time: 2024-12-04 00:14:05.645846, step: 1467\n",
            "loss: 0.376953125, time: 2024-12-04 00:14:06.235628, step: 1468\n",
            "loss: 0.3828125, time: 2024-12-04 00:14:06.825469, step: 1469\n",
            "loss: 0.384765625, time: 2024-12-04 00:14:07.415135, step: 1470\n",
            "loss: 0.396484375, time: 2024-12-04 00:14:08.004773, step: 1471\n",
            "loss: 0.412109375, time: 2024-12-04 00:14:08.595379, step: 1472\n",
            "loss: 0.380859375, time: 2024-12-04 00:14:09.185905, step: 1473\n",
            "loss: 0.39453125, time: 2024-12-04 00:14:09.776162, step: 1474\n",
            "loss: 0.40625, time: 2024-12-04 00:14:10.367932, step: 1475\n",
            "loss: 0.373046875, time: 2024-12-04 00:14:10.958095, step: 1476\n",
            "loss: 0.392578125, time: 2024-12-04 00:14:11.549028, step: 1477\n",
            "loss: 0.392578125, time: 2024-12-04 00:14:12.139378, step: 1478\n",
            "loss: 0.40234375, time: 2024-12-04 00:14:12.729329, step: 1479\n",
            "loss: 0.412109375, time: 2024-12-04 00:14:13.319460, step: 1480\n",
            "----- Time -> 2024-12-04 00:14:37.016087 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.380859375, time: 2024-12-04 00:14:37.292293, step: 1481\n",
            "loss: 0.3671875, time: 2024-12-04 00:14:37.882691, step: 1482\n",
            "loss: 0.38671875, time: 2024-12-04 00:14:38.473004, step: 1483\n",
            "loss: 0.390625, time: 2024-12-04 00:14:39.063269, step: 1484\n",
            "loss: 0.388671875, time: 2024-12-04 00:14:39.653240, step: 1485\n",
            "loss: 0.38671875, time: 2024-12-04 00:14:40.243264, step: 1486\n",
            "loss: 0.3984375, time: 2024-12-04 00:14:40.833682, step: 1487\n",
            "loss: 0.419921875, time: 2024-12-04 00:14:41.424028, step: 1488\n",
            "loss: 0.396484375, time: 2024-12-04 00:14:42.013677, step: 1489\n",
            "loss: 0.380859375, time: 2024-12-04 00:14:42.603761, step: 1490\n",
            "loss: 0.373046875, time: 2024-12-04 00:14:43.193984, step: 1491\n",
            "loss: 0.412109375, time: 2024-12-04 00:14:43.783828, step: 1492\n",
            "loss: 0.37890625, time: 2024-12-04 00:14:44.374000, step: 1493\n",
            "loss: 0.365234375, time: 2024-12-04 00:14:44.964437, step: 1494\n",
            "loss: 0.396484375, time: 2024-12-04 00:14:45.554406, step: 1495\n",
            "loss: 0.390625, time: 2024-12-04 00:14:46.144233, step: 1496\n",
            "loss: 0.388671875, time: 2024-12-04 00:14:46.733998, step: 1497\n",
            "loss: 0.3828125, time: 2024-12-04 00:14:47.325198, step: 1498\n",
            "loss: 0.400390625, time: 2024-12-04 00:14:47.915123, step: 1499\n",
            "loss: 0.380859375, time: 2024-12-04 00:14:48.566824, step: 1500\n",
            "----- Time -> 2024-12-04 00:15:11.995785 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40234375, time: 2024-12-04 00:15:12.274092, step: 1501\n",
            "loss: 0.361328125, time: 2024-12-04 00:15:12.864375, step: 1502\n",
            "loss: 0.373046875, time: 2024-12-04 00:15:13.454972, step: 1503\n",
            "loss: 0.40234375, time: 2024-12-04 00:15:14.045167, step: 1504\n",
            "loss: 0.435546875, time: 2024-12-04 00:15:14.635100, step: 1505\n",
            "loss: 0.392578125, time: 2024-12-04 00:15:15.225633, step: 1506\n",
            "loss: 0.38671875, time: 2024-12-04 00:15:15.815492, step: 1507\n",
            "loss: 0.373046875, time: 2024-12-04 00:15:16.405162, step: 1508\n",
            "loss: 0.404296875, time: 2024-12-04 00:15:16.995362, step: 1509\n",
            "loss: 0.376953125, time: 2024-12-04 00:15:17.585762, step: 1510\n",
            "loss: 0.388671875, time: 2024-12-04 00:15:18.175593, step: 1511\n",
            "loss: 0.396484375, time: 2024-12-04 00:15:18.766118, step: 1512\n",
            "loss: 0.375, time: 2024-12-04 00:15:19.356210, step: 1513\n",
            "loss: 0.3828125, time: 2024-12-04 00:15:19.945957, step: 1514\n",
            "loss: 0.392578125, time: 2024-12-04 00:15:20.536121, step: 1515\n",
            "loss: 0.421875, time: 2024-12-04 00:15:21.126266, step: 1516\n",
            "loss: 0.396484375, time: 2024-12-04 00:15:21.715879, step: 1517\n",
            "loss: 0.38671875, time: 2024-12-04 00:15:22.305889, step: 1518\n",
            "loss: 0.392578125, time: 2024-12-04 00:15:22.896664, step: 1519\n",
            "loss: 0.388671875, time: 2024-12-04 00:15:23.486289, step: 1520\n",
            "----- Time -> 2024-12-04 00:15:47.026820 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.40625, time: 2024-12-04 00:15:47.297288, step: 1521\n",
            "loss: 0.4140625, time: 2024-12-04 00:15:47.887538, step: 1522\n",
            "loss: 0.4140625, time: 2024-12-04 00:15:48.477588, step: 1523\n",
            "loss: 0.369140625, time: 2024-12-04 00:15:49.067608, step: 1524\n",
            "loss: 0.412109375, time: 2024-12-04 00:15:49.657743, step: 1525\n",
            "loss: 0.38671875, time: 2024-12-04 00:15:50.248264, step: 1526\n",
            "loss: 0.3984375, time: 2024-12-04 00:15:50.838654, step: 1527\n",
            "loss: 0.373046875, time: 2024-12-04 00:15:51.428983, step: 1528\n",
            "loss: 0.3984375, time: 2024-12-04 00:15:52.018758, step: 1529\n",
            "loss: 0.3828125, time: 2024-12-04 00:15:52.608687, step: 1530\n",
            "loss: 0.392578125, time: 2024-12-04 00:15:53.198485, step: 1531\n",
            "loss: 0.388671875, time: 2024-12-04 00:15:53.788064, step: 1532\n",
            "loss: 0.38671875, time: 2024-12-04 00:15:54.377810, step: 1533\n",
            "loss: 0.3828125, time: 2024-12-04 00:15:54.967545, step: 1534\n",
            "loss: 0.384765625, time: 2024-12-04 00:15:55.557578, step: 1535\n",
            "loss: 0.392578125, time: 2024-12-04 00:15:56.147339, step: 1536\n",
            "loss: 0.416015625, time: 2024-12-04 00:15:56.737147, step: 1537\n",
            "loss: 0.37890625, time: 2024-12-04 00:15:57.327636, step: 1538\n",
            "loss: 0.396484375, time: 2024-12-04 00:15:57.917299, step: 1539\n",
            "loss: 0.388671875, time: 2024-12-04 00:15:58.507316, step: 1540\n",
            "----- Time -> 2024-12-04 00:16:22.297606 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.4140625, time: 2024-12-04 00:16:22.585866, step: 1541\n",
            "loss: 0.38671875, time: 2024-12-04 00:16:23.176331, step: 1542\n",
            "loss: 0.38671875, time: 2024-12-04 00:16:23.766395, step: 1543\n",
            "loss: 0.392578125, time: 2024-12-04 00:16:24.356478, step: 1544\n",
            "loss: 0.423828125, time: 2024-12-04 00:16:24.946513, step: 1545\n",
            "loss: 0.392578125, time: 2024-12-04 00:16:25.536346, step: 1546\n",
            "loss: 0.37109375, time: 2024-12-04 00:16:26.126650, step: 1547\n",
            "loss: 0.41015625, time: 2024-12-04 00:16:26.718154, step: 1548\n",
            "loss: 0.392578125, time: 2024-12-04 00:16:27.308343, step: 1549\n",
            "loss: 0.41796875, time: 2024-12-04 00:16:27.898621, step: 1550\n",
            "loss: 0.392578125, time: 2024-12-04 00:16:28.488838, step: 1551\n",
            "loss: 0.40625, time: 2024-12-04 00:16:29.078884, step: 1552\n",
            "loss: 0.439453125, time: 2024-12-04 00:16:29.668549, step: 1553\n",
            "loss: 0.396484375, time: 2024-12-04 00:16:30.259182, step: 1554\n",
            "loss: 0.390625, time: 2024-12-04 00:16:30.849248, step: 1555\n",
            "loss: 0.38671875, time: 2024-12-04 00:16:31.439048, step: 1556\n",
            "loss: 0.42578125, time: 2024-12-04 00:16:32.029292, step: 1557\n",
            "loss: 0.416015625, time: 2024-12-04 00:16:32.619411, step: 1558\n",
            "loss: 0.392578125, time: 2024-12-04 00:16:33.209012, step: 1559\n",
            "loss: 0.359375, time: 2024-12-04 00:16:33.799455, step: 1560\n",
            "----- Time -> 2024-12-04 00:16:57.457039 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3984375, time: 2024-12-04 00:16:57.750212, step: 1561\n",
            "loss: 0.390625, time: 2024-12-04 00:16:58.340375, step: 1562\n",
            "loss: 0.4140625, time: 2024-12-04 00:16:58.930091, step: 1563\n",
            "loss: 0.392578125, time: 2024-12-04 00:16:59.519821, step: 1564\n",
            "loss: 0.392578125, time: 2024-12-04 00:17:00.109700, step: 1565\n",
            "loss: 0.3828125, time: 2024-12-04 00:17:00.700220, step: 1566\n",
            "loss: 0.380859375, time: 2024-12-04 00:17:01.290977, step: 1567\n",
            "loss: 0.392578125, time: 2024-12-04 00:17:01.881046, step: 1568\n",
            "loss: 0.390625, time: 2024-12-04 00:17:02.470887, step: 1569\n",
            "loss: 0.3984375, time: 2024-12-04 00:17:03.061260, step: 1570\n",
            "loss: 0.392578125, time: 2024-12-04 00:17:03.651457, step: 1571\n",
            "loss: 0.396484375, time: 2024-12-04 00:17:04.241783, step: 1572\n",
            "loss: 0.38671875, time: 2024-12-04 00:17:04.832278, step: 1573\n",
            "loss: 0.404296875, time: 2024-12-04 00:17:05.422147, step: 1574\n",
            "loss: 0.39453125, time: 2024-12-04 00:17:06.012029, step: 1575\n",
            "loss: 0.37890625, time: 2024-12-04 00:17:06.602518, step: 1576\n",
            "loss: 0.373046875, time: 2024-12-04 00:17:07.192529, step: 1577\n",
            "loss: 0.390625, time: 2024-12-04 00:17:07.782643, step: 1578\n",
            "loss: 0.384765625, time: 2024-12-04 00:17:08.372967, step: 1579\n",
            "loss: 0.3984375, time: 2024-12-04 00:17:08.962429, step: 1580\n",
            "----- Time -> 2024-12-04 00:17:32.532319 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-04 00:17:32.811108, step: 1581\n",
            "loss: 0.380859375, time: 2024-12-04 00:17:33.401070, step: 1582\n",
            "loss: 0.384765625, time: 2024-12-04 00:17:33.990664, step: 1583\n",
            "loss: 0.3984375, time: 2024-12-04 00:17:34.581070, step: 1584\n",
            "loss: 0.388671875, time: 2024-12-04 00:17:35.171192, step: 1585\n",
            "loss: 0.3828125, time: 2024-12-04 00:17:35.761202, step: 1586\n",
            "loss: 0.373046875, time: 2024-12-04 00:17:36.352125, step: 1587\n",
            "loss: 0.37890625, time: 2024-12-04 00:17:36.942752, step: 1588\n",
            "loss: 0.380859375, time: 2024-12-04 00:17:37.532810, step: 1589\n",
            "loss: 0.3828125, time: 2024-12-04 00:17:38.123130, step: 1590\n",
            "loss: 0.3828125, time: 2024-12-04 00:17:38.713352, step: 1591\n",
            "loss: 0.38671875, time: 2024-12-04 00:17:39.303539, step: 1592\n",
            "loss: 0.390625, time: 2024-12-04 00:17:39.893974, step: 1593\n",
            "loss: 0.384765625, time: 2024-12-04 00:17:40.483995, step: 1594\n",
            "loss: 0.376953125, time: 2024-12-04 00:17:41.074000, step: 1595\n",
            "loss: 0.416015625, time: 2024-12-04 00:17:41.664569, step: 1596\n",
            "loss: 0.388671875, time: 2024-12-04 00:17:42.254962, step: 1597\n",
            "loss: 0.380859375, time: 2024-12-04 00:17:42.845639, step: 1598\n",
            "loss: 0.39453125, time: 2024-12-04 00:17:43.436507, step: 1599\n",
            "loss: 0.416015625, time: 2024-12-04 00:17:44.026556, step: 1600\n",
            "----- Time -> 2024-12-04 00:18:07.467049 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.390625, time: 2024-12-04 00:18:07.752175, step: 1601\n",
            "loss: 0.3984375, time: 2024-12-04 00:18:08.343204, step: 1602\n",
            "loss: 0.400390625, time: 2024-12-04 00:18:08.932675, step: 1603\n",
            "loss: 0.38671875, time: 2024-12-04 00:18:09.522200, step: 1604\n",
            "loss: 0.390625, time: 2024-12-04 00:18:10.113827, step: 1605\n",
            "loss: 0.3828125, time: 2024-12-04 00:18:10.703570, step: 1606\n",
            "loss: 0.373046875, time: 2024-12-04 00:18:11.294025, step: 1607\n",
            "loss: 0.37890625, time: 2024-12-04 00:18:11.884035, step: 1608\n",
            "loss: 0.3828125, time: 2024-12-04 00:18:12.474076, step: 1609\n",
            "loss: 0.37109375, time: 2024-12-04 00:18:13.064148, step: 1610\n",
            "loss: 0.392578125, time: 2024-12-04 00:18:13.654201, step: 1611\n",
            "loss: 0.380859375, time: 2024-12-04 00:18:14.244195, step: 1612\n",
            "loss: 0.37890625, time: 2024-12-04 00:18:14.834078, step: 1613\n",
            "loss: 0.37890625, time: 2024-12-04 00:18:15.423814, step: 1614\n",
            "loss: 0.38671875, time: 2024-12-04 00:18:16.013991, step: 1615\n",
            "loss: 0.38671875, time: 2024-12-04 00:18:16.603786, step: 1616\n",
            "loss: 0.375, time: 2024-12-04 00:18:17.193633, step: 1617\n",
            "loss: 0.400390625, time: 2024-12-04 00:18:17.783783, step: 1618\n",
            "loss: 0.390625, time: 2024-12-04 00:18:18.373925, step: 1619\n",
            "loss: 0.3984375, time: 2024-12-04 00:18:18.963818, step: 1620\n",
            "----- Time -> 2024-12-04 00:18:42.524903 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.380859375, time: 2024-12-04 00:18:42.798794, step: 1621\n",
            "loss: 0.40625, time: 2024-12-04 00:18:43.389125, step: 1622\n",
            "loss: 0.376953125, time: 2024-12-04 00:18:43.979351, step: 1623\n",
            "loss: 0.392578125, time: 2024-12-04 00:18:44.569517, step: 1624\n",
            "loss: 0.392578125, time: 2024-12-04 00:18:45.160467, step: 1625\n",
            "loss: 0.37890625, time: 2024-12-04 00:18:45.750533, step: 1626\n",
            "loss: 0.390625, time: 2024-12-04 00:18:46.340326, step: 1627\n",
            "loss: 0.408203125, time: 2024-12-04 00:18:46.930599, step: 1628\n",
            "loss: 0.392578125, time: 2024-12-04 00:18:47.521581, step: 1629\n",
            "loss: 0.400390625, time: 2024-12-04 00:18:48.111225, step: 1630\n",
            "loss: 0.396484375, time: 2024-12-04 00:18:48.701840, step: 1631\n",
            "loss: 0.388671875, time: 2024-12-04 00:18:49.291932, step: 1632\n",
            "loss: 0.396484375, time: 2024-12-04 00:18:49.882195, step: 1633\n",
            "loss: 0.3828125, time: 2024-12-04 00:18:50.472475, step: 1634\n",
            "loss: 0.384765625, time: 2024-12-04 00:18:51.061917, step: 1635\n",
            "loss: 0.3984375, time: 2024-12-04 00:18:51.652065, step: 1636\n",
            "loss: 0.408203125, time: 2024-12-04 00:18:52.242059, step: 1637\n",
            "loss: 0.384765625, time: 2024-12-04 00:18:52.832071, step: 1638\n",
            "loss: 0.41015625, time: 2024-12-04 00:18:53.422043, step: 1639\n",
            "loss: 0.392578125, time: 2024-12-04 00:18:54.011421, step: 1640\n",
            "----- Time -> 2024-12-04 00:19:17.731094 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.396484375, time: 2024-12-04 00:19:18.002367, step: 1641\n",
            "loss: 0.3828125, time: 2024-12-04 00:19:18.591887, step: 1642\n",
            "loss: 0.39453125, time: 2024-12-04 00:19:19.181612, step: 1643\n",
            "loss: 0.38671875, time: 2024-12-04 00:19:19.771636, step: 1644\n",
            "loss: 0.427734375, time: 2024-12-04 00:19:20.361591, step: 1645\n",
            "loss: 0.380859375, time: 2024-12-04 00:19:20.952307, step: 1646\n",
            "loss: 0.3828125, time: 2024-12-04 00:19:21.542695, step: 1647\n",
            "loss: 0.390625, time: 2024-12-04 00:19:22.135679, step: 1648\n",
            "loss: 0.396484375, time: 2024-12-04 00:19:22.725940, step: 1649\n",
            "loss: 0.37890625, time: 2024-12-04 00:19:23.315993, step: 1650\n",
            "loss: 0.400390625, time: 2024-12-04 00:19:23.906375, step: 1651\n",
            "loss: 0.38671875, time: 2024-12-04 00:19:24.496827, step: 1652\n",
            "loss: 0.392578125, time: 2024-12-04 00:19:25.086528, step: 1653\n",
            "loss: 0.384765625, time: 2024-12-04 00:19:25.676324, step: 1654\n",
            "loss: 0.404296875, time: 2024-12-04 00:19:26.266685, step: 1655\n",
            "loss: 0.4140625, time: 2024-12-04 00:19:26.856440, step: 1656\n",
            "loss: 0.388671875, time: 2024-12-04 00:19:27.446044, step: 1657\n",
            "loss: 0.3671875, time: 2024-12-04 00:19:28.036797, step: 1658\n",
            "loss: 0.37890625, time: 2024-12-04 00:19:28.627029, step: 1659\n",
            "loss: 0.392578125, time: 2024-12-04 00:19:29.216576, step: 1660\n",
            "----- Time -> 2024-12-04 00:19:52.954424 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.408203125, time: 2024-12-04 00:19:53.222882, step: 1661\n",
            "loss: 0.384765625, time: 2024-12-04 00:19:53.813265, step: 1662\n",
            "loss: 0.421875, time: 2024-12-04 00:19:54.403744, step: 1663\n",
            "loss: 0.3828125, time: 2024-12-04 00:19:54.993965, step: 1664\n",
            "loss: 0.40625, time: 2024-12-04 00:19:55.584478, step: 1665\n",
            "loss: 0.412109375, time: 2024-12-04 00:19:56.176239, step: 1666\n",
            "loss: 0.376953125, time: 2024-12-04 00:19:56.766066, step: 1667\n",
            "loss: 0.384765625, time: 2024-12-04 00:19:57.356131, step: 1668\n",
            "loss: 0.396484375, time: 2024-12-04 00:19:57.946545, step: 1669\n",
            "loss: 0.3828125, time: 2024-12-04 00:19:58.536489, step: 1670\n",
            "loss: 0.400390625, time: 2024-12-04 00:19:59.126662, step: 1671\n",
            "loss: 0.390625, time: 2024-12-04 00:19:59.717478, step: 1672\n",
            "loss: 0.4296875, time: 2024-12-04 00:20:00.307528, step: 1673\n",
            "loss: 0.416015625, time: 2024-12-04 00:20:00.897110, step: 1674\n",
            "loss: 0.3671875, time: 2024-12-04 00:20:01.486802, step: 1675\n",
            "loss: 0.3828125, time: 2024-12-04 00:20:02.076919, step: 1676\n",
            "loss: 0.376953125, time: 2024-12-04 00:20:02.666608, step: 1677\n",
            "loss: 0.380859375, time: 2024-12-04 00:20:03.256380, step: 1678\n",
            "loss: 0.375, time: 2024-12-04 00:20:03.846502, step: 1679\n",
            "loss: 0.369140625, time: 2024-12-04 00:20:04.436204, step: 1680\n",
            "----- Time -> 2024-12-04 00:20:28.084917 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.38671875, time: 2024-12-04 00:20:28.359669, step: 1681\n",
            "loss: 0.3828125, time: 2024-12-04 00:20:28.949488, step: 1682\n",
            "loss: 0.400390625, time: 2024-12-04 00:20:29.539143, step: 1683\n",
            "loss: 0.400390625, time: 2024-12-04 00:20:30.129220, step: 1684\n",
            "loss: 0.375, time: 2024-12-04 00:20:30.719048, step: 1685\n",
            "loss: 0.37890625, time: 2024-12-04 00:20:31.309161, step: 1686\n",
            "loss: 0.373046875, time: 2024-12-04 00:20:31.899282, step: 1687\n",
            "loss: 0.392578125, time: 2024-12-04 00:20:32.488833, step: 1688\n",
            "loss: 0.3828125, time: 2024-12-04 00:20:33.078404, step: 1689\n",
            "loss: 0.380859375, time: 2024-12-04 00:20:33.668184, step: 1690\n",
            "loss: 0.408203125, time: 2024-12-04 00:20:34.259174, step: 1691\n",
            "loss: 0.37109375, time: 2024-12-04 00:20:34.849092, step: 1692\n",
            "loss: 0.390625, time: 2024-12-04 00:20:35.439330, step: 1693\n",
            "loss: 0.40234375, time: 2024-12-04 00:20:36.029626, step: 1694\n",
            "loss: 0.4140625, time: 2024-12-04 00:20:36.619835, step: 1695\n",
            "loss: 0.40234375, time: 2024-12-04 00:20:37.210029, step: 1696\n",
            "loss: 0.40625, time: 2024-12-04 00:20:37.800630, step: 1697\n",
            "loss: 0.388671875, time: 2024-12-04 00:20:38.390489, step: 1698\n",
            "loss: 0.3984375, time: 2024-12-04 00:20:38.980476, step: 1699\n",
            "loss: 0.384765625, time: 2024-12-04 00:20:39.570539, step: 1700\n",
            "----- Time -> 2024-12-04 00:21:03.388206 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-04 00:21:03.675763, step: 1701\n",
            "loss: 0.3984375, time: 2024-12-04 00:21:04.266662, step: 1702\n",
            "loss: 0.392578125, time: 2024-12-04 00:21:04.856745, step: 1703\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:05.446414, step: 1704\n",
            "loss: 0.40625, time: 2024-12-04 00:21:06.036841, step: 1705\n",
            "loss: 0.38671875, time: 2024-12-04 00:21:06.627700, step: 1706\n",
            "loss: 0.39453125, time: 2024-12-04 00:21:07.217483, step: 1707\n",
            "loss: 0.37890625, time: 2024-12-04 00:21:07.808010, step: 1708\n",
            "loss: 0.380859375, time: 2024-12-04 00:21:08.397784, step: 1709\n",
            "loss: 0.390625, time: 2024-12-04 00:21:08.987855, step: 1710\n",
            "loss: 0.380859375, time: 2024-12-04 00:21:09.578106, step: 1711\n",
            "loss: 0.369140625, time: 2024-12-04 00:21:10.168316, step: 1712\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:10.758276, step: 1713\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:11.349703, step: 1714\n",
            "loss: 0.380859375, time: 2024-12-04 00:21:11.939366, step: 1715\n",
            "loss: 0.392578125, time: 2024-12-04 00:21:12.529167, step: 1716\n",
            "loss: 0.380859375, time: 2024-12-04 00:21:13.119660, step: 1717\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:13.709335, step: 1718\n",
            "loss: 0.400390625, time: 2024-12-04 00:21:14.299788, step: 1719\n",
            "loss: 0.373046875, time: 2024-12-04 00:21:14.890219, step: 1720\n",
            "----- Time -> 2024-12-04 00:21:38.722593 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.384765625, time: 2024-12-04 00:21:38.997348, step: 1721\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:39.588525, step: 1722\n",
            "loss: 0.37890625, time: 2024-12-04 00:21:40.178905, step: 1723\n",
            "loss: 0.390625, time: 2024-12-04 00:21:40.769256, step: 1724\n",
            "loss: 0.3828125, time: 2024-12-04 00:21:41.359517, step: 1725\n",
            "loss: 0.390625, time: 2024-12-04 00:21:41.949432, step: 1726\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:42.539411, step: 1727\n",
            "loss: 0.390625, time: 2024-12-04 00:21:43.129732, step: 1728\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:43.719719, step: 1729\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:44.309696, step: 1730\n",
            "loss: 0.39453125, time: 2024-12-04 00:21:44.900182, step: 1731\n",
            "loss: 0.44140625, time: 2024-12-04 00:21:45.490516, step: 1732\n",
            "loss: 0.39453125, time: 2024-12-04 00:21:46.080262, step: 1733\n",
            "loss: 0.396484375, time: 2024-12-04 00:21:46.670740, step: 1734\n",
            "loss: 0.44140625, time: 2024-12-04 00:21:47.262793, step: 1735\n",
            "loss: 0.390625, time: 2024-12-04 00:21:47.852615, step: 1736\n",
            "loss: 0.392578125, time: 2024-12-04 00:21:48.442695, step: 1737\n",
            "loss: 0.388671875, time: 2024-12-04 00:21:49.032484, step: 1738\n",
            "loss: 0.3515625, time: 2024-12-04 00:21:49.623354, step: 1739\n",
            "loss: 0.375, time: 2024-12-04 00:21:50.213983, step: 1740\n",
            "----- Time -> 2024-12-04 00:22:13.706406 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-04 00:22:13.978135, step: 1741\n",
            "loss: 0.388671875, time: 2024-12-04 00:22:14.571372, step: 1742\n",
            "loss: 0.369140625, time: 2024-12-04 00:22:15.161866, step: 1743\n",
            "loss: 0.38671875, time: 2024-12-04 00:22:15.752077, step: 1744\n",
            "loss: 0.40234375, time: 2024-12-04 00:22:16.342496, step: 1745\n",
            "loss: 0.435546875, time: 2024-12-04 00:22:16.932802, step: 1746\n",
            "loss: 0.40625, time: 2024-12-04 00:22:17.522828, step: 1747\n",
            "loss: 0.37109375, time: 2024-12-04 00:22:18.113190, step: 1748\n",
            "loss: 0.376953125, time: 2024-12-04 00:22:18.703217, step: 1749\n",
            "loss: 0.373046875, time: 2024-12-04 00:22:19.293107, step: 1750\n",
            "loss: 0.38671875, time: 2024-12-04 00:22:19.883516, step: 1751\n",
            "loss: 0.392578125, time: 2024-12-04 00:22:20.473131, step: 1752\n",
            "loss: 0.408203125, time: 2024-12-04 00:22:21.062647, step: 1753\n",
            "loss: 0.3828125, time: 2024-12-04 00:22:21.652904, step: 1754\n",
            "loss: 0.37890625, time: 2024-12-04 00:22:22.242826, step: 1755\n",
            "loss: 0.41796875, time: 2024-12-04 00:22:22.832459, step: 1756\n",
            "loss: 0.404296875, time: 2024-12-04 00:22:23.422787, step: 1757\n",
            "loss: 0.373046875, time: 2024-12-04 00:22:24.012389, step: 1758\n",
            "loss: 0.373046875, time: 2024-12-04 00:22:24.602192, step: 1759\n",
            "loss: 0.40234375, time: 2024-12-04 00:22:25.192599, step: 1760\n",
            "----- Time -> 2024-12-04 00:22:48.869994 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.390625, time: 2024-12-04 00:22:49.139905, step: 1761\n",
            "loss: 0.40625, time: 2024-12-04 00:22:49.730098, step: 1762\n",
            "loss: 0.396484375, time: 2024-12-04 00:22:50.320145, step: 1763\n",
            "loss: 0.39453125, time: 2024-12-04 00:22:50.909963, step: 1764\n",
            "loss: 0.388671875, time: 2024-12-04 00:22:51.499456, step: 1765\n",
            "loss: 0.408203125, time: 2024-12-04 00:22:52.089504, step: 1766\n",
            "loss: 0.390625, time: 2024-12-04 00:22:52.680617, step: 1767\n",
            "loss: 0.3828125, time: 2024-12-04 00:22:53.270748, step: 1768\n",
            "loss: 0.3828125, time: 2024-12-04 00:22:53.861287, step: 1769\n",
            "loss: 0.380859375, time: 2024-12-04 00:22:54.451336, step: 1770\n",
            "loss: 0.38671875, time: 2024-12-04 00:22:55.041316, step: 1771\n",
            "loss: 0.3984375, time: 2024-12-04 00:22:55.631826, step: 1772\n",
            "loss: 0.38671875, time: 2024-12-04 00:22:56.222135, step: 1773\n",
            "loss: 0.390625, time: 2024-12-04 00:22:56.812163, step: 1774\n",
            "loss: 0.400390625, time: 2024-12-04 00:22:57.402784, step: 1775\n",
            "loss: 0.388671875, time: 2024-12-04 00:22:57.992471, step: 1776\n",
            "loss: 0.388671875, time: 2024-12-04 00:22:58.582446, step: 1777\n",
            "loss: 0.4140625, time: 2024-12-04 00:22:59.172834, step: 1778\n",
            "loss: 0.38671875, time: 2024-12-04 00:22:59.763091, step: 1779\n",
            "loss: 0.380859375, time: 2024-12-04 00:23:00.353545, step: 1780\n",
            "----- Time -> 2024-12-04 00:23:23.986665 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.375, time: 2024-12-04 00:23:24.265767, step: 1781\n",
            "loss: 0.38671875, time: 2024-12-04 00:23:24.855536, step: 1782\n",
            "loss: 0.3984375, time: 2024-12-04 00:23:25.446255, step: 1783\n",
            "loss: 0.373046875, time: 2024-12-04 00:23:26.036060, step: 1784\n",
            "loss: 0.38671875, time: 2024-12-04 00:23:26.626093, step: 1785\n",
            "loss: 0.390625, time: 2024-12-04 00:23:27.215633, step: 1786\n",
            "loss: 0.390625, time: 2024-12-04 00:23:27.805857, step: 1787\n",
            "loss: 0.376953125, time: 2024-12-04 00:23:28.396107, step: 1788\n",
            "loss: 0.3828125, time: 2024-12-04 00:23:28.985873, step: 1789\n",
            "loss: 0.3671875, time: 2024-12-04 00:23:29.575433, step: 1790\n",
            "loss: 0.40625, time: 2024-12-04 00:23:30.166249, step: 1791\n",
            "loss: 0.376953125, time: 2024-12-04 00:23:30.756043, step: 1792\n",
            "loss: 0.3828125, time: 2024-12-04 00:23:31.346168, step: 1793\n",
            "loss: 0.400390625, time: 2024-12-04 00:23:31.936809, step: 1794\n",
            "loss: 0.3828125, time: 2024-12-04 00:23:32.526602, step: 1795\n",
            "loss: 0.404296875, time: 2024-12-04 00:23:33.116202, step: 1796\n",
            "loss: 0.376953125, time: 2024-12-04 00:23:33.706639, step: 1797\n",
            "loss: 0.384765625, time: 2024-12-04 00:23:34.296788, step: 1798\n",
            "loss: 0.3828125, time: 2024-12-04 00:23:34.886514, step: 1799\n",
            "loss: 0.3984375, time: 2024-12-04 00:23:35.476595, step: 1800\n",
            "----- Time -> 2024-12-04 00:23:59.191268 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-04 00:23:59.467588, step: 1801\n",
            "loss: 0.3984375, time: 2024-12-04 00:24:00.057453, step: 1802\n",
            "loss: 0.384765625, time: 2024-12-04 00:24:00.647419, step: 1803\n",
            "loss: 0.400390625, time: 2024-12-04 00:24:01.285508, step: 1804\n",
            "loss: 0.38671875, time: 2024-12-04 00:24:01.876727, step: 1805\n",
            "loss: 0.390625, time: 2024-12-04 00:24:02.466357, step: 1806\n",
            "loss: 0.392578125, time: 2024-12-04 00:24:03.056557, step: 1807\n",
            "loss: 0.38671875, time: 2024-12-04 00:24:03.646346, step: 1808\n",
            "loss: 0.39453125, time: 2024-12-04 00:24:04.235994, step: 1809\n",
            "loss: 0.380859375, time: 2024-12-04 00:24:04.826342, step: 1810\n",
            "loss: 0.384765625, time: 2024-12-04 00:24:05.415972, step: 1811\n",
            "loss: 0.396484375, time: 2024-12-04 00:24:06.005390, step: 1812\n",
            "loss: 0.400390625, time: 2024-12-04 00:24:06.596235, step: 1813\n",
            "loss: 0.39453125, time: 2024-12-04 00:24:07.185594, step: 1814\n",
            "loss: 0.37890625, time: 2024-12-04 00:24:07.775556, step: 1815\n",
            "loss: 0.38671875, time: 2024-12-04 00:24:08.365810, step: 1816\n",
            "loss: 0.3828125, time: 2024-12-04 00:24:08.956822, step: 1817\n",
            "loss: 0.40625, time: 2024-12-04 00:24:09.546377, step: 1818\n",
            "loss: 0.408203125, time: 2024-12-04 00:24:10.136364, step: 1819\n",
            "loss: 0.396484375, time: 2024-12-04 00:24:10.726550, step: 1820\n",
            "----- Time -> 2024-12-04 00:24:34.261638 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-04 00:24:34.541609, step: 1821\n",
            "loss: 0.392578125, time: 2024-12-04 00:24:35.132746, step: 1822\n",
            "loss: 0.3828125, time: 2024-12-04 00:24:35.722536, step: 1823\n",
            "loss: 0.390625, time: 2024-12-04 00:24:36.312590, step: 1824\n",
            "loss: 0.400390625, time: 2024-12-04 00:24:36.902412, step: 1825\n",
            "loss: 0.3828125, time: 2024-12-04 00:24:37.492325, step: 1826\n",
            "loss: 0.404296875, time: 2024-12-04 00:24:38.082040, step: 1827\n",
            "loss: 0.3984375, time: 2024-12-04 00:24:38.672036, step: 1828\n",
            "loss: 0.388671875, time: 2024-12-04 00:24:39.263067, step: 1829\n",
            "loss: 0.41015625, time: 2024-12-04 00:24:39.852906, step: 1830\n",
            "loss: 0.39453125, time: 2024-12-04 00:24:40.442909, step: 1831\n",
            "loss: 0.400390625, time: 2024-12-04 00:24:41.033330, step: 1832\n",
            "loss: 0.3984375, time: 2024-12-04 00:24:41.623406, step: 1833\n",
            "loss: 0.400390625, time: 2024-12-04 00:24:42.213429, step: 1834\n",
            "loss: 0.376953125, time: 2024-12-04 00:24:42.804087, step: 1835\n",
            "loss: 0.376953125, time: 2024-12-04 00:24:43.393954, step: 1836\n",
            "loss: 0.396484375, time: 2024-12-04 00:24:43.983658, step: 1837\n",
            "loss: 0.40234375, time: 2024-12-04 00:24:44.574301, step: 1838\n",
            "loss: 0.38671875, time: 2024-12-04 00:24:45.164530, step: 1839\n",
            "loss: 0.380859375, time: 2024-12-04 00:24:45.754166, step: 1840\n",
            "----- Time -> 2024-12-04 00:25:09.537066 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-04 00:25:09.819159, step: 1841\n",
            "loss: 0.392578125, time: 2024-12-04 00:25:10.410269, step: 1842\n",
            "loss: 0.37890625, time: 2024-12-04 00:25:11.001184, step: 1843\n",
            "loss: 0.380859375, time: 2024-12-04 00:25:11.591639, step: 1844\n",
            "loss: 0.396484375, time: 2024-12-04 00:25:12.181779, step: 1845\n",
            "loss: 0.400390625, time: 2024-12-04 00:25:12.772029, step: 1846\n",
            "loss: 0.388671875, time: 2024-12-04 00:25:13.362513, step: 1847\n",
            "loss: 0.375, time: 2024-12-04 00:25:13.952927, step: 1848\n",
            "loss: 0.41015625, time: 2024-12-04 00:25:14.543147, step: 1849\n",
            "loss: 0.423828125, time: 2024-12-04 00:25:15.133802, step: 1850\n",
            "loss: 0.37890625, time: 2024-12-04 00:25:15.724211, step: 1851\n",
            "loss: 0.40234375, time: 2024-12-04 00:25:16.314407, step: 1852\n",
            "loss: 0.380859375, time: 2024-12-04 00:25:16.905440, step: 1853\n",
            "loss: 0.384765625, time: 2024-12-04 00:25:17.495685, step: 1854\n",
            "loss: 0.4375, time: 2024-12-04 00:25:18.085884, step: 1855\n",
            "loss: 0.375, time: 2024-12-04 00:25:18.676413, step: 1856\n",
            "loss: 0.392578125, time: 2024-12-04 00:25:19.266849, step: 1857\n",
            "loss: 0.380859375, time: 2024-12-04 00:25:19.857000, step: 1858\n",
            "loss: 0.37890625, time: 2024-12-04 00:25:20.447889, step: 1859\n",
            "loss: 0.392578125, time: 2024-12-04 00:25:21.037901, step: 1860\n",
            "----- Time -> 2024-12-04 00:25:45.032040 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.388671875, time: 2024-12-04 00:25:45.306849, step: 1861\n",
            "loss: 0.41796875, time: 2024-12-04 00:25:45.898681, step: 1862\n",
            "loss: 0.3828125, time: 2024-12-04 00:25:46.488855, step: 1863\n",
            "loss: 0.373046875, time: 2024-12-04 00:25:47.079103, step: 1864\n",
            "loss: 0.400390625, time: 2024-12-04 00:25:47.669883, step: 1865\n",
            "loss: 0.392578125, time: 2024-12-04 00:25:48.260315, step: 1866\n",
            "loss: 0.3828125, time: 2024-12-04 00:25:48.850796, step: 1867\n",
            "loss: 0.390625, time: 2024-12-04 00:25:49.441036, step: 1868\n",
            "loss: 0.369140625, time: 2024-12-04 00:25:50.031168, step: 1869\n",
            "loss: 0.380859375, time: 2024-12-04 00:25:50.621518, step: 1870\n",
            "loss: 0.373046875, time: 2024-12-04 00:25:51.211829, step: 1871\n",
            "loss: 0.3984375, time: 2024-12-04 00:25:51.802367, step: 1872\n",
            "loss: 0.41796875, time: 2024-12-04 00:25:52.392750, step: 1873\n",
            "loss: 0.400390625, time: 2024-12-04 00:25:52.983443, step: 1874\n",
            "loss: 0.390625, time: 2024-12-04 00:25:53.573444, step: 1875\n",
            "loss: 0.392578125, time: 2024-12-04 00:25:54.163478, step: 1876\n",
            "loss: 0.384765625, time: 2024-12-04 00:25:54.754059, step: 1877\n",
            "loss: 0.39453125, time: 2024-12-04 00:25:55.344196, step: 1878\n",
            "loss: 0.373046875, time: 2024-12-04 00:25:55.934176, step: 1879\n",
            "loss: 0.400390625, time: 2024-12-04 00:25:56.524609, step: 1880\n",
            "----- Time -> 2024-12-04 00:26:20.199821 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.37109375, time: 2024-12-04 00:26:20.467895, step: 1881\n",
            "loss: 0.408203125, time: 2024-12-04 00:26:21.057752, step: 1882\n",
            "loss: 0.3828125, time: 2024-12-04 00:26:21.647606, step: 1883\n",
            "loss: 0.3671875, time: 2024-12-04 00:26:22.237457, step: 1884\n",
            "loss: 0.365234375, time: 2024-12-04 00:26:22.828167, step: 1885\n",
            "loss: 0.423828125, time: 2024-12-04 00:26:23.418014, step: 1886\n",
            "loss: 0.3671875, time: 2024-12-04 00:26:24.007701, step: 1887\n",
            "loss: 0.369140625, time: 2024-12-04 00:26:24.597880, step: 1888\n",
            "loss: 0.3828125, time: 2024-12-04 00:26:25.188583, step: 1889\n",
            "loss: 0.400390625, time: 2024-12-04 00:26:25.779058, step: 1890\n",
            "loss: 0.380859375, time: 2024-12-04 00:26:26.369500, step: 1891\n",
            "loss: 0.408203125, time: 2024-12-04 00:26:26.960142, step: 1892\n",
            "loss: 0.41015625, time: 2024-12-04 00:26:27.551311, step: 1893\n",
            "loss: 0.36328125, time: 2024-12-04 00:26:28.141968, step: 1894\n",
            "loss: 0.384765625, time: 2024-12-04 00:26:28.732691, step: 1895\n",
            "loss: 0.384765625, time: 2024-12-04 00:26:29.322923, step: 1896\n",
            "loss: 0.380859375, time: 2024-12-04 00:26:29.913067, step: 1897\n",
            "loss: 0.421875, time: 2024-12-04 00:26:30.502994, step: 1898\n",
            "loss: 0.400390625, time: 2024-12-04 00:26:31.093223, step: 1899\n",
            "loss: 0.40625, time: 2024-12-04 00:26:31.683597, step: 1900\n",
            "----- Time -> 2024-12-04 00:26:55.412852 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.373046875, time: 2024-12-04 00:26:55.702492, step: 1901\n",
            "loss: 0.37109375, time: 2024-12-04 00:26:56.293596, step: 1902\n",
            "loss: 0.400390625, time: 2024-12-04 00:26:56.883521, step: 1903\n",
            "loss: 0.365234375, time: 2024-12-04 00:26:57.473437, step: 1904\n",
            "loss: 0.40625, time: 2024-12-04 00:26:58.063494, step: 1905\n",
            "loss: 0.38671875, time: 2024-12-04 00:26:58.653572, step: 1906\n",
            "loss: 0.408203125, time: 2024-12-04 00:26:59.244184, step: 1907\n",
            "loss: 0.423828125, time: 2024-12-04 00:26:59.834347, step: 1908\n",
            "loss: 0.408203125, time: 2024-12-04 00:27:00.424273, step: 1909\n",
            "loss: 0.408203125, time: 2024-12-04 00:27:01.014787, step: 1910\n",
            "loss: 0.3828125, time: 2024-12-04 00:27:01.604729, step: 1911\n",
            "loss: 0.37890625, time: 2024-12-04 00:27:02.194910, step: 1912\n",
            "loss: 0.40625, time: 2024-12-04 00:27:02.785705, step: 1913\n",
            "loss: 0.375, time: 2024-12-04 00:27:03.375962, step: 1914\n",
            "loss: 0.375, time: 2024-12-04 00:27:03.966107, step: 1915\n",
            "loss: 0.3828125, time: 2024-12-04 00:27:04.556828, step: 1916\n",
            "loss: 0.3828125, time: 2024-12-04 00:27:05.147142, step: 1917\n",
            "loss: 0.40234375, time: 2024-12-04 00:27:05.737473, step: 1918\n",
            "loss: 0.396484375, time: 2024-12-04 00:27:06.328447, step: 1919\n",
            "loss: 0.404296875, time: 2024-12-04 00:27:06.918817, step: 1920\n",
            "----- Time -> 2024-12-04 00:27:30.543053 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.39453125, time: 2024-12-04 00:27:30.814461, step: 1921\n",
            "loss: 0.376953125, time: 2024-12-04 00:27:31.404422, step: 1922\n",
            "loss: 0.37890625, time: 2024-12-04 00:27:31.994111, step: 1923\n",
            "loss: 0.376953125, time: 2024-12-04 00:27:32.583752, step: 1924\n",
            "loss: 0.359375, time: 2024-12-04 00:27:33.173767, step: 1925\n",
            "loss: 0.4296875, time: 2024-12-04 00:27:33.763895, step: 1926\n",
            "loss: 0.375, time: 2024-12-04 00:27:34.353898, step: 1927\n",
            "loss: 0.388671875, time: 2024-12-04 00:27:34.943535, step: 1928\n",
            "loss: 0.392578125, time: 2024-12-04 00:27:35.533402, step: 1929\n",
            "loss: 0.38671875, time: 2024-12-04 00:27:36.123171, step: 1930\n",
            "loss: 0.4140625, time: 2024-12-04 00:27:36.713411, step: 1931\n",
            "loss: 0.3984375, time: 2024-12-04 00:27:37.303910, step: 1932\n",
            "loss: 0.3828125, time: 2024-12-04 00:27:37.894444, step: 1933\n",
            "loss: 0.3984375, time: 2024-12-04 00:27:38.484218, step: 1934\n",
            "loss: 0.392578125, time: 2024-12-04 00:27:39.074821, step: 1935\n",
            "loss: 0.4140625, time: 2024-12-04 00:27:39.665010, step: 1936\n",
            "loss: 0.390625, time: 2024-12-04 00:27:40.255154, step: 1937\n",
            "loss: 0.384765625, time: 2024-12-04 00:27:40.845449, step: 1938\n",
            "loss: 0.384765625, time: 2024-12-04 00:27:41.436184, step: 1939\n",
            "loss: 0.392578125, time: 2024-12-04 00:27:42.026558, step: 1940\n",
            "----- Time -> 2024-12-04 00:28:05.487864 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.3828125, time: 2024-12-04 00:28:05.765576, step: 1941\n",
            "loss: 0.3828125, time: 2024-12-04 00:28:06.355509, step: 1942\n",
            "loss: 0.3828125, time: 2024-12-04 00:28:06.945413, step: 1943\n",
            "loss: 0.38671875, time: 2024-12-04 00:28:07.535443, step: 1944\n",
            "loss: 0.39453125, time: 2024-12-04 00:28:08.125384, step: 1945\n",
            "loss: 0.373046875, time: 2024-12-04 00:28:08.715101, step: 1946\n",
            "loss: 0.39453125, time: 2024-12-04 00:28:09.305297, step: 1947\n",
            "loss: 0.40234375, time: 2024-12-04 00:28:09.895747, step: 1948\n",
            "loss: 0.384765625, time: 2024-12-04 00:28:10.486028, step: 1949\n",
            "loss: 0.390625, time: 2024-12-04 00:28:11.076571, step: 1950\n",
            "loss: 0.412109375, time: 2024-12-04 00:28:11.667830, step: 1951\n",
            "loss: 0.392578125, time: 2024-12-04 00:28:12.258155, step: 1952\n",
            "loss: 0.392578125, time: 2024-12-04 00:28:12.849218, step: 1953\n",
            "loss: 0.373046875, time: 2024-12-04 00:28:13.439329, step: 1954\n",
            "loss: 0.380859375, time: 2024-12-04 00:28:14.029367, step: 1955\n",
            "loss: 0.41015625, time: 2024-12-04 00:28:14.619377, step: 1956\n",
            "loss: 0.400390625, time: 2024-12-04 00:28:15.209542, step: 1957\n",
            "loss: 0.373046875, time: 2024-12-04 00:28:15.799443, step: 1958\n",
            "loss: 0.373046875, time: 2024-12-04 00:28:16.389828, step: 1959\n",
            "loss: 0.380859375, time: 2024-12-04 00:28:16.979831, step: 1960\n",
            "----- Time -> 2024-12-04 00:28:40.469687 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.396484375, time: 2024-12-04 00:28:40.747814, step: 1961\n",
            "loss: 0.392578125, time: 2024-12-04 00:28:41.337935, step: 1962\n",
            "loss: 0.373046875, time: 2024-12-04 00:28:41.928042, step: 1963\n",
            "loss: 0.421875, time: 2024-12-04 00:28:42.519448, step: 1964\n",
            "loss: 0.408203125, time: 2024-12-04 00:28:43.109425, step: 1965\n",
            "loss: 0.388671875, time: 2024-12-04 00:28:43.699604, step: 1966\n",
            "loss: 0.3671875, time: 2024-12-04 00:28:44.289775, step: 1967\n",
            "loss: 0.390625, time: 2024-12-04 00:28:44.879444, step: 1968\n",
            "loss: 0.36328125, time: 2024-12-04 00:28:45.469419, step: 1969\n",
            "loss: 0.41015625, time: 2024-12-04 00:28:46.059565, step: 1970\n",
            "loss: 0.388671875, time: 2024-12-04 00:28:46.649535, step: 1971\n",
            "loss: 0.41015625, time: 2024-12-04 00:28:47.239277, step: 1972\n",
            "loss: 0.37109375, time: 2024-12-04 00:28:47.829214, step: 1973\n",
            "loss: 0.369140625, time: 2024-12-04 00:28:48.418923, step: 1974\n",
            "loss: 0.38671875, time: 2024-12-04 00:28:49.008778, step: 1975\n",
            "loss: 0.37890625, time: 2024-12-04 00:28:49.599471, step: 1976\n",
            "loss: 0.376953125, time: 2024-12-04 00:28:50.189229, step: 1977\n",
            "loss: 0.388671875, time: 2024-12-04 00:28:50.778831, step: 1978\n",
            "loss: 0.373046875, time: 2024-12-04 00:28:51.369324, step: 1979\n",
            "loss: 0.388671875, time: 2024-12-04 00:28:51.958974, step: 1980\n",
            "----- Time -> 2024-12-04 00:29:15.775750 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.392578125, time: 2024-12-04 00:29:16.065602, step: 1981\n",
            "loss: 0.373046875, time: 2024-12-04 00:29:16.655913, step: 1982\n",
            "loss: 0.3828125, time: 2024-12-04 00:29:17.245735, step: 1983\n",
            "loss: 0.388671875, time: 2024-12-04 00:29:17.836054, step: 1984\n",
            "loss: 0.396484375, time: 2024-12-04 00:29:18.426087, step: 1985\n",
            "loss: 0.392578125, time: 2024-12-04 00:29:19.016362, step: 1986\n",
            "loss: 0.3828125, time: 2024-12-04 00:29:19.606722, step: 1987\n",
            "loss: 0.380859375, time: 2024-12-04 00:29:20.196589, step: 1988\n",
            "loss: 0.388671875, time: 2024-12-04 00:29:20.787154, step: 1989\n",
            "loss: 0.37890625, time: 2024-12-04 00:29:21.377817, step: 1990\n",
            "loss: 0.38671875, time: 2024-12-04 00:29:21.967941, step: 1991\n",
            "loss: 0.375, time: 2024-12-04 00:29:22.557967, step: 1992\n",
            "loss: 0.37109375, time: 2024-12-04 00:29:23.147990, step: 1993\n",
            "loss: 0.431640625, time: 2024-12-04 00:29:23.738875, step: 1994\n",
            "loss: 0.37890625, time: 2024-12-04 00:29:24.329295, step: 1995\n",
            "loss: 0.400390625, time: 2024-12-04 00:29:24.919022, step: 1996\n",
            "loss: 0.412109375, time: 2024-12-04 00:29:25.508873, step: 1997\n",
            "loss: 0.400390625, time: 2024-12-04 00:29:26.099327, step: 1998\n",
            "loss: 0.369140625, time: 2024-12-04 00:29:26.689236, step: 1999\n",
            "loss: 0.38671875, time: 2024-12-04 00:29:27.279364, step: 2000\n",
            "----- Time -> 2024-12-04 00:29:50.885928 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Learning_rate</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>train_loss</td><td>â–„â–„â–ƒâ–…â–ˆâ–„â–„â–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–‚â–ƒâ–…â–„â–‚â–‚â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–„</td></tr><tr><td>train_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Learning_rate</td><td>3e-05</td></tr><tr><td>train_loss</td><td>0.38672</td></tr><tr><td>train_step</td><td>2000</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">serene-mountain-31</strong> at: <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/z7phfljd' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/z7phfljd</a><br/> View project at: <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241203_233116-z7phfljd/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_roots_configs, train_roots_loader, testing_roots_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dx0Z7GRRhXCM",
        "outputId": "e9f01d66-d446-48f4-c99c-3413aed108a0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241204_004608-mcqfzvhs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/mcqfzvhs' target=\"_blank\">lilac-valley-32</a></strong> to <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/mcqfzvhs' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/mcqfzvhs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch 1 train begin 2024-12-04 00:46:10.060686\n",
            "loss: 8.4375, time: 2024-12-04 00:46:10.344872, step: 1\n",
            "loss: 8.5, time: 2024-12-04 00:46:10.938250, step: 2\n",
            "loss: 9.3125, time: 2024-12-04 00:46:11.528453, step: 3\n",
            "loss: 7.84375, time: 2024-12-04 00:46:12.118468, step: 4\n",
            "loss: 8.4375, time: 2024-12-04 00:46:12.709084, step: 5\n",
            "loss: 8.5, time: 2024-12-04 00:46:13.299819, step: 6\n",
            "loss: 7.1875, time: 2024-12-04 00:46:13.889733, step: 7\n",
            "loss: 7.09375, time: 2024-12-04 00:46:14.479630, step: 8\n",
            "loss: 5.125, time: 2024-12-04 00:46:15.069995, step: 9\n",
            "loss: 7.09375, time: 2024-12-04 00:46:15.660504, step: 10\n",
            "loss: 6.90625, time: 2024-12-04 00:46:16.251059, step: 11\n",
            "loss: 6.53125, time: 2024-12-04 00:46:16.842007, step: 12\n",
            "loss: 5.90625, time: 2024-12-04 00:46:17.432285, step: 13\n",
            "loss: 6.15625, time: 2024-12-04 00:46:18.022238, step: 14\n",
            "loss: 6.21875, time: 2024-12-04 00:46:18.612472, step: 15\n",
            "loss: 4.21875, time: 2024-12-04 00:46:19.202327, step: 16\n",
            "loss: 5.46875, time: 2024-12-04 00:46:19.792706, step: 17\n",
            "loss: 4.8125, time: 2024-12-04 00:46:20.383403, step: 18\n",
            "loss: 5.34375, time: 2024-12-04 00:46:20.973936, step: 19\n",
            "loss: 4.375, time: 2024-12-04 00:46:21.563807, step: 20\n",
            "----- Time -> 2024-12-04 00:46:22.028434 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 4.5, time: 2024-12-04 00:46:22.281550, step: 21\n",
            "loss: 5.53125, time: 2024-12-04 00:46:22.871511, step: 22\n",
            "loss: 4.96875, time: 2024-12-04 00:46:23.461508, step: 23\n",
            "loss: 4.5, time: 2024-12-04 00:46:24.051597, step: 24\n",
            "loss: 4.125, time: 2024-12-04 00:46:24.641652, step: 25\n",
            "loss: 3.640625, time: 2024-12-04 00:46:25.231428, step: 26\n",
            "loss: 3.578125, time: 2024-12-04 00:46:25.821447, step: 27\n",
            "loss: 3.484375, time: 2024-12-04 00:46:26.412073, step: 28\n",
            "loss: 3.671875, time: 2024-12-04 00:46:27.001781, step: 29\n",
            "loss: 3.484375, time: 2024-12-04 00:46:27.591738, step: 30\n",
            "loss: 2.59375, time: 2024-12-04 00:46:28.182266, step: 31\n",
            "loss: 3.015625, time: 2024-12-04 00:46:28.772326, step: 32\n",
            "loss: 2.453125, time: 2024-12-04 00:46:29.362745, step: 33\n",
            "loss: 2.046875, time: 2024-12-04 00:46:29.953136, step: 34\n",
            "loss: 1.984375, time: 2024-12-04 00:46:30.543140, step: 35\n",
            "loss: 2.234375, time: 2024-12-04 00:46:31.133138, step: 36\n",
            "loss: 1.7734375, time: 2024-12-04 00:46:31.723474, step: 37\n",
            "loss: 1.6484375, time: 2024-12-04 00:46:32.313630, step: 38\n",
            "loss: 1.421875, time: 2024-12-04 00:46:32.903698, step: 39\n",
            "loss: 1.5625, time: 2024-12-04 00:46:33.595765, step: 40\n",
            "----- Time -> 2024-12-04 00:46:34.061089 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 1.28125, time: 2024-12-04 00:46:34.312753, step: 41\n",
            "loss: 1.1640625, time: 2024-12-04 00:46:34.903066, step: 42\n",
            "loss: 1.15625, time: 2024-12-04 00:46:35.493200, step: 43\n",
            "loss: 1.1875, time: 2024-12-04 00:46:36.082855, step: 44\n",
            "loss: 1.015625, time: 2024-12-04 00:46:36.673054, step: 45\n",
            "loss: 1.0703125, time: 2024-12-04 00:46:37.263735, step: 46\n",
            "loss: 1.328125, time: 2024-12-04 00:46:37.853365, step: 47\n",
            "loss: 0.93359375, time: 2024-12-04 00:46:38.443162, step: 48\n",
            "loss: 1.203125, time: 2024-12-04 00:46:39.033590, step: 49\n",
            "loss: 1.1015625, time: 2024-12-04 00:46:39.623213, step: 50\n",
            "loss: 0.96484375, time: 2024-12-04 00:46:40.213396, step: 51\n",
            "loss: 1.1484375, time: 2024-12-04 00:46:40.803272, step: 52\n",
            "loss: 0.78125, time: 2024-12-04 00:46:41.393165, step: 53\n",
            "loss: 0.72265625, time: 2024-12-04 00:46:41.983093, step: 54\n",
            "loss: 0.84375, time: 2024-12-04 00:46:42.573606, step: 55\n",
            "loss: 0.69140625, time: 2024-12-04 00:46:43.163597, step: 56\n",
            "loss: 0.51953125, time: 2024-12-04 00:46:43.754195, step: 57\n",
            "loss: 0.57421875, time: 2024-12-04 00:46:44.344527, step: 58\n",
            "loss: 0.84765625, time: 2024-12-04 00:46:44.934137, step: 59\n",
            "loss: 0.5859375, time: 2024-12-04 00:46:45.524328, step: 60\n",
            "----- Time -> 2024-12-04 00:46:45.982802 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.72265625, time: 2024-12-04 00:46:46.235040, step: 61\n",
            "loss: 0.95703125, time: 2024-12-04 00:46:46.824759, step: 62\n",
            "loss: 0.6953125, time: 2024-12-04 00:46:47.414591, step: 63\n",
            "loss: 0.61328125, time: 2024-12-04 00:46:48.004336, step: 64\n",
            "loss: 0.48828125, time: 2024-12-04 00:46:48.595902, step: 65\n",
            "loss: 0.58203125, time: 2024-12-04 00:46:49.185736, step: 66\n",
            "loss: 0.9140625, time: 2024-12-04 00:46:49.775556, step: 67\n",
            "loss: 0.45703125, time: 2024-12-04 00:46:50.365928, step: 68\n",
            "loss: 0.56640625, time: 2024-12-04 00:46:50.955603, step: 69\n",
            "loss: 0.71484375, time: 2024-12-04 00:46:51.545086, step: 70\n",
            "loss: 0.68359375, time: 2024-12-04 00:46:52.135767, step: 71\n",
            "loss: 0.5546875, time: 2024-12-04 00:46:52.726069, step: 72\n",
            "loss: 0.921875, time: 2024-12-04 00:46:53.316031, step: 73\n",
            "loss: 0.4921875, time: 2024-12-04 00:46:53.906494, step: 74\n",
            "loss: 0.50390625, time: 2024-12-04 00:46:54.497268, step: 75\n",
            "loss: 0.435546875, time: 2024-12-04 00:46:55.087869, step: 76\n",
            "loss: 0.515625, time: 2024-12-04 00:46:55.678304, step: 77\n",
            "loss: 0.388671875, time: 2024-12-04 00:46:56.268563, step: 78\n",
            "loss: 0.625, time: 2024-12-04 00:46:56.858667, step: 79\n",
            "loss: 0.78125, time: 2024-12-04 00:46:57.450027, step: 80\n",
            "----- Time -> 2024-12-04 00:46:57.913805 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.6640625, time: 2024-12-04 00:46:58.167015, step: 81\n",
            "loss: 0.66796875, time: 2024-12-04 00:46:58.756821, step: 82\n",
            "loss: 0.36328125, time: 2024-12-04 00:46:59.347195, step: 83\n",
            "loss: 0.671875, time: 2024-12-04 00:46:59.937061, step: 84\n",
            "loss: 0.51953125, time: 2024-12-04 00:47:00.526922, step: 85\n",
            "loss: 0.8515625, time: 2024-12-04 00:47:01.117664, step: 86\n",
            "loss: 0.65234375, time: 2024-12-04 00:47:01.707292, step: 87\n",
            "loss: 0.400390625, time: 2024-12-04 00:47:02.297314, step: 88\n",
            "loss: 0.5, time: 2024-12-04 00:47:02.888004, step: 89\n",
            "loss: 0.59765625, time: 2024-12-04 00:47:03.478089, step: 90\n",
            "loss: 0.56640625, time: 2024-12-04 00:47:04.068423, step: 91\n",
            "loss: 0.66015625, time: 2024-12-04 00:47:04.658763, step: 92\n",
            "loss: 0.51953125, time: 2024-12-04 00:47:05.248918, step: 93\n",
            "loss: 0.5703125, time: 2024-12-04 00:47:05.839048, step: 94\n",
            "loss: 0.400390625, time: 2024-12-04 00:47:06.430347, step: 95\n",
            "loss: 0.609375, time: 2024-12-04 00:47:07.020890, step: 96\n",
            "loss: 0.36328125, time: 2024-12-04 00:47:07.611010, step: 97\n",
            "loss: 0.5625, time: 2024-12-04 00:47:08.201831, step: 98\n",
            "loss: 0.54296875, time: 2024-12-04 00:47:08.792278, step: 99\n",
            "loss: 0.60546875, time: 2024-12-04 00:47:09.382594, step: 100\n",
            "----- Time -> 2024-12-04 00:47:09.845744 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.58984375, time: 2024-12-04 00:47:10.098280, step: 101\n",
            "loss: 0.78515625, time: 2024-12-04 00:47:10.689307, step: 102\n",
            "loss: 0.423828125, time: 2024-12-04 00:47:11.280004, step: 103\n",
            "loss: 0.32421875, time: 2024-12-04 00:47:11.870286, step: 104\n",
            "loss: 0.4140625, time: 2024-12-04 00:47:12.460367, step: 105\n",
            "loss: 0.443359375, time: 2024-12-04 00:47:13.051279, step: 106\n",
            "loss: 0.65234375, time: 2024-12-04 00:47:13.641363, step: 107\n",
            "loss: 0.54296875, time: 2024-12-04 00:47:14.231580, step: 108\n",
            "loss: 0.43359375, time: 2024-12-04 00:47:14.822345, step: 109\n",
            "loss: 0.451171875, time: 2024-12-04 00:47:15.412073, step: 110\n",
            "loss: 0.51171875, time: 2024-12-04 00:47:16.002059, step: 111\n",
            "loss: 0.60546875, time: 2024-12-04 00:47:16.592550, step: 112\n",
            "loss: 0.59375, time: 2024-12-04 00:47:17.182464, step: 113\n",
            "loss: 0.625, time: 2024-12-04 00:47:17.772631, step: 114\n",
            "loss: 0.6328125, time: 2024-12-04 00:47:18.363643, step: 115\n",
            "loss: 0.4921875, time: 2024-12-04 00:47:18.954080, step: 116\n",
            "loss: 0.388671875, time: 2024-12-04 00:47:19.544260, step: 117\n",
            "loss: 0.314453125, time: 2024-12-04 00:47:20.135200, step: 118\n",
            "loss: 0.46875, time: 2024-12-04 00:47:20.725732, step: 119\n",
            "loss: 0.61328125, time: 2024-12-04 00:47:21.316274, step: 120\n",
            "----- Time -> 2024-12-04 00:47:21.779103 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.5, time: 2024-12-04 00:47:22.032889, step: 121\n",
            "loss: 0.40234375, time: 2024-12-04 00:47:22.623202, step: 122\n",
            "loss: 0.39453125, time: 2024-12-04 00:47:23.213567, step: 123\n",
            "loss: 0.5703125, time: 2024-12-04 00:47:23.804413, step: 124\n",
            "loss: 0.60546875, time: 2024-12-04 00:47:24.395291, step: 125\n",
            "loss: 0.61328125, time: 2024-12-04 00:47:24.985345, step: 126\n",
            "loss: 0.42578125, time: 2024-12-04 00:47:25.576809, step: 127\n",
            "loss: 0.55078125, time: 2024-12-04 00:47:26.167867, step: 128\n",
            "loss: 0.298828125, time: 2024-12-04 00:47:26.759364, step: 129\n",
            "loss: 0.6015625, time: 2024-12-04 00:47:27.350502, step: 130\n",
            "loss: 0.384765625, time: 2024-12-04 00:47:27.941021, step: 131\n",
            "loss: 0.41015625, time: 2024-12-04 00:47:28.531290, step: 132\n",
            "loss: 0.416015625, time: 2024-12-04 00:47:29.122197, step: 133\n",
            "loss: 0.349609375, time: 2024-12-04 00:47:29.712395, step: 134\n",
            "loss: 0.55859375, time: 2024-12-04 00:47:30.302902, step: 135\n",
            "loss: 0.546875, time: 2024-12-04 00:47:30.893937, step: 136\n",
            "loss: 0.34765625, time: 2024-12-04 00:47:31.484550, step: 137\n",
            "loss: 0.7421875, time: 2024-12-04 00:47:32.074741, step: 138\n",
            "loss: 0.69921875, time: 2024-12-04 00:47:32.666092, step: 139\n",
            "loss: 0.7578125, time: 2024-12-04 00:47:33.256911, step: 140\n",
            "----- Time -> 2024-12-04 00:47:33.724532 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.349609375, time: 2024-12-04 00:47:33.977978, step: 141\n",
            "loss: 0.71484375, time: 2024-12-04 00:47:34.606351, step: 142\n",
            "loss: 0.71875, time: 2024-12-04 00:47:35.196939, step: 143\n",
            "loss: 0.734375, time: 2024-12-04 00:47:35.787825, step: 144\n",
            "loss: 0.5625, time: 2024-12-04 00:47:36.378141, step: 145\n",
            "loss: 0.63671875, time: 2024-12-04 00:47:36.968168, step: 146\n",
            "loss: 0.408203125, time: 2024-12-04 00:47:37.558998, step: 147\n",
            "loss: 0.6484375, time: 2024-12-04 00:47:38.149961, step: 148\n",
            "loss: 0.466796875, time: 2024-12-04 00:47:38.740300, step: 149\n",
            "loss: 0.703125, time: 2024-12-04 00:47:39.330543, step: 150\n",
            "loss: 0.7578125, time: 2024-12-04 00:47:39.921394, step: 151\n",
            "loss: 0.53125, time: 2024-12-04 00:47:40.511679, step: 152\n",
            "loss: 0.4453125, time: 2024-12-04 00:47:41.102378, step: 153\n",
            "loss: 0.58984375, time: 2024-12-04 00:47:41.693047, step: 154\n",
            "loss: 0.361328125, time: 2024-12-04 00:47:42.283297, step: 155\n",
            "loss: 0.70703125, time: 2024-12-04 00:47:42.874516, step: 156\n",
            "loss: 0.54296875, time: 2024-12-04 00:47:43.464885, step: 157\n",
            "loss: 0.3515625, time: 2024-12-04 00:47:44.055255, step: 158\n",
            "loss: 0.35546875, time: 2024-12-04 00:47:44.646541, step: 159\n",
            "loss: 0.71484375, time: 2024-12-04 00:47:45.237149, step: 160\n",
            "----- Time -> 2024-12-04 00:47:45.704599 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.578125, time: 2024-12-04 00:47:45.956983, step: 161\n",
            "loss: 0.68359375, time: 2024-12-04 00:47:46.547512, step: 162\n",
            "loss: 0.51171875, time: 2024-12-04 00:47:47.137736, step: 163\n",
            "loss: 0.6015625, time: 2024-12-04 00:47:47.728190, step: 164\n",
            "loss: 0.77734375, time: 2024-12-04 00:47:48.318687, step: 165\n",
            "loss: 0.373046875, time: 2024-12-04 00:47:48.909233, step: 166\n",
            "loss: 0.462890625, time: 2024-12-04 00:47:49.500131, step: 167\n",
            "loss: 0.38671875, time: 2024-12-04 00:47:50.090472, step: 168\n",
            "loss: 0.337890625, time: 2024-12-04 00:47:50.681325, step: 169\n",
            "loss: 0.61328125, time: 2024-12-04 00:47:51.272084, step: 170\n",
            "loss: 0.5078125, time: 2024-12-04 00:47:51.862346, step: 171\n",
            "loss: 0.671875, time: 2024-12-04 00:47:52.453238, step: 172\n",
            "loss: 0.48046875, time: 2024-12-04 00:47:53.044835, step: 173\n",
            "loss: 0.76953125, time: 2024-12-04 00:47:53.635121, step: 174\n",
            "loss: 0.349609375, time: 2024-12-04 00:47:54.225758, step: 175\n",
            "loss: 0.5546875, time: 2024-12-04 00:47:54.816837, step: 176\n",
            "loss: 0.44921875, time: 2024-12-04 00:47:55.407798, step: 177\n",
            "loss: 0.306640625, time: 2024-12-04 00:47:55.999405, step: 178\n",
            "loss: 0.55859375, time: 2024-12-04 00:47:56.590320, step: 179\n",
            "loss: 0.55078125, time: 2024-12-04 00:47:57.180611, step: 180\n",
            "----- Time -> 2024-12-04 00:47:57.646609 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.384765625, time: 2024-12-04 00:47:57.900684, step: 181\n",
            "loss: 0.4453125, time: 2024-12-04 00:47:58.491056, step: 182\n",
            "loss: 0.353515625, time: 2024-12-04 00:47:59.082445, step: 183\n",
            "loss: 0.546875, time: 2024-12-04 00:47:59.673149, step: 184\n",
            "loss: 0.404296875, time: 2024-12-04 00:48:00.263903, step: 185\n",
            "loss: 0.375, time: 2024-12-04 00:48:00.855727, step: 186\n",
            "loss: 0.50390625, time: 2024-12-04 00:48:01.446224, step: 187\n",
            "loss: 0.58203125, time: 2024-12-04 00:48:02.036515, step: 188\n",
            "loss: 0.482421875, time: 2024-12-04 00:48:02.627650, step: 189\n",
            "loss: 0.447265625, time: 2024-12-04 00:48:03.217913, step: 190\n",
            "loss: 0.578125, time: 2024-12-04 00:48:03.808105, step: 191\n",
            "loss: 0.390625, time: 2024-12-04 00:48:04.399227, step: 192\n",
            "loss: 0.455078125, time: 2024-12-04 00:48:04.989766, step: 193\n",
            "loss: 0.6640625, time: 2024-12-04 00:48:05.580914, step: 194\n",
            "loss: 0.56640625, time: 2024-12-04 00:48:06.172218, step: 195\n",
            "loss: 0.482421875, time: 2024-12-04 00:48:06.762691, step: 196\n",
            "loss: 0.53515625, time: 2024-12-04 00:48:07.353012, step: 197\n",
            "loss: 0.6015625, time: 2024-12-04 00:48:07.944196, step: 198\n",
            "loss: 0.30078125, time: 2024-12-04 00:48:08.535016, step: 199\n",
            "loss: 0.2734375, time: 2024-12-04 00:48:09.125348, step: 200\n",
            "----- Time -> 2024-12-04 00:48:09.596497 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.51953125, time: 2024-12-04 00:48:09.848797, step: 201\n",
            "loss: 0.5625, time: 2024-12-04 00:48:10.439158, step: 202\n",
            "loss: 0.294921875, time: 2024-12-04 00:48:11.029589, step: 203\n",
            "loss: 0.416015625, time: 2024-12-04 00:48:11.619642, step: 204\n",
            "loss: 0.421875, time: 2024-12-04 00:48:12.209995, step: 205\n",
            "loss: 0.392578125, time: 2024-12-04 00:48:12.801684, step: 206\n",
            "loss: 0.3515625, time: 2024-12-04 00:48:13.391556, step: 207\n",
            "loss: 0.431640625, time: 2024-12-04 00:48:13.982063, step: 208\n",
            "loss: 0.52734375, time: 2024-12-04 00:48:14.572268, step: 209\n",
            "loss: 0.359375, time: 2024-12-04 00:48:15.162420, step: 210\n",
            "loss: 0.302734375, time: 2024-12-04 00:48:15.752675, step: 211\n",
            "loss: 0.515625, time: 2024-12-04 00:48:16.343602, step: 212\n",
            "loss: 0.53515625, time: 2024-12-04 00:48:16.933538, step: 213\n",
            "loss: 0.66796875, time: 2024-12-04 00:48:17.523968, step: 214\n",
            "loss: 0.5, time: 2024-12-04 00:48:18.114161, step: 215\n",
            "loss: 0.37890625, time: 2024-12-04 00:48:18.704754, step: 216\n",
            "loss: 0.59765625, time: 2024-12-04 00:48:19.294902, step: 217\n",
            "loss: 0.384765625, time: 2024-12-04 00:48:19.886477, step: 218\n",
            "loss: 0.392578125, time: 2024-12-04 00:48:20.477313, step: 219\n",
            "loss: 0.3515625, time: 2024-12-04 00:48:21.067341, step: 220\n",
            "----- Time -> 2024-12-04 00:48:21.539522 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.455078125, time: 2024-12-04 00:48:21.792074, step: 221\n",
            "loss: 0.33984375, time: 2024-12-04 00:48:22.383111, step: 222\n",
            "loss: 0.328125, time: 2024-12-04 00:48:22.973078, step: 223\n",
            "loss: 0.6640625, time: 2024-12-04 00:48:23.563096, step: 224\n",
            "loss: 0.34375, time: 2024-12-04 00:48:24.153409, step: 225\n",
            "loss: 0.298828125, time: 2024-12-04 00:48:24.743813, step: 226\n",
            "loss: 0.330078125, time: 2024-12-04 00:48:25.333685, step: 227\n",
            "loss: 0.7890625, time: 2024-12-04 00:48:25.923741, step: 228\n",
            "loss: 0.4296875, time: 2024-12-04 00:48:26.513987, step: 229\n",
            "loss: 0.55859375, time: 2024-12-04 00:48:27.103891, step: 230\n",
            "loss: 0.439453125, time: 2024-12-04 00:48:27.693937, step: 231\n",
            "loss: 0.34375, time: 2024-12-04 00:48:28.285562, step: 232\n",
            "loss: 0.466796875, time: 2024-12-04 00:48:28.876149, step: 233\n",
            "loss: 0.5234375, time: 2024-12-04 00:48:29.465770, step: 234\n",
            "loss: 0.35546875, time: 2024-12-04 00:48:30.056031, step: 235\n",
            "loss: 0.357421875, time: 2024-12-04 00:48:30.646103, step: 236\n",
            "loss: 0.48046875, time: 2024-12-04 00:48:31.236052, step: 237\n",
            "loss: 0.462890625, time: 2024-12-04 00:48:31.825983, step: 238\n",
            "loss: 0.369140625, time: 2024-12-04 00:48:32.416397, step: 239\n",
            "loss: 0.26953125, time: 2024-12-04 00:48:33.006938, step: 240\n",
            "----- Time -> 2024-12-04 00:48:33.474776 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.328125, time: 2024-12-04 00:48:33.727994, step: 241\n",
            "loss: 0.5625, time: 2024-12-04 00:48:34.318466, step: 242\n",
            "loss: 0.39453125, time: 2024-12-04 00:48:34.908072, step: 243\n",
            "loss: 0.33984375, time: 2024-12-04 00:48:35.498295, step: 244\n",
            "loss: 0.390625, time: 2024-12-04 00:48:36.090842, step: 245\n",
            "loss: 0.322265625, time: 2024-12-04 00:48:36.681275, step: 246\n",
            "loss: 0.59375, time: 2024-12-04 00:48:37.272123, step: 247\n",
            "loss: 0.70703125, time: 2024-12-04 00:48:37.862351, step: 248\n",
            "loss: 0.32421875, time: 2024-12-04 00:48:38.452132, step: 249\n",
            "loss: 0.3828125, time: 2024-12-04 00:48:39.042672, step: 250\n",
            "loss: 0.43359375, time: 2024-12-04 00:48:39.633443, step: 251\n",
            "loss: 0.609375, time: 2024-12-04 00:48:40.223676, step: 252\n",
            "loss: 0.53515625, time: 2024-12-04 00:48:40.813667, step: 253\n",
            "loss: 0.48828125, time: 2024-12-04 00:48:41.404665, step: 254\n",
            "loss: 0.431640625, time: 2024-12-04 00:48:41.994726, step: 255\n",
            "loss: 0.330078125, time: 2024-12-04 00:48:42.584233, step: 256\n",
            "loss: 0.3671875, time: 2024-12-04 00:48:43.174918, step: 257\n",
            "loss: 0.474609375, time: 2024-12-04 00:48:43.764948, step: 258\n",
            "loss: 0.3359375, time: 2024-12-04 00:48:44.354805, step: 259\n",
            "loss: 0.59765625, time: 2024-12-04 00:48:44.945761, step: 260\n",
            "----- Time -> 2024-12-04 00:48:45.412356 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.38671875, time: 2024-12-04 00:48:45.665887, step: 261\n",
            "loss: 0.37890625, time: 2024-12-04 00:48:46.257106, step: 262\n",
            "loss: 0.55078125, time: 2024-12-04 00:48:46.848100, step: 263\n",
            "loss: 0.322265625, time: 2024-12-04 00:48:47.437899, step: 264\n",
            "loss: 0.271484375, time: 2024-12-04 00:48:48.027770, step: 265\n",
            "loss: 0.62109375, time: 2024-12-04 00:48:48.618485, step: 266\n",
            "loss: 0.26171875, time: 2024-12-04 00:48:49.207879, step: 267\n",
            "loss: 0.5078125, time: 2024-12-04 00:48:49.797549, step: 268\n",
            "loss: 0.333984375, time: 2024-12-04 00:48:50.388120, step: 269\n",
            "loss: 0.48046875, time: 2024-12-04 00:48:50.977858, step: 270\n",
            "loss: 0.32421875, time: 2024-12-04 00:48:51.567380, step: 271\n",
            "loss: 0.287109375, time: 2024-12-04 00:48:52.157694, step: 272\n",
            "loss: 0.486328125, time: 2024-12-04 00:48:52.748379, step: 273\n",
            "loss: 0.498046875, time: 2024-12-04 00:48:53.338312, step: 274\n",
            "loss: 0.59765625, time: 2024-12-04 00:48:53.928215, step: 275\n",
            "loss: 0.39453125, time: 2024-12-04 00:48:54.518226, step: 276\n",
            "loss: 0.49609375, time: 2024-12-04 00:48:55.107967, step: 277\n",
            "loss: 0.361328125, time: 2024-12-04 00:48:55.698277, step: 278\n",
            "loss: 0.470703125, time: 2024-12-04 00:48:56.289139, step: 279\n",
            "loss: 0.486328125, time: 2024-12-04 00:48:56.878845, step: 280\n",
            "----- Time -> 2024-12-04 00:48:57.346629 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.5078125, time: 2024-12-04 00:48:57.598390, step: 281\n",
            "loss: 0.412109375, time: 2024-12-04 00:48:58.188161, step: 282\n",
            "loss: 0.58203125, time: 2024-12-04 00:48:58.778555, step: 283\n",
            "loss: 0.6015625, time: 2024-12-04 00:48:59.369555, step: 284\n",
            "loss: 0.32421875, time: 2024-12-04 00:48:59.960168, step: 285\n",
            "loss: 0.53515625, time: 2024-12-04 00:49:00.551877, step: 286\n",
            "loss: 0.46484375, time: 2024-12-04 00:49:01.142665, step: 287\n",
            "loss: 0.5390625, time: 2024-12-04 00:49:01.732555, step: 288\n",
            "loss: 0.60546875, time: 2024-12-04 00:49:02.323480, step: 289\n",
            "loss: 0.4453125, time: 2024-12-04 00:49:02.914075, step: 290\n",
            "loss: 0.443359375, time: 2024-12-04 00:49:03.504519, step: 291\n",
            "loss: 0.490234375, time: 2024-12-04 00:49:04.095242, step: 292\n",
            "loss: 0.3203125, time: 2024-12-04 00:49:04.686137, step: 293\n",
            "loss: 0.451171875, time: 2024-12-04 00:49:05.276661, step: 294\n",
            "loss: 0.3203125, time: 2024-12-04 00:49:05.867477, step: 295\n",
            "loss: 0.6171875, time: 2024-12-04 00:49:06.458474, step: 296\n",
            "loss: 0.328125, time: 2024-12-04 00:49:07.048236, step: 297\n",
            "loss: 0.349609375, time: 2024-12-04 00:49:07.638354, step: 298\n",
            "loss: 0.5, time: 2024-12-04 00:49:08.228764, step: 299\n",
            "loss: 0.328125, time: 2024-12-04 00:49:08.819037, step: 300\n",
            "----- Time -> 2024-12-04 00:49:09.280379 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.421875, time: 2024-12-04 00:49:09.532161, step: 301\n",
            "loss: 0.337890625, time: 2024-12-04 00:49:10.122248, step: 302\n",
            "loss: 0.423828125, time: 2024-12-04 00:49:10.713359, step: 303\n",
            "loss: 0.58984375, time: 2024-12-04 00:49:11.303244, step: 304\n",
            "loss: 0.283203125, time: 2024-12-04 00:49:11.895122, step: 305\n",
            "loss: 0.5859375, time: 2024-12-04 00:49:12.485638, step: 306\n",
            "loss: 0.283203125, time: 2024-12-04 00:49:13.075400, step: 307\n",
            "loss: 0.55859375, time: 2024-12-04 00:49:13.665854, step: 308\n",
            "loss: 0.271484375, time: 2024-12-04 00:49:14.256229, step: 309\n",
            "loss: 0.359375, time: 2024-12-04 00:49:14.846145, step: 310\n",
            "loss: 0.267578125, time: 2024-12-04 00:49:15.436670, step: 311\n",
            "loss: 0.62109375, time: 2024-12-04 00:49:16.027196, step: 312\n",
            "loss: 0.63671875, time: 2024-12-04 00:49:16.616889, step: 313\n",
            "loss: 0.62109375, time: 2024-12-04 00:49:17.207286, step: 314\n",
            "loss: 0.345703125, time: 2024-12-04 00:49:17.797667, step: 315\n",
            "loss: 0.478515625, time: 2024-12-04 00:49:18.387548, step: 316\n",
            "loss: 0.5234375, time: 2024-12-04 00:49:18.977863, step: 317\n",
            "loss: 0.67578125, time: 2024-12-04 00:49:19.568226, step: 318\n",
            "loss: 0.408203125, time: 2024-12-04 00:49:20.157933, step: 319\n",
            "loss: 0.55078125, time: 2024-12-04 00:49:20.748105, step: 320\n",
            "----- Time -> 2024-12-04 00:49:21.211119 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.62890625, time: 2024-12-04 00:49:21.463394, step: 321\n",
            "loss: 0.40625, time: 2024-12-04 00:49:22.053150, step: 322\n",
            "loss: 0.5, time: 2024-12-04 00:49:22.643701, step: 323\n",
            "loss: 0.302734375, time: 2024-12-04 00:49:23.234092, step: 324\n",
            "loss: 0.408203125, time: 2024-12-04 00:49:23.824671, step: 325\n",
            "loss: 0.625, time: 2024-12-04 00:49:24.415124, step: 326\n",
            "loss: 0.56640625, time: 2024-12-04 00:49:25.005863, step: 327\n",
            "loss: 0.5859375, time: 2024-12-04 00:49:25.596168, step: 328\n",
            "loss: 0.298828125, time: 2024-12-04 00:49:26.186084, step: 329\n",
            "loss: 0.330078125, time: 2024-12-04 00:49:26.777003, step: 330\n",
            "loss: 0.53125, time: 2024-12-04 00:49:27.367301, step: 331\n",
            "loss: 0.337890625, time: 2024-12-04 00:49:27.957276, step: 332\n",
            "loss: 0.4609375, time: 2024-12-04 00:49:28.548063, step: 333\n",
            "loss: 0.498046875, time: 2024-12-04 00:49:29.138604, step: 334\n",
            "loss: 0.357421875, time: 2024-12-04 00:49:29.728744, step: 335\n",
            "loss: 0.474609375, time: 2024-12-04 00:49:30.319532, step: 336\n",
            "loss: 0.7109375, time: 2024-12-04 00:49:30.909949, step: 337\n",
            "loss: 0.298828125, time: 2024-12-04 00:49:31.500345, step: 338\n",
            "loss: 0.50390625, time: 2024-12-04 00:49:32.090857, step: 339\n",
            "loss: 0.412109375, time: 2024-12-04 00:49:32.680774, step: 340\n",
            "----- Time -> 2024-12-04 00:49:33.144346 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.47265625, time: 2024-12-04 00:49:33.396661, step: 341\n",
            "loss: 0.671875, time: 2024-12-04 00:49:33.986992, step: 342\n",
            "loss: 0.53125, time: 2024-12-04 00:49:34.577355, step: 343\n",
            "loss: 0.59375, time: 2024-12-04 00:49:35.167761, step: 344\n",
            "loss: 0.400390625, time: 2024-12-04 00:49:35.758710, step: 345\n",
            "loss: 0.494140625, time: 2024-12-04 00:49:36.349060, step: 346\n",
            "loss: 0.5703125, time: 2024-12-04 00:49:36.939155, step: 347\n",
            "loss: 0.279296875, time: 2024-12-04 00:49:37.533147, step: 348\n",
            "loss: 0.291015625, time: 2024-12-04 00:49:38.123356, step: 349\n",
            "loss: 0.423828125, time: 2024-12-04 00:49:38.713232, step: 350\n",
            "loss: 0.44921875, time: 2024-12-04 00:49:39.304398, step: 351\n",
            "loss: 0.61328125, time: 2024-12-04 00:49:39.895054, step: 352\n",
            "loss: 0.3671875, time: 2024-12-04 00:49:40.485245, step: 353\n",
            "loss: 0.375, time: 2024-12-04 00:49:41.076076, step: 354\n",
            "loss: 0.34765625, time: 2024-12-04 00:49:41.667394, step: 355\n",
            "loss: 0.4765625, time: 2024-12-04 00:49:42.257721, step: 356\n",
            "loss: 0.275390625, time: 2024-12-04 00:49:42.848627, step: 357\n",
            "loss: 0.294921875, time: 2024-12-04 00:49:43.438667, step: 358\n",
            "loss: 0.46484375, time: 2024-12-04 00:49:44.028245, step: 359\n",
            "loss: 0.578125, time: 2024-12-04 00:49:44.618610, step: 360\n",
            "----- Time -> 2024-12-04 00:49:45.086047 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.4375, time: 2024-12-04 00:49:45.338936, step: 361\n",
            "loss: 0.3203125, time: 2024-12-04 00:49:45.930538, step: 362\n",
            "loss: 0.412109375, time: 2024-12-04 00:49:46.520707, step: 363\n",
            "loss: 0.396484375, time: 2024-12-04 00:49:47.110202, step: 364\n",
            "loss: 0.53515625, time: 2024-12-04 00:49:47.701039, step: 365\n",
            "loss: 0.5078125, time: 2024-12-04 00:49:48.291685, step: 366\n",
            "loss: 0.59765625, time: 2024-12-04 00:49:48.881266, step: 367\n",
            "loss: 0.337890625, time: 2024-12-04 00:49:49.471498, step: 368\n",
            "loss: 0.2734375, time: 2024-12-04 00:49:50.062207, step: 369\n",
            "loss: 0.322265625, time: 2024-12-04 00:49:50.651857, step: 370\n",
            "loss: 0.41015625, time: 2024-12-04 00:49:51.242173, step: 371\n",
            "loss: 0.51953125, time: 2024-12-04 00:49:51.833298, step: 372\n",
            "loss: 0.451171875, time: 2024-12-04 00:49:52.423188, step: 373\n",
            "loss: 0.3828125, time: 2024-12-04 00:49:53.013140, step: 374\n",
            "loss: 0.5625, time: 2024-12-04 00:49:53.603857, step: 375\n",
            "loss: 0.376953125, time: 2024-12-04 00:49:54.193929, step: 376\n",
            "loss: 0.29296875, time: 2024-12-04 00:49:54.784742, step: 377\n",
            "loss: 0.6015625, time: 2024-12-04 00:49:55.375237, step: 378\n",
            "loss: 0.330078125, time: 2024-12-04 00:49:55.964821, step: 379\n",
            "loss: 0.263671875, time: 2024-12-04 00:49:56.554605, step: 380\n",
            "----- Time -> 2024-12-04 00:49:57.019061 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.56640625, time: 2024-12-04 00:49:57.271175, step: 381\n",
            "loss: 0.3046875, time: 2024-12-04 00:49:57.861574, step: 382\n",
            "loss: 0.443359375, time: 2024-12-04 00:49:58.451912, step: 383\n",
            "loss: 0.416015625, time: 2024-12-04 00:49:59.042467, step: 384\n",
            "loss: 0.26953125, time: 2024-12-04 00:49:59.632486, step: 385\n",
            "loss: 0.3203125, time: 2024-12-04 00:50:00.223435, step: 386\n",
            "loss: 0.5390625, time: 2024-12-04 00:50:00.814108, step: 387\n",
            "loss: 0.3671875, time: 2024-12-04 00:50:01.404105, step: 388\n",
            "loss: 0.330078125, time: 2024-12-04 00:50:01.995046, step: 389\n",
            "loss: 0.419921875, time: 2024-12-04 00:50:02.585891, step: 390\n",
            "loss: 0.486328125, time: 2024-12-04 00:50:03.176143, step: 391\n",
            "loss: 0.34765625, time: 2024-12-04 00:50:03.766631, step: 392\n",
            "loss: 0.59765625, time: 2024-12-04 00:50:04.357276, step: 393\n",
            "loss: 0.353515625, time: 2024-12-04 00:50:04.948052, step: 394\n",
            "loss: 0.5546875, time: 2024-12-04 00:50:05.538651, step: 395\n",
            "loss: 0.421875, time: 2024-12-04 00:50:06.129692, step: 396\n",
            "loss: 0.5625, time: 2024-12-04 00:50:06.720304, step: 397\n",
            "loss: 0.31640625, time: 2024-12-04 00:50:07.311176, step: 398\n",
            "loss: 0.41796875, time: 2024-12-04 00:50:07.901971, step: 399\n",
            "loss: 0.2451171875, time: 2024-12-04 00:50:08.492507, step: 400\n",
            "----- Time -> 2024-12-04 00:50:08.956375 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.30859375, time: 2024-12-04 00:50:09.211001, step: 401\n",
            "loss: 0.3046875, time: 2024-12-04 00:50:09.800906, step: 402\n",
            "loss: 0.466796875, time: 2024-12-04 00:50:10.391998, step: 403\n",
            "loss: 0.44921875, time: 2024-12-04 00:50:10.982890, step: 404\n",
            "loss: 0.287109375, time: 2024-12-04 00:50:11.572736, step: 405\n",
            "loss: 0.310546875, time: 2024-12-04 00:50:12.163585, step: 406\n",
            "loss: 0.5859375, time: 2024-12-04 00:50:12.754174, step: 407\n",
            "loss: 0.546875, time: 2024-12-04 00:50:13.344156, step: 408\n",
            "loss: 0.4375, time: 2024-12-04 00:50:13.935064, step: 409\n",
            "loss: 0.55078125, time: 2024-12-04 00:50:14.525439, step: 410\n",
            "loss: 0.34375, time: 2024-12-04 00:50:15.115456, step: 411\n",
            "loss: 0.48828125, time: 2024-12-04 00:50:15.706808, step: 412\n",
            "loss: 0.43359375, time: 2024-12-04 00:50:16.297070, step: 413\n",
            "loss: 0.2470703125, time: 2024-12-04 00:50:16.887025, step: 414\n",
            "loss: 0.4453125, time: 2024-12-04 00:50:17.477658, step: 415\n",
            "loss: 0.5546875, time: 2024-12-04 00:50:18.068258, step: 416\n",
            "loss: 0.51171875, time: 2024-12-04 00:50:18.658142, step: 417\n",
            "loss: 0.310546875, time: 2024-12-04 00:50:19.248588, step: 418\n",
            "loss: 0.330078125, time: 2024-12-04 00:50:19.839585, step: 419\n",
            "loss: 0.43359375, time: 2024-12-04 00:50:20.429410, step: 420\n",
            "----- Time -> 2024-12-04 00:50:20.893208 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.2421875, time: 2024-12-04 00:50:21.146587, step: 421\n",
            "loss: 0.30078125, time: 2024-12-04 00:50:21.736700, step: 422\n",
            "loss: 0.443359375, time: 2024-12-04 00:50:22.327024, step: 423\n",
            "loss: 0.30078125, time: 2024-12-04 00:50:22.917840, step: 424\n",
            "loss: 0.515625, time: 2024-12-04 00:50:23.507973, step: 425\n",
            "loss: 0.267578125, time: 2024-12-04 00:50:24.097780, step: 426\n",
            "loss: 0.2578125, time: 2024-12-04 00:50:24.688589, step: 427\n",
            "loss: 0.359375, time: 2024-12-04 00:50:25.279154, step: 428\n",
            "loss: 0.236328125, time: 2024-12-04 00:50:25.869088, step: 429\n",
            "loss: 0.388671875, time: 2024-12-04 00:50:26.460621, step: 430\n",
            "loss: 0.234375, time: 2024-12-04 00:50:27.050772, step: 431\n",
            "loss: 0.3828125, time: 2024-12-04 00:50:27.641490, step: 432\n",
            "loss: 0.28125, time: 2024-12-04 00:50:28.231823, step: 433\n",
            "loss: 0.283203125, time: 2024-12-04 00:50:28.821768, step: 434\n",
            "loss: 0.33984375, time: 2024-12-04 00:50:29.412088, step: 435\n",
            "loss: 0.38671875, time: 2024-12-04 00:50:30.002838, step: 436\n",
            "loss: 0.443359375, time: 2024-12-04 00:50:30.593388, step: 437\n",
            "loss: 0.30078125, time: 2024-12-04 00:50:31.183121, step: 438\n",
            "loss: 0.2265625, time: 2024-12-04 00:50:31.774456, step: 439\n",
            "loss: 0.65234375, time: 2024-12-04 00:50:32.364762, step: 440\n",
            "----- Time -> 2024-12-04 00:50:32.828294 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.361328125, time: 2024-12-04 00:50:33.081732, step: 441\n",
            "loss: 0.50390625, time: 2024-12-04 00:50:33.671592, step: 442\n",
            "loss: 0.265625, time: 2024-12-04 00:50:34.261520, step: 443\n",
            "loss: 0.59765625, time: 2024-12-04 00:50:34.852488, step: 444\n",
            "loss: 0.353515625, time: 2024-12-04 00:50:35.442529, step: 445\n",
            "loss: 0.28515625, time: 2024-12-04 00:50:36.032159, step: 446\n",
            "loss: 0.32421875, time: 2024-12-04 00:50:36.622711, step: 447\n",
            "loss: 0.46875, time: 2024-12-04 00:50:37.212930, step: 448\n",
            "loss: 0.373046875, time: 2024-12-04 00:50:37.803366, step: 449\n",
            "loss: 0.59375, time: 2024-12-04 00:50:38.394282, step: 450\n",
            "loss: 0.291015625, time: 2024-12-04 00:50:38.987364, step: 451\n",
            "loss: 0.55078125, time: 2024-12-04 00:50:39.578293, step: 452\n",
            "loss: 0.271484375, time: 2024-12-04 00:50:40.169409, step: 453\n",
            "loss: 0.2314453125, time: 2024-12-04 00:50:40.758855, step: 454\n",
            "loss: 0.478515625, time: 2024-12-04 00:50:41.348649, step: 455\n",
            "loss: 0.494140625, time: 2024-12-04 00:50:41.939191, step: 456\n",
            "loss: 0.61328125, time: 2024-12-04 00:50:42.528929, step: 457\n",
            "loss: 0.333984375, time: 2024-12-04 00:50:43.118496, step: 458\n",
            "loss: 0.578125, time: 2024-12-04 00:50:43.708765, step: 459\n",
            "loss: 0.4375, time: 2024-12-04 00:50:44.299592, step: 460\n",
            "----- Time -> 2024-12-04 00:50:44.759083 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.5859375, time: 2024-12-04 00:50:45.011309, step: 461\n",
            "loss: 0.41015625, time: 2024-12-04 00:50:45.601762, step: 462\n",
            "loss: 0.408203125, time: 2024-12-04 00:50:46.193457, step: 463\n",
            "loss: 0.33984375, time: 2024-12-04 00:50:46.783180, step: 464\n",
            "loss: 0.6796875, time: 2024-12-04 00:50:47.373401, step: 465\n",
            "loss: 0.30859375, time: 2024-12-04 00:50:47.963800, step: 466\n",
            "loss: 0.54296875, time: 2024-12-04 00:50:48.553981, step: 467\n",
            "loss: 0.232421875, time: 2024-12-04 00:50:49.143720, step: 468\n",
            "loss: 0.291015625, time: 2024-12-04 00:50:49.734362, step: 469\n",
            "loss: 0.32421875, time: 2024-12-04 00:50:50.325535, step: 470\n",
            "loss: 0.40625, time: 2024-12-04 00:50:50.915354, step: 471\n",
            "loss: 0.38671875, time: 2024-12-04 00:50:51.505844, step: 472\n",
            "loss: 0.515625, time: 2024-12-04 00:50:52.096240, step: 473\n",
            "loss: 0.447265625, time: 2024-12-04 00:50:52.685999, step: 474\n",
            "loss: 0.51953125, time: 2024-12-04 00:50:53.276765, step: 475\n",
            "loss: 0.51171875, time: 2024-12-04 00:50:53.867037, step: 476\n",
            "loss: 0.609375, time: 2024-12-04 00:50:54.456636, step: 477\n",
            "loss: 0.328125, time: 2024-12-04 00:50:55.046876, step: 478\n",
            "loss: 0.318359375, time: 2024-12-04 00:50:55.637400, step: 479\n",
            "loss: 0.271484375, time: 2024-12-04 00:50:56.226992, step: 480\n",
            "----- Time -> 2024-12-04 00:50:56.694386 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.26953125, time: 2024-12-04 00:50:56.947499, step: 481\n",
            "loss: 0.54296875, time: 2024-12-04 00:50:57.537238, step: 482\n",
            "loss: 0.373046875, time: 2024-12-04 00:50:58.127809, step: 483\n",
            "loss: 0.5234375, time: 2024-12-04 00:50:58.717809, step: 484\n",
            "loss: 0.291015625, time: 2024-12-04 00:50:59.307803, step: 485\n",
            "loss: 0.365234375, time: 2024-12-04 00:50:59.898833, step: 486\n",
            "loss: 0.427734375, time: 2024-12-04 00:51:00.488856, step: 487\n",
            "loss: 0.3984375, time: 2024-12-04 00:51:01.078391, step: 488\n",
            "loss: 0.333984375, time: 2024-12-04 00:51:01.669153, step: 489\n",
            "loss: 0.6328125, time: 2024-12-04 00:51:02.259886, step: 490\n",
            "loss: 0.5859375, time: 2024-12-04 00:51:02.849905, step: 491\n",
            "loss: 0.53515625, time: 2024-12-04 00:51:03.440224, step: 492\n",
            "loss: 0.30078125, time: 2024-12-04 00:51:04.030683, step: 493\n",
            "loss: 0.31640625, time: 2024-12-04 00:51:04.620815, step: 494\n",
            "loss: 0.50390625, time: 2024-12-04 00:51:05.211357, step: 495\n",
            "loss: 0.421875, time: 2024-12-04 00:51:05.801905, step: 496\n",
            "loss: 0.5546875, time: 2024-12-04 00:51:06.391624, step: 497\n",
            "loss: 0.55859375, time: 2024-12-04 00:51:06.981933, step: 498\n",
            "loss: 0.65234375, time: 2024-12-04 00:51:07.572197, step: 499\n",
            "loss: 0.53515625, time: 2024-12-04 00:51:08.161858, step: 500\n",
            "----- Time -> 2024-12-04 00:51:08.621059 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Learning_rate</td><td>â–â–‚â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Learning_rate</td><td>6e-05</td></tr><tr><td>train_loss</td><td>0.53516</td></tr><tr><td>train_step</td><td>500</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lilac-valley-32</strong> at: <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/mcqfzvhs' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/mcqfzvhs</a><br/> View project at: <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241204_004608-mcqfzvhs/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_deriv_configs, train_deriv_loader, testing_deriv_loader, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T19:02:24.616671Z",
          "iopub.execute_input": "2024-11-15T19:02:24.616919Z",
          "iopub.status.idle": "2024-11-15T22:21:29.845300Z",
          "shell.execute_reply.started": "2024-11-15T19:02:24.616894Z",
          "shell.execute_reply": "2024-11-15T22:21:29.843425Z"
        },
        "id": "yg0Qw3Hxu0-f",
        "outputId": "8424185a-4750-4389-df4d-8b4a2f626e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241204_005110-leh90ppl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/leh90ppl' target=\"_blank\">gentle-snowball-33</a></strong> to <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/leh90ppl' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/leh90ppl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch 1 train begin 2024-12-04 00:51:11.448253\n",
            "loss: 1.2890625, time: 2024-12-04 00:51:11.731619, step: 1\n",
            "loss: 2.375, time: 2024-12-04 00:51:12.325095, step: 2\n",
            "loss: 2.421875, time: 2024-12-04 00:51:12.914929, step: 3\n",
            "loss: 1.6484375, time: 2024-12-04 00:51:13.505497, step: 4\n",
            "loss: 1.6953125, time: 2024-12-04 00:51:14.095896, step: 5\n",
            "loss: 2.03125, time: 2024-12-04 00:51:14.685075, step: 6\n",
            "loss: 1.46875, time: 2024-12-04 00:51:15.274935, step: 7\n",
            "loss: 1.921875, time: 2024-12-04 00:51:15.865600, step: 8\n",
            "loss: 1.65625, time: 2024-12-04 00:51:16.455467, step: 9\n",
            "loss: 1.7265625, time: 2024-12-04 00:51:17.045163, step: 10\n",
            "loss: 1.28125, time: 2024-12-04 00:51:17.635686, step: 11\n",
            "loss: 1.2109375, time: 2024-12-04 00:51:18.225854, step: 12\n",
            "loss: 1.09375, time: 2024-12-04 00:51:18.815728, step: 13\n",
            "loss: 0.95703125, time: 2024-12-04 00:51:19.405769, step: 14\n",
            "loss: 0.69921875, time: 2024-12-04 00:51:19.995751, step: 15\n",
            "loss: 0.9765625, time: 2024-12-04 00:51:20.585529, step: 16\n",
            "loss: 1.3046875, time: 2024-12-04 00:51:21.175503, step: 17\n",
            "loss: 0.84765625, time: 2024-12-04 00:51:21.765682, step: 18\n",
            "loss: 0.7890625, time: 2024-12-04 00:51:22.355129, step: 19\n",
            "loss: 1.0703125, time: 2024-12-04 00:51:22.944752, step: 20\n",
            "----- Time -> 2024-12-04 00:51:23.409875 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.8046875, time: 2024-12-04 00:51:23.661487, step: 21\n",
            "loss: 0.93359375, time: 2024-12-04 00:51:24.250844, step: 22\n",
            "loss: 1.234375, time: 2024-12-04 00:51:24.840668, step: 23\n",
            "loss: 1.0390625, time: 2024-12-04 00:51:25.430799, step: 24\n",
            "loss: 0.765625, time: 2024-12-04 00:51:26.020248, step: 25\n",
            "loss: 0.67578125, time: 2024-12-04 00:51:26.609822, step: 26\n",
            "loss: 0.86328125, time: 2024-12-04 00:51:27.199914, step: 27\n",
            "loss: 0.65234375, time: 2024-12-04 00:51:27.790007, step: 28\n",
            "loss: 0.65625, time: 2024-12-04 00:51:28.380170, step: 29\n",
            "loss: 0.66796875, time: 2024-12-04 00:51:28.971119, step: 30\n",
            "loss: 0.58984375, time: 2024-12-04 00:51:29.561214, step: 31\n",
            "loss: 0.2392578125, time: 2024-12-04 00:51:30.150795, step: 32\n",
            "loss: 0.59375, time: 2024-12-04 00:51:30.741003, step: 33\n",
            "loss: 0.52734375, time: 2024-12-04 00:51:31.330707, step: 34\n",
            "loss: 0.546875, time: 2024-12-04 00:51:31.920362, step: 35\n",
            "loss: 0.447265625, time: 2024-12-04 00:51:32.510466, step: 36\n",
            "loss: 0.40234375, time: 2024-12-04 00:51:33.100484, step: 37\n",
            "loss: 0.486328125, time: 2024-12-04 00:51:33.690169, step: 38\n",
            "loss: 0.92578125, time: 2024-12-04 00:51:34.280871, step: 39\n",
            "loss: 0.50390625, time: 2024-12-04 00:51:34.870691, step: 40\n",
            "----- Time -> 2024-12-04 00:51:35.334827 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.369140625, time: 2024-12-04 00:51:35.586443, step: 41\n",
            "loss: 0.318359375, time: 2024-12-04 00:51:36.176570, step: 42\n",
            "loss: 0.640625, time: 2024-12-04 00:51:36.766888, step: 43\n",
            "loss: 0.6953125, time: 2024-12-04 00:51:37.356561, step: 44\n",
            "loss: 0.515625, time: 2024-12-04 00:51:37.946572, step: 45\n",
            "loss: 0.51171875, time: 2024-12-04 00:51:38.536143, step: 46\n",
            "loss: 0.5234375, time: 2024-12-04 00:51:39.125228, step: 47\n",
            "loss: 0.55078125, time: 2024-12-04 00:51:39.715574, step: 48\n",
            "loss: 0.60546875, time: 2024-12-04 00:51:40.324994, step: 49\n",
            "loss: 0.412109375, time: 2024-12-04 00:51:40.915091, step: 50\n",
            "loss: 0.66015625, time: 2024-12-04 00:51:41.505173, step: 51\n",
            "loss: 0.4453125, time: 2024-12-04 00:51:42.095607, step: 52\n",
            "loss: 0.427734375, time: 2024-12-04 00:51:42.685744, step: 53\n",
            "loss: 0.4375, time: 2024-12-04 00:51:43.275944, step: 54\n",
            "loss: 0.65234375, time: 2024-12-04 00:51:43.866223, step: 55\n",
            "loss: 0.42578125, time: 2024-12-04 00:51:44.455837, step: 56\n",
            "loss: 0.28125, time: 2024-12-04 00:51:45.045745, step: 57\n",
            "loss: 0.49609375, time: 2024-12-04 00:51:45.635991, step: 58\n",
            "loss: 0.5625, time: 2024-12-04 00:51:46.225442, step: 59\n",
            "loss: 0.54296875, time: 2024-12-04 00:51:46.816352, step: 60\n",
            "----- Time -> 2024-12-04 00:51:47.276537 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.5625, time: 2024-12-04 00:51:47.528193, step: 61\n",
            "loss: 0.353515625, time: 2024-12-04 00:51:48.117783, step: 62\n",
            "loss: 0.4140625, time: 2024-12-04 00:51:48.707286, step: 63\n",
            "loss: 0.46875, time: 2024-12-04 00:51:49.297358, step: 64\n",
            "loss: 0.41015625, time: 2024-12-04 00:51:49.889430, step: 65\n",
            "loss: 0.326171875, time: 2024-12-04 00:51:50.479397, step: 66\n",
            "loss: 0.55078125, time: 2024-12-04 00:51:51.068578, step: 67\n",
            "loss: 0.478515625, time: 2024-12-04 00:51:51.658994, step: 68\n",
            "loss: 0.49609375, time: 2024-12-04 00:51:52.249339, step: 69\n",
            "loss: 0.423828125, time: 2024-12-04 00:51:52.839657, step: 70\n",
            "loss: 0.6015625, time: 2024-12-04 00:51:53.429850, step: 71\n",
            "loss: 0.37109375, time: 2024-12-04 00:51:54.020891, step: 72\n",
            "loss: 0.52734375, time: 2024-12-04 00:51:54.611538, step: 73\n",
            "loss: 0.3515625, time: 2024-12-04 00:51:55.201842, step: 74\n",
            "loss: 0.48046875, time: 2024-12-04 00:51:55.792232, step: 75\n",
            "loss: 0.64453125, time: 2024-12-04 00:51:56.382127, step: 76\n",
            "loss: 0.55078125, time: 2024-12-04 00:51:56.972703, step: 77\n",
            "loss: 0.357421875, time: 2024-12-04 00:51:57.563076, step: 78\n",
            "loss: 0.466796875, time: 2024-12-04 00:51:58.152967, step: 79\n",
            "loss: 0.1474609375, time: 2024-12-04 00:51:58.743596, step: 80\n",
            "----- Time -> 2024-12-04 00:51:59.209751 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.359375, time: 2024-12-04 00:51:59.461364, step: 81\n",
            "loss: 0.5390625, time: 2024-12-04 00:52:00.050889, step: 82\n",
            "loss: 0.396484375, time: 2024-12-04 00:52:00.641313, step: 83\n",
            "loss: 0.419921875, time: 2024-12-04 00:52:01.231699, step: 84\n",
            "loss: 0.462890625, time: 2024-12-04 00:52:01.821871, step: 85\n",
            "loss: 0.4453125, time: 2024-12-04 00:52:02.412237, step: 86\n",
            "loss: 0.50390625, time: 2024-12-04 00:52:03.002323, step: 87\n",
            "loss: 0.44921875, time: 2024-12-04 00:52:03.591937, step: 88\n",
            "loss: 0.431640625, time: 2024-12-04 00:52:04.181486, step: 89\n",
            "loss: 0.515625, time: 2024-12-04 00:52:04.772042, step: 90\n",
            "loss: 0.52734375, time: 2024-12-04 00:52:05.362462, step: 91\n",
            "loss: 0.51171875, time: 2024-12-04 00:52:05.952144, step: 92\n",
            "loss: 0.466796875, time: 2024-12-04 00:52:06.542852, step: 93\n",
            "loss: 0.2890625, time: 2024-12-04 00:52:07.133340, step: 94\n",
            "loss: 0.421875, time: 2024-12-04 00:52:07.723266, step: 95\n",
            "loss: 0.333984375, time: 2024-12-04 00:52:08.314445, step: 96\n",
            "loss: 0.4921875, time: 2024-12-04 00:52:08.904549, step: 97\n",
            "loss: 0.7890625, time: 2024-12-04 00:52:09.494752, step: 98\n",
            "loss: 0.337890625, time: 2024-12-04 00:52:10.085868, step: 99\n",
            "loss: 0.3125, time: 2024-12-04 00:52:10.676106, step: 100\n",
            "----- Time -> 2024-12-04 00:52:11.141196 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.494140625, time: 2024-12-04 00:52:11.392877, step: 101\n",
            "loss: 0.546875, time: 2024-12-04 00:52:11.983233, step: 102\n",
            "loss: 0.5234375, time: 2024-12-04 00:52:12.572896, step: 103\n",
            "loss: 0.58984375, time: 2024-12-04 00:52:13.163526, step: 104\n",
            "loss: 0.4921875, time: 2024-12-04 00:52:13.754160, step: 105\n",
            "loss: 0.361328125, time: 2024-12-04 00:52:14.344160, step: 106\n",
            "loss: 0.38671875, time: 2024-12-04 00:52:14.934155, step: 107\n",
            "loss: 0.396484375, time: 2024-12-04 00:52:15.524780, step: 108\n",
            "loss: 0.40625, time: 2024-12-04 00:52:16.116417, step: 109\n",
            "loss: 0.3984375, time: 2024-12-04 00:52:16.707149, step: 110\n",
            "loss: 0.447265625, time: 2024-12-04 00:52:17.297829, step: 111\n",
            "loss: 0.52734375, time: 2024-12-04 00:52:17.888055, step: 112\n",
            "loss: 0.48828125, time: 2024-12-04 00:52:18.478042, step: 113\n",
            "loss: 0.31640625, time: 2024-12-04 00:52:19.069055, step: 114\n",
            "loss: 0.330078125, time: 2024-12-04 00:52:19.659238, step: 115\n",
            "loss: 0.369140625, time: 2024-12-04 00:52:20.250262, step: 116\n",
            "loss: 0.388671875, time: 2024-12-04 00:52:20.841264, step: 117\n",
            "loss: 0.361328125, time: 2024-12-04 00:52:21.431456, step: 118\n",
            "loss: 0.296875, time: 2024-12-04 00:52:22.021187, step: 119\n",
            "loss: 0.365234375, time: 2024-12-04 00:52:22.612334, step: 120\n",
            "----- Time -> 2024-12-04 00:52:23.071692 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.205078125, time: 2024-12-04 00:52:23.323324, step: 121\n",
            "loss: 0.28125, time: 2024-12-04 00:52:23.912833, step: 122\n",
            "loss: 0.439453125, time: 2024-12-04 00:52:24.503477, step: 123\n",
            "loss: 0.6640625, time: 2024-12-04 00:52:25.093349, step: 124\n",
            "loss: 0.37890625, time: 2024-12-04 00:52:25.682865, step: 125\n",
            "loss: 0.484375, time: 2024-12-04 00:52:26.273799, step: 126\n",
            "loss: 0.390625, time: 2024-12-04 00:52:26.864205, step: 127\n",
            "loss: 0.40234375, time: 2024-12-04 00:52:27.453840, step: 128\n",
            "loss: 0.2001953125, time: 2024-12-04 00:52:28.044369, step: 129\n",
            "loss: 0.51171875, time: 2024-12-04 00:52:28.634494, step: 130\n",
            "loss: 0.427734375, time: 2024-12-04 00:52:29.224512, step: 131\n",
            "loss: 0.5625, time: 2024-12-04 00:52:29.815242, step: 132\n",
            "loss: 0.46875, time: 2024-12-04 00:52:30.406188, step: 133\n",
            "loss: 0.37109375, time: 2024-12-04 00:52:30.995885, step: 134\n",
            "loss: 0.296875, time: 2024-12-04 00:52:31.587325, step: 135\n",
            "loss: 0.39453125, time: 2024-12-04 00:52:32.178005, step: 136\n",
            "loss: 0.451171875, time: 2024-12-04 00:52:32.767825, step: 137\n",
            "loss: 0.388671875, time: 2024-12-04 00:52:33.359270, step: 138\n",
            "loss: 0.44921875, time: 2024-12-04 00:52:33.949382, step: 139\n",
            "loss: 0.462890625, time: 2024-12-04 00:52:34.539071, step: 140\n",
            "----- Time -> 2024-12-04 00:52:35.007988 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.384765625, time: 2024-12-04 00:52:35.260062, step: 141\n",
            "loss: 0.296875, time: 2024-12-04 00:52:35.850212, step: 142\n",
            "loss: 0.42578125, time: 2024-12-04 00:52:36.440920, step: 143\n",
            "loss: 0.376953125, time: 2024-12-04 00:52:37.031339, step: 144\n",
            "loss: 0.44140625, time: 2024-12-04 00:52:37.621182, step: 145\n",
            "loss: 0.455078125, time: 2024-12-04 00:52:38.211748, step: 146\n",
            "loss: 0.291015625, time: 2024-12-04 00:52:38.802454, step: 147\n",
            "loss: 0.431640625, time: 2024-12-04 00:52:39.392503, step: 148\n",
            "loss: 0.5390625, time: 2024-12-04 00:52:39.982815, step: 149\n",
            "loss: 0.2138671875, time: 2024-12-04 00:52:40.573299, step: 150\n",
            "loss: 0.4921875, time: 2024-12-04 00:52:41.163510, step: 151\n",
            "loss: 0.28515625, time: 2024-12-04 00:52:41.776049, step: 152\n",
            "loss: 0.4140625, time: 2024-12-04 00:52:42.367153, step: 153\n",
            "loss: 0.322265625, time: 2024-12-04 00:52:42.957096, step: 154\n",
            "loss: 0.283203125, time: 2024-12-04 00:52:43.548539, step: 155\n",
            "loss: 0.51953125, time: 2024-12-04 00:52:44.139086, step: 156\n",
            "loss: 0.267578125, time: 2024-12-04 00:52:44.729070, step: 157\n",
            "loss: 0.470703125, time: 2024-12-04 00:52:45.320100, step: 158\n",
            "loss: 0.275390625, time: 2024-12-04 00:52:45.910286, step: 159\n",
            "loss: 0.369140625, time: 2024-12-04 00:52:46.500136, step: 160\n",
            "----- Time -> 2024-12-04 00:52:46.963256 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.482421875, time: 2024-12-04 00:52:47.214738, step: 161\n",
            "loss: 0.43359375, time: 2024-12-04 00:52:47.804787, step: 162\n",
            "loss: 0.462890625, time: 2024-12-04 00:52:48.395057, step: 163\n",
            "loss: 0.484375, time: 2024-12-04 00:52:48.985275, step: 164\n",
            "loss: 0.43359375, time: 2024-12-04 00:52:49.575280, step: 165\n",
            "loss: 0.392578125, time: 2024-12-04 00:52:50.165346, step: 166\n",
            "loss: 0.404296875, time: 2024-12-04 00:52:50.756652, step: 167\n",
            "loss: 0.384765625, time: 2024-12-04 00:52:51.347021, step: 168\n",
            "loss: 0.435546875, time: 2024-12-04 00:52:51.938073, step: 169\n",
            "loss: 0.36328125, time: 2024-12-04 00:52:52.528945, step: 170\n",
            "loss: 0.349609375, time: 2024-12-04 00:52:53.119122, step: 171\n",
            "loss: 0.486328125, time: 2024-12-04 00:52:53.709351, step: 172\n",
            "loss: 0.314453125, time: 2024-12-04 00:52:54.300492, step: 173\n",
            "loss: 0.443359375, time: 2024-12-04 00:52:54.890787, step: 174\n",
            "loss: 0.3984375, time: 2024-12-04 00:52:55.481267, step: 175\n",
            "loss: 0.3984375, time: 2024-12-04 00:52:56.072368, step: 176\n",
            "loss: 0.435546875, time: 2024-12-04 00:52:56.663265, step: 177\n",
            "loss: 0.546875, time: 2024-12-04 00:52:57.253599, step: 178\n",
            "loss: 0.376953125, time: 2024-12-04 00:52:57.844892, step: 179\n",
            "loss: 0.30859375, time: 2024-12-04 00:52:58.435278, step: 180\n",
            "----- Time -> 2024-12-04 00:52:58.901007 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.375, time: 2024-12-04 00:52:59.152954, step: 181\n",
            "loss: 0.431640625, time: 2024-12-04 00:52:59.745590, step: 182\n",
            "loss: 0.318359375, time: 2024-12-04 00:53:00.336185, step: 183\n",
            "loss: 0.466796875, time: 2024-12-04 00:53:00.926211, step: 184\n",
            "loss: 0.443359375, time: 2024-12-04 00:53:01.517014, step: 185\n",
            "loss: 0.384765625, time: 2024-12-04 00:53:02.107368, step: 186\n",
            "loss: 0.3671875, time: 2024-12-04 00:53:02.697316, step: 187\n",
            "loss: 0.60546875, time: 2024-12-04 00:53:03.288480, step: 188\n",
            "loss: 0.38671875, time: 2024-12-04 00:53:03.878876, step: 189\n",
            "loss: 0.31640625, time: 2024-12-04 00:53:04.468859, step: 190\n",
            "loss: 0.435546875, time: 2024-12-04 00:53:05.059775, step: 191\n",
            "loss: 0.33984375, time: 2024-12-04 00:53:05.650502, step: 192\n",
            "loss: 0.240234375, time: 2024-12-04 00:53:06.240503, step: 193\n",
            "loss: 0.333984375, time: 2024-12-04 00:53:06.832697, step: 194\n",
            "loss: 0.453125, time: 2024-12-04 00:53:07.423028, step: 195\n",
            "loss: 0.353515625, time: 2024-12-04 00:53:08.013423, step: 196\n",
            "loss: 0.42578125, time: 2024-12-04 00:53:08.604294, step: 197\n",
            "loss: 0.48046875, time: 2024-12-04 00:53:09.194965, step: 198\n",
            "loss: 0.625, time: 2024-12-04 00:53:09.784852, step: 199\n",
            "loss: 0.38671875, time: 2024-12-04 00:53:10.375338, step: 200\n",
            "----- Time -> 2024-12-04 00:53:10.839502 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.388671875, time: 2024-12-04 00:53:11.091141, step: 201\n",
            "loss: 0.494140625, time: 2024-12-04 00:53:11.680821, step: 202\n",
            "loss: 0.54296875, time: 2024-12-04 00:53:12.271535, step: 203\n",
            "loss: 0.38671875, time: 2024-12-04 00:53:12.862567, step: 204\n",
            "loss: 0.423828125, time: 2024-12-04 00:53:13.452112, step: 205\n",
            "loss: 0.408203125, time: 2024-12-04 00:53:14.042452, step: 206\n",
            "loss: 0.474609375, time: 2024-12-04 00:53:14.632825, step: 207\n",
            "loss: 0.4921875, time: 2024-12-04 00:53:15.223124, step: 208\n",
            "loss: 0.380859375, time: 2024-12-04 00:53:15.813412, step: 209\n",
            "loss: 0.224609375, time: 2024-12-04 00:53:16.403669, step: 210\n",
            "loss: 0.421875, time: 2024-12-04 00:53:16.993242, step: 211\n",
            "loss: 0.373046875, time: 2024-12-04 00:53:17.583412, step: 212\n",
            "loss: 0.40234375, time: 2024-12-04 00:53:18.174199, step: 213\n",
            "loss: 0.478515625, time: 2024-12-04 00:53:18.764370, step: 214\n",
            "loss: 0.484375, time: 2024-12-04 00:53:19.354035, step: 215\n",
            "loss: 0.365234375, time: 2024-12-04 00:53:19.944628, step: 216\n",
            "loss: 0.408203125, time: 2024-12-04 00:53:20.534916, step: 217\n",
            "loss: 0.1630859375, time: 2024-12-04 00:53:21.124697, step: 218\n",
            "loss: 0.5078125, time: 2024-12-04 00:53:21.715821, step: 219\n",
            "loss: 0.388671875, time: 2024-12-04 00:53:22.306532, step: 220\n",
            "----- Time -> 2024-12-04 00:53:22.766653 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.314453125, time: 2024-12-04 00:53:23.018571, step: 221\n",
            "loss: 0.51171875, time: 2024-12-04 00:53:23.609588, step: 222\n",
            "loss: 0.4140625, time: 2024-12-04 00:53:24.199918, step: 223\n",
            "loss: 0.357421875, time: 2024-12-04 00:53:24.789653, step: 224\n",
            "loss: 0.439453125, time: 2024-12-04 00:53:25.380140, step: 225\n",
            "loss: 0.455078125, time: 2024-12-04 00:53:25.970438, step: 226\n",
            "loss: 0.36328125, time: 2024-12-04 00:53:26.560384, step: 227\n",
            "loss: 0.369140625, time: 2024-12-04 00:53:27.151348, step: 228\n",
            "loss: 0.408203125, time: 2024-12-04 00:53:27.741485, step: 229\n",
            "loss: 0.361328125, time: 2024-12-04 00:53:28.331569, step: 230\n",
            "loss: 0.34765625, time: 2024-12-04 00:53:28.922080, step: 231\n",
            "loss: 0.357421875, time: 2024-12-04 00:53:29.512777, step: 232\n",
            "loss: 0.314453125, time: 2024-12-04 00:53:30.102600, step: 233\n",
            "loss: 0.404296875, time: 2024-12-04 00:53:30.693468, step: 234\n",
            "loss: 0.2294921875, time: 2024-12-04 00:53:31.283800, step: 235\n",
            "loss: 0.4765625, time: 2024-12-04 00:53:31.873609, step: 236\n",
            "loss: 0.419921875, time: 2024-12-04 00:53:32.464595, step: 237\n",
            "loss: 0.380859375, time: 2024-12-04 00:53:33.055297, step: 238\n",
            "loss: 0.341796875, time: 2024-12-04 00:53:33.644935, step: 239\n",
            "loss: 0.451171875, time: 2024-12-04 00:53:34.235855, step: 240\n",
            "----- Time -> 2024-12-04 00:53:34.695743 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.375, time: 2024-12-04 00:53:34.947287, step: 241\n",
            "loss: 0.423828125, time: 2024-12-04 00:53:35.536533, step: 242\n",
            "loss: 0.55859375, time: 2024-12-04 00:53:36.126938, step: 243\n",
            "loss: 0.34765625, time: 2024-12-04 00:53:36.717477, step: 244\n",
            "loss: 0.353515625, time: 2024-12-04 00:53:37.307418, step: 245\n",
            "loss: 0.45703125, time: 2024-12-04 00:53:37.897685, step: 246\n",
            "loss: 0.47265625, time: 2024-12-04 00:53:38.488053, step: 247\n",
            "loss: 0.439453125, time: 2024-12-04 00:53:39.077544, step: 248\n",
            "loss: 0.34375, time: 2024-12-04 00:53:39.667979, step: 249\n",
            "loss: 0.380859375, time: 2024-12-04 00:53:40.259111, step: 250\n",
            "loss: 0.30859375, time: 2024-12-04 00:53:40.848804, step: 251\n",
            "loss: 0.32421875, time: 2024-12-04 00:53:41.438854, step: 252\n",
            "loss: 0.37109375, time: 2024-12-04 00:53:42.029249, step: 253\n",
            "loss: 0.484375, time: 2024-12-04 00:53:42.618936, step: 254\n",
            "loss: 0.40234375, time: 2024-12-04 00:53:43.246730, step: 255\n",
            "loss: 0.41796875, time: 2024-12-04 00:53:43.837859, step: 256\n",
            "loss: 0.416015625, time: 2024-12-04 00:53:44.427909, step: 257\n",
            "loss: 0.357421875, time: 2024-12-04 00:53:45.018082, step: 258\n",
            "loss: 0.486328125, time: 2024-12-04 00:53:45.608801, step: 259\n",
            "loss: 0.490234375, time: 2024-12-04 00:53:46.198749, step: 260\n",
            "----- Time -> 2024-12-04 00:53:46.666474 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.443359375, time: 2024-12-04 00:53:46.918660, step: 261\n",
            "loss: 0.46484375, time: 2024-12-04 00:53:47.509054, step: 262\n",
            "loss: 0.375, time: 2024-12-04 00:53:48.098460, step: 263\n",
            "loss: 0.345703125, time: 2024-12-04 00:53:48.688880, step: 264\n",
            "loss: 0.302734375, time: 2024-12-04 00:53:49.279246, step: 265\n",
            "loss: 0.4765625, time: 2024-12-04 00:53:49.868798, step: 266\n",
            "loss: 0.359375, time: 2024-12-04 00:53:50.458219, step: 267\n",
            "loss: 0.328125, time: 2024-12-04 00:53:51.048392, step: 268\n",
            "loss: 0.419921875, time: 2024-12-04 00:53:51.638313, step: 269\n",
            "loss: 0.390625, time: 2024-12-04 00:53:52.227771, step: 270\n",
            "loss: 0.263671875, time: 2024-12-04 00:53:52.819218, step: 271\n",
            "loss: 0.341796875, time: 2024-12-04 00:53:53.409311, step: 272\n",
            "loss: 0.431640625, time: 2024-12-04 00:53:53.998627, step: 273\n",
            "loss: 0.421875, time: 2024-12-04 00:53:54.589250, step: 274\n",
            "loss: 0.380859375, time: 2024-12-04 00:53:55.179217, step: 275\n",
            "loss: 0.408203125, time: 2024-12-04 00:53:55.769161, step: 276\n",
            "loss: 0.490234375, time: 2024-12-04 00:53:56.359690, step: 277\n",
            "loss: 0.349609375, time: 2024-12-04 00:53:56.949937, step: 278\n",
            "loss: 0.416015625, time: 2024-12-04 00:53:57.539851, step: 279\n",
            "loss: 0.451171875, time: 2024-12-04 00:53:58.130439, step: 280\n",
            "----- Time -> 2024-12-04 00:53:58.598359 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.373046875, time: 2024-12-04 00:53:58.850457, step: 281\n",
            "loss: 0.578125, time: 2024-12-04 00:53:59.442306, step: 282\n",
            "loss: 0.298828125, time: 2024-12-04 00:54:00.032197, step: 283\n",
            "loss: 0.50390625, time: 2024-12-04 00:54:00.622049, step: 284\n",
            "loss: 0.46875, time: 2024-12-04 00:54:01.212339, step: 285\n",
            "loss: 0.4375, time: 2024-12-04 00:54:01.803122, step: 286\n",
            "loss: 0.326171875, time: 2024-12-04 00:54:02.392738, step: 287\n",
            "loss: 0.35546875, time: 2024-12-04 00:54:02.982769, step: 288\n",
            "loss: 0.408203125, time: 2024-12-04 00:54:03.573167, step: 289\n",
            "loss: 0.42578125, time: 2024-12-04 00:54:04.163241, step: 290\n",
            "loss: 0.447265625, time: 2024-12-04 00:54:04.752996, step: 291\n",
            "loss: 0.4140625, time: 2024-12-04 00:54:05.343390, step: 292\n",
            "loss: 0.443359375, time: 2024-12-04 00:54:05.933641, step: 293\n",
            "loss: 0.451171875, time: 2024-12-04 00:54:06.523232, step: 294\n",
            "loss: 0.421875, time: 2024-12-04 00:54:07.113499, step: 295\n",
            "loss: 0.431640625, time: 2024-12-04 00:54:07.703680, step: 296\n",
            "loss: 0.46875, time: 2024-12-04 00:54:08.293721, step: 297\n",
            "loss: 0.44921875, time: 2024-12-04 00:54:08.883218, step: 298\n",
            "loss: 0.3046875, time: 2024-12-04 00:54:09.473567, step: 299\n",
            "loss: 0.49609375, time: 2024-12-04 00:54:10.064084, step: 300\n",
            "----- Time -> 2024-12-04 00:54:10.526533 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.33203125, time: 2024-12-04 00:54:10.778123, step: 301\n",
            "loss: 0.419921875, time: 2024-12-04 00:54:11.368645, step: 302\n",
            "loss: 0.34375, time: 2024-12-04 00:54:11.959400, step: 303\n",
            "loss: 0.46875, time: 2024-12-04 00:54:12.549819, step: 304\n",
            "loss: 0.421875, time: 2024-12-04 00:54:13.140746, step: 305\n",
            "loss: 0.345703125, time: 2024-12-04 00:54:13.730901, step: 306\n",
            "loss: 0.53515625, time: 2024-12-04 00:54:14.320809, step: 307\n",
            "loss: 0.419921875, time: 2024-12-04 00:54:14.911155, step: 308\n",
            "loss: 0.51953125, time: 2024-12-04 00:54:15.502159, step: 309\n",
            "loss: 0.275390625, time: 2024-12-04 00:54:16.091850, step: 310\n",
            "loss: 0.359375, time: 2024-12-04 00:54:16.682246, step: 311\n",
            "loss: 0.296875, time: 2024-12-04 00:54:17.272857, step: 312\n",
            "loss: 0.392578125, time: 2024-12-04 00:54:17.862675, step: 313\n",
            "loss: 0.462890625, time: 2024-12-04 00:54:18.452722, step: 314\n",
            "loss: 0.4609375, time: 2024-12-04 00:54:19.042976, step: 315\n",
            "loss: 0.21875, time: 2024-12-04 00:54:19.632475, step: 316\n",
            "loss: 0.4296875, time: 2024-12-04 00:54:20.222710, step: 317\n",
            "loss: 0.478515625, time: 2024-12-04 00:54:20.813094, step: 318\n",
            "loss: 0.341796875, time: 2024-12-04 00:54:21.403150, step: 319\n",
            "loss: 0.2890625, time: 2024-12-04 00:54:21.992543, step: 320\n",
            "----- Time -> 2024-12-04 00:54:22.467103 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.2890625, time: 2024-12-04 00:54:22.718690, step: 321\n",
            "loss: 0.318359375, time: 2024-12-04 00:54:23.309618, step: 322\n",
            "loss: 0.478515625, time: 2024-12-04 00:54:23.900558, step: 323\n",
            "loss: 0.3515625, time: 2024-12-04 00:54:24.490304, step: 324\n",
            "loss: 0.376953125, time: 2024-12-04 00:54:25.081072, step: 325\n",
            "loss: 0.4921875, time: 2024-12-04 00:54:25.671467, step: 326\n",
            "loss: 0.43359375, time: 2024-12-04 00:54:26.261509, step: 327\n",
            "loss: 0.625, time: 2024-12-04 00:54:26.852160, step: 328\n",
            "loss: 0.46484375, time: 2024-12-04 00:54:27.443058, step: 329\n",
            "loss: 0.3984375, time: 2024-12-04 00:54:28.032759, step: 330\n",
            "loss: 0.390625, time: 2024-12-04 00:54:28.623655, step: 331\n",
            "loss: 0.29296875, time: 2024-12-04 00:54:29.214854, step: 332\n",
            "loss: 0.32421875, time: 2024-12-04 00:54:29.804808, step: 333\n",
            "loss: 0.47265625, time: 2024-12-04 00:54:30.395125, step: 334\n",
            "loss: 0.29296875, time: 2024-12-04 00:54:30.986244, step: 335\n",
            "loss: 0.43359375, time: 2024-12-04 00:54:31.576434, step: 336\n",
            "loss: 0.470703125, time: 2024-12-04 00:54:32.167251, step: 337\n",
            "loss: 0.3203125, time: 2024-12-04 00:54:32.757580, step: 338\n",
            "loss: 0.5, time: 2024-12-04 00:54:33.347481, step: 339\n",
            "loss: 0.37109375, time: 2024-12-04 00:54:33.936969, step: 340\n",
            "----- Time -> 2024-12-04 00:54:34.405767 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.408203125, time: 2024-12-04 00:54:34.658759, step: 341\n",
            "loss: 0.3203125, time: 2024-12-04 00:54:35.249272, step: 342\n",
            "loss: 0.43359375, time: 2024-12-04 00:54:35.841592, step: 343\n",
            "loss: 0.41015625, time: 2024-12-04 00:54:36.431651, step: 344\n",
            "loss: 0.466796875, time: 2024-12-04 00:54:37.022521, step: 345\n",
            "loss: 0.37890625, time: 2024-12-04 00:54:37.613133, step: 346\n",
            "loss: 0.34765625, time: 2024-12-04 00:54:38.202826, step: 347\n",
            "loss: 0.423828125, time: 2024-12-04 00:54:38.793516, step: 348\n",
            "loss: 0.462890625, time: 2024-12-04 00:54:39.384364, step: 349\n",
            "loss: 0.373046875, time: 2024-12-04 00:54:39.974082, step: 350\n",
            "loss: 0.353515625, time: 2024-12-04 00:54:40.564335, step: 351\n",
            "loss: 0.33984375, time: 2024-12-04 00:54:41.155270, step: 352\n",
            "loss: 0.314453125, time: 2024-12-04 00:54:41.745165, step: 353\n",
            "loss: 0.384765625, time: 2024-12-04 00:54:42.335545, step: 354\n",
            "loss: 0.40234375, time: 2024-12-04 00:54:42.925868, step: 355\n",
            "loss: 0.416015625, time: 2024-12-04 00:54:43.515797, step: 356\n",
            "loss: 0.376953125, time: 2024-12-04 00:54:44.106122, step: 357\n",
            "loss: 0.373046875, time: 2024-12-04 00:54:44.727960, step: 358\n",
            "loss: 0.427734375, time: 2024-12-04 00:54:45.318941, step: 359\n",
            "loss: 0.2734375, time: 2024-12-04 00:54:45.909293, step: 360\n",
            "----- Time -> 2024-12-04 00:54:46.372366 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.408203125, time: 2024-12-04 00:54:46.624417, step: 361\n",
            "loss: 0.50390625, time: 2024-12-04 00:54:47.215216, step: 362\n",
            "loss: 0.42578125, time: 2024-12-04 00:54:47.805450, step: 363\n",
            "loss: 0.369140625, time: 2024-12-04 00:54:48.395706, step: 364\n",
            "loss: 0.431640625, time: 2024-12-04 00:54:48.986788, step: 365\n",
            "loss: 0.251953125, time: 2024-12-04 00:54:49.577113, step: 366\n",
            "loss: 0.275390625, time: 2024-12-04 00:54:50.166804, step: 367\n",
            "loss: 0.369140625, time: 2024-12-04 00:54:50.757153, step: 368\n",
            "loss: 0.45703125, time: 2024-12-04 00:54:51.347199, step: 369\n",
            "loss: 0.361328125, time: 2024-12-04 00:54:51.937221, step: 370\n",
            "loss: 0.2392578125, time: 2024-12-04 00:54:52.527735, step: 371\n",
            "loss: 0.330078125, time: 2024-12-04 00:54:53.117326, step: 372\n",
            "loss: 0.37109375, time: 2024-12-04 00:54:53.706784, step: 373\n",
            "loss: 0.5, time: 2024-12-04 00:54:54.297082, step: 374\n",
            "loss: 0.423828125, time: 2024-12-04 00:54:54.887767, step: 375\n",
            "loss: 0.291015625, time: 2024-12-04 00:54:55.477607, step: 376\n",
            "loss: 0.318359375, time: 2024-12-04 00:54:56.068021, step: 377\n",
            "loss: 0.38671875, time: 2024-12-04 00:54:56.658712, step: 378\n",
            "loss: 0.37109375, time: 2024-12-04 00:54:57.249387, step: 379\n",
            "loss: 0.369140625, time: 2024-12-04 00:54:57.840287, step: 380\n",
            "----- Time -> 2024-12-04 00:54:58.301375 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.375, time: 2024-12-04 00:54:58.553747, step: 381\n",
            "loss: 0.392578125, time: 2024-12-04 00:54:59.143516, step: 382\n",
            "loss: 0.3359375, time: 2024-12-04 00:54:59.733573, step: 383\n",
            "loss: 0.2138671875, time: 2024-12-04 00:55:00.324669, step: 384\n",
            "loss: 0.451171875, time: 2024-12-04 00:55:00.914893, step: 385\n",
            "loss: 0.3671875, time: 2024-12-04 00:55:01.504939, step: 386\n",
            "loss: 0.50390625, time: 2024-12-04 00:55:02.096215, step: 387\n",
            "loss: 0.37890625, time: 2024-12-04 00:55:02.687525, step: 388\n",
            "loss: 0.40625, time: 2024-12-04 00:55:03.277709, step: 389\n",
            "loss: 0.392578125, time: 2024-12-04 00:55:03.868875, step: 390\n",
            "loss: 0.357421875, time: 2024-12-04 00:55:04.459049, step: 391\n",
            "loss: 0.44921875, time: 2024-12-04 00:55:05.048827, step: 392\n",
            "loss: 0.4375, time: 2024-12-04 00:55:05.639642, step: 393\n",
            "loss: 0.345703125, time: 2024-12-04 00:55:06.230049, step: 394\n",
            "loss: 0.34765625, time: 2024-12-04 00:55:06.820054, step: 395\n",
            "loss: 0.416015625, time: 2024-12-04 00:55:07.411120, step: 396\n",
            "loss: 0.390625, time: 2024-12-04 00:55:08.000810, step: 397\n",
            "loss: 0.279296875, time: 2024-12-04 00:55:08.590452, step: 398\n",
            "loss: 0.326171875, time: 2024-12-04 00:55:09.180935, step: 399\n",
            "loss: 0.4296875, time: 2024-12-04 00:55:09.770933, step: 400\n",
            "----- Time -> 2024-12-04 00:55:10.236886 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.41015625, time: 2024-12-04 00:55:10.488517, step: 401\n",
            "loss: 0.455078125, time: 2024-12-04 00:55:11.078817, step: 402\n",
            "loss: 0.45703125, time: 2024-12-04 00:55:11.668925, step: 403\n",
            "loss: 0.369140625, time: 2024-12-04 00:55:12.258993, step: 404\n",
            "loss: 0.375, time: 2024-12-04 00:55:12.850020, step: 405\n",
            "loss: 0.443359375, time: 2024-12-04 00:55:13.440973, step: 406\n",
            "loss: 0.4296875, time: 2024-12-04 00:55:14.030660, step: 407\n",
            "loss: 0.373046875, time: 2024-12-04 00:55:14.622207, step: 408\n",
            "loss: 0.474609375, time: 2024-12-04 00:55:15.213480, step: 409\n",
            "loss: 0.359375, time: 2024-12-04 00:55:15.803219, step: 410\n",
            "loss: 0.44140625, time: 2024-12-04 00:55:16.393527, step: 411\n",
            "loss: 0.35546875, time: 2024-12-04 00:55:16.983567, step: 412\n",
            "loss: 0.412109375, time: 2024-12-04 00:55:17.572943, step: 413\n",
            "loss: 0.4375, time: 2024-12-04 00:55:18.163588, step: 414\n",
            "loss: 0.341796875, time: 2024-12-04 00:55:18.754290, step: 415\n",
            "loss: 0.447265625, time: 2024-12-04 00:55:19.344327, step: 416\n",
            "loss: 0.302734375, time: 2024-12-04 00:55:19.934190, step: 417\n",
            "loss: 0.37109375, time: 2024-12-04 00:55:20.524695, step: 418\n",
            "loss: 0.388671875, time: 2024-12-04 00:55:21.116774, step: 419\n",
            "loss: 0.54296875, time: 2024-12-04 00:55:21.706601, step: 420\n",
            "----- Time -> 2024-12-04 00:55:22.167666 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.46484375, time: 2024-12-04 00:55:22.419100, step: 421\n",
            "loss: 0.39453125, time: 2024-12-04 00:55:23.009166, step: 422\n",
            "loss: 0.29296875, time: 2024-12-04 00:55:23.598912, step: 423\n",
            "loss: 0.419921875, time: 2024-12-04 00:55:24.189333, step: 424\n",
            "loss: 0.50390625, time: 2024-12-04 00:55:24.779369, step: 425\n",
            "loss: 0.255859375, time: 2024-12-04 00:55:25.369402, step: 426\n",
            "loss: 0.404296875, time: 2024-12-04 00:55:25.960335, step: 427\n",
            "loss: 0.3984375, time: 2024-12-04 00:55:26.551815, step: 428\n",
            "loss: 0.2431640625, time: 2024-12-04 00:55:27.141452, step: 429\n",
            "loss: 0.3359375, time: 2024-12-04 00:55:27.732218, step: 430\n",
            "loss: 0.404296875, time: 2024-12-04 00:55:28.322580, step: 431\n",
            "loss: 0.330078125, time: 2024-12-04 00:55:28.911963, step: 432\n",
            "loss: 0.2578125, time: 2024-12-04 00:55:29.502392, step: 433\n",
            "loss: 0.34375, time: 2024-12-04 00:55:30.092892, step: 434\n",
            "loss: 0.40625, time: 2024-12-04 00:55:30.682526, step: 435\n",
            "loss: 0.400390625, time: 2024-12-04 00:55:31.273290, step: 436\n",
            "loss: 0.416015625, time: 2024-12-04 00:55:31.863951, step: 437\n",
            "loss: 0.294921875, time: 2024-12-04 00:55:32.453736, step: 438\n",
            "loss: 0.345703125, time: 2024-12-04 00:55:33.043136, step: 439\n",
            "loss: 0.375, time: 2024-12-04 00:55:33.633531, step: 440\n",
            "----- Time -> 2024-12-04 00:55:34.096494 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.373046875, time: 2024-12-04 00:55:34.347939, step: 441\n",
            "loss: 0.47265625, time: 2024-12-04 00:55:34.937834, step: 442\n",
            "loss: 0.322265625, time: 2024-12-04 00:55:35.528670, step: 443\n",
            "loss: 0.318359375, time: 2024-12-04 00:55:36.119254, step: 444\n",
            "loss: 0.36328125, time: 2024-12-04 00:55:36.709062, step: 445\n",
            "loss: 0.3828125, time: 2024-12-04 00:55:37.299789, step: 446\n",
            "loss: 0.41796875, time: 2024-12-04 00:55:37.890590, step: 447\n",
            "loss: 0.19921875, time: 2024-12-04 00:55:38.480665, step: 448\n",
            "loss: 0.41015625, time: 2024-12-04 00:55:39.071672, step: 449\n",
            "loss: 0.3984375, time: 2024-12-04 00:55:39.662018, step: 450\n",
            "loss: 0.34765625, time: 2024-12-04 00:55:40.251937, step: 451\n",
            "loss: 0.326171875, time: 2024-12-04 00:55:40.842571, step: 452\n",
            "loss: 0.431640625, time: 2024-12-04 00:55:41.432802, step: 453\n",
            "loss: 0.376953125, time: 2024-12-04 00:55:42.022658, step: 454\n",
            "loss: 0.384765625, time: 2024-12-04 00:55:42.613263, step: 455\n",
            "loss: 0.388671875, time: 2024-12-04 00:55:43.203548, step: 456\n",
            "loss: 0.306640625, time: 2024-12-04 00:55:43.793345, step: 457\n",
            "loss: 0.4140625, time: 2024-12-04 00:55:44.384045, step: 458\n",
            "loss: 0.4375, time: 2024-12-04 00:55:44.973978, step: 459\n",
            "loss: 0.46875, time: 2024-12-04 00:55:45.563884, step: 460\n",
            "----- Time -> 2024-12-04 00:55:46.084208 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.341796875, time: 2024-12-04 00:55:46.337741, step: 461\n",
            "loss: 0.4609375, time: 2024-12-04 00:55:46.927967, step: 462\n",
            "loss: 0.263671875, time: 2024-12-04 00:55:47.517754, step: 463\n",
            "loss: 0.46875, time: 2024-12-04 00:55:48.108041, step: 464\n",
            "loss: 0.412109375, time: 2024-12-04 00:55:48.698617, step: 465\n",
            "loss: 0.39453125, time: 2024-12-04 00:55:49.288940, step: 466\n",
            "loss: 0.392578125, time: 2024-12-04 00:55:49.879359, step: 467\n",
            "loss: 0.40625, time: 2024-12-04 00:55:50.469979, step: 468\n",
            "loss: 0.376953125, time: 2024-12-04 00:55:51.059769, step: 469\n",
            "loss: 0.380859375, time: 2024-12-04 00:55:51.650245, step: 470\n",
            "loss: 0.408203125, time: 2024-12-04 00:55:52.240969, step: 471\n",
            "loss: 0.4375, time: 2024-12-04 00:55:52.831000, step: 472\n",
            "loss: 0.353515625, time: 2024-12-04 00:55:53.421440, step: 473\n",
            "loss: 0.45703125, time: 2024-12-04 00:55:54.011885, step: 474\n",
            "loss: 0.287109375, time: 2024-12-04 00:55:54.602333, step: 475\n",
            "loss: 0.3125, time: 2024-12-04 00:55:55.192116, step: 476\n",
            "loss: 0.365234375, time: 2024-12-04 00:55:55.783119, step: 477\n",
            "loss: 0.3046875, time: 2024-12-04 00:55:56.373084, step: 478\n",
            "loss: 0.412109375, time: 2024-12-04 00:55:56.963157, step: 479\n",
            "loss: 0.32421875, time: 2024-12-04 00:55:57.553831, step: 480\n",
            "----- Time -> 2024-12-04 00:55:58.021565 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n",
            "loss: 0.380859375, time: 2024-12-04 00:55:58.273614, step: 481\n",
            "loss: 0.474609375, time: 2024-12-04 00:55:58.863897, step: 482\n",
            "loss: 0.318359375, time: 2024-12-04 00:55:59.453822, step: 483\n",
            "loss: 0.353515625, time: 2024-12-04 00:56:00.043640, step: 484\n",
            "loss: 0.37890625, time: 2024-12-04 00:56:00.634150, step: 485\n",
            "loss: 0.33203125, time: 2024-12-04 00:56:01.224122, step: 486\n",
            "loss: 0.2890625, time: 2024-12-04 00:56:01.813939, step: 487\n",
            "loss: 0.375, time: 2024-12-04 00:56:02.404803, step: 488\n",
            "loss: 0.388671875, time: 2024-12-04 00:56:02.994524, step: 489\n",
            "loss: 0.318359375, time: 2024-12-04 00:56:03.584322, step: 490\n",
            "loss: 0.37109375, time: 2024-12-04 00:56:04.175180, step: 491\n",
            "loss: 0.34765625, time: 2024-12-04 00:56:04.765851, step: 492\n",
            "loss: 0.416015625, time: 2024-12-04 00:56:05.355789, step: 493\n",
            "loss: 0.353515625, time: 2024-12-04 00:56:05.946090, step: 494\n",
            "loss: 0.345703125, time: 2024-12-04 00:56:06.536851, step: 495\n",
            "loss: 0.4140625, time: 2024-12-04 00:56:07.126742, step: 496\n",
            "loss: 0.392578125, time: 2024-12-04 00:56:07.717308, step: 497\n",
            "loss: 0.384765625, time: 2024-12-04 00:56:08.307917, step: 498\n",
            "loss: 0.388671875, time: 2024-12-04 00:56:08.898523, step: 499\n",
            "loss: 0.376953125, time: 2024-12-04 00:56:09.489348, step: 500\n",
            "----- Time -> 2024-12-04 00:56:09.952856 ----- Validation Batch Size -> 0 ----  Validation Loss -> 0.0000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Learning_rate</td><td>â–â–‚â–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–…â–ƒâ–ƒâ–„â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–‚â–â–</td></tr><tr><td>train_step</td><td>â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Learning_rate</td><td>6e-05</td></tr><tr><td>train_loss</td><td>0.37695</td></tr><tr><td>train_step</td><td>500</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gentle-snowball-33</strong> at: <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/leh90ppl' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model/runs/leh90ppl</a><br/> View project at: <a href='https://wandb.ai/alebrije-san-jose-state-university/Math-Model' target=\"_blank\">https://wandb.ai/alebrije-san-jose-state-university/Math-Model</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241204_005110-leh90ppl/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model Trained for 3000 Steps on HuggingFace"
      ],
      "metadata": {
        "id": "ge0isrcIu0-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the non quantized model\n",
        "model.push_to_hub(\n",
        "    SAVED_MODEL,\n",
        "    tokenizer=tokenizer,\n",
        "    safe_serialization=True,\n",
        "    create_pr=True,\n",
        "    max_shard_size=\"3GB\",\n",
        ")\n",
        "\n",
        "tokenizer.push_to_hub(\n",
        "    SAVED_MODEL,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-15T22:23:23.005628Z",
          "iopub.execute_input": "2024-11-15T22:23:23.005873Z",
          "iopub.status.idle": "2024-11-15T22:23:45.596064Z",
          "shell.execute_reply.started": "2024-11-15T22:23:23.005848Z",
          "shell.execute_reply": "2024-11-15T22:23:45.594335Z"
        },
        "id": "Mi3T2GIMu0-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "b4c19180935040f0b157fe8ddb65249e",
            "6ffa55b03566404bb4799e794211f2a8",
            "3b2f48012ff0473f9a81eb884f4d0cde",
            "c121cc1708014ee7850dcfb6aca90bfd",
            "5551fa1083f5415fa3c1668abf34366e",
            "6dfa771c5b764f05aef5c4cc2aa53b2f",
            "8b99868e6eea4833bcb061b3aa6c624c",
            "192dfd0b251c49a48519174314ac4de7",
            "fc1d72428a4e4b68bc72c427910e7d10",
            "9e0ce1d687de444cbd979e0950a98ae0",
            "a2e65019eb274c89aac2511bd4c6f7fe",
            "6082d1f2e3774591b330717b2db6a6a9",
            "3a68f873b036478f8e642913b8b9ac3e",
            "aff5dcc10e8d45569ddc43cd7577cdec",
            "3e55ad74f0c74c4d9b0f0f6167395a6f",
            "7dda54ba16c94e56ac4bd74ad98dc6b3",
            "ecbe0ad48406484bb1672e52b29b43c3",
            "275029495a6940d185a52b108fe2ccfa",
            "fe0a5e0e39d443a682b5edc8a89700bb",
            "1dc840f3e3394f61be780699a2b5c24f",
            "5068ba6f377a4f3f847159d9eb0370d0",
            "a205587552f6473eafb49c1564c1f4a8",
            "1ba546ccd82b4a5980876a09ce61a108",
            "1582068a1cce44b0b2ea470d563fe92c",
            "ff19974f98624c68b91854d8b6ac3f67",
            "5a5b69e6f5e947c6b7defeb99e0f7f73",
            "7cde0297cbb64f9faf44c4428e89661b",
            "b7faba1fa9a84a179cee00dbeabefa48",
            "b4df420e48384f50b823152f50bc105a",
            "264176ce69204a36a3dcb788b67d27a0",
            "4c2732a3684c4058825c0bde018f8783",
            "6da1c33facf2466a8d330796e48f7337",
            "2e5e71999d0a42cc92626762387545d3"
          ]
        },
        "outputId": "ae639a86-5131-43c2-9bbf-ae78fe7098d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4c19180935040f0b157fe8ddb65249e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6082d1f2e3774591b330717b2db6a6a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ba546ccd82b4a5980876a09ce61a108"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftq7E4dvxdU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}